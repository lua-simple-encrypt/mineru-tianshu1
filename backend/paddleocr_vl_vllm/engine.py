"""
PaddleOCR-VL-VLLM è§£æå¼•æ“
å•ä¾‹æ¨¡å¼ï¼Œæ¯ä¸ªè¿›ç¨‹åªåŠ è½½ä¸€æ¬¡åŸºç¡€ç‰ˆé¢è¯†åˆ«æ¨¡å‹, OCRéƒ¨åˆ†è°ƒç”¨é…ç½®çš„API
ä½¿ç”¨æœ€æ–°çš„ PaddleOCR-VL-VLLM APIï¼ˆè‡ªåŠ¨å¤šè¯­è¨€è¯†åˆ«ï¼‰

å‚è€ƒæ–‡æ¡£ï¼šhttps://www.paddleocr.ai/latest/version3.x/pipeline_usage/PaddleOCR-VL.html#322-python-api

é‡è¦æç¤ºï¼š
- PaddleOCR-VL-VLLM ä»…æ”¯æŒ GPU æ¨ç†ï¼Œä¸æ”¯æŒ CPU åŠ Arm æ¶æ„
- GPU è¦æ±‚ï¼šCompute Capability >= 8.5 (RTX 3090, A10, A100, H100 ç­‰)
- æ”¯æŒæœ¬åœ°æ¨¡å‹åŠ è½½ï¼ˆ/root/.paddlex/official_models/ï¼‰æˆ–è‡ªåŠ¨ä¸‹è½½
"""

import os
import gc
import json
import traceback
from pathlib import Path
from typing import Optional, Dict, Any
from threading import Lock
import time
from loguru import logger

class PaddleOCRVLVLLMEngine:
    """
    PaddleOCR-VL-VLLM è§£æå¼•æ“ï¼ˆæ–°ç‰ˆæœ¬ï¼‰

    ç‰¹æ€§ï¼š
    - å•ä¾‹æ¨¡å¼ï¼ˆæ¯ä¸ªè¿›ç¨‹åªåŠ è½½ä¸€æ¬¡æ¨¡å‹ï¼‰
    - è‡ªåŠ¨å¤šè¯­è¨€è¯†åˆ«ï¼ˆæ— éœ€æŒ‡å®šè¯­è¨€ï¼Œæ”¯æŒ 109+ è¯­è¨€ï¼‰
    - çº¿ç¨‹å®‰å…¨
    - ä»…æ”¯æŒ GPU æ¨ç†ï¼ˆä¸æ”¯æŒ CPUï¼‰
    - åŸç”Ÿæ”¯æŒ PDF å¤šé¡µæ–‡æ¡£è§£æ
    - ç»“æ„åŒ–è¾“å‡ºï¼ˆMarkdown/JSONï¼‰
    - æ¨¡å‹è‡ªåŠ¨ä¸‹è½½å’Œç¼“å­˜ï¼ˆæ”¯æŒæŒä¹…åŒ–æŒ‚è½½ï¼‰
    - å†…å­˜ä¼˜åŒ–ï¼šä½¿ç”¨ç”Ÿæˆå™¨æµå¼å¤„ç†é•¿æ–‡æ¡£ï¼Œé˜²æ­¢ OOM
    - å‚æ•°æ”¯æŒï¼šæ”¯æŒ PaddleOCR-VL-1.5 çš„å…¨é‡é«˜çº§å‚æ•°é…ç½®

    GPU è¦æ±‚ï¼š
    - NVIDIA GPU with Compute Capability >= 8.5
    - æ¨èï¼šRTX 3090, RTX 4090, A10, A100, H100
    """

    _instance: Optional["PaddleOCRVLVLLMEngine"] = None
    _lock = Lock()
    _pipeline = None
    _initialized = False

    def __new__(cls, *args, **kwargs):
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
        return cls._instance

    def __init__(self, device: str = "cuda:0", vllm_api_base: str = "http://localhost:17300/v1", model_name: str = "PaddleOCR-VL-1.5-0.9B"):
        """
        åˆå§‹åŒ–å¼•æ“ï¼ˆåªæ‰§è¡Œä¸€æ¬¡ï¼‰

        Args:
            device: è®¾å¤‡ (cuda:0, cuda:1 ç­‰ï¼ŒPaddleOCR ä»…æ”¯æŒ GPU)
            vllm_api_base: VLLM API åŸºç¡€ URL
            model_name: æ¨¡å‹åç§° (é»˜è®¤: PaddleOCR-VL-1.5-0.9B)
        """
        if self._initialized:
            return

        with self._lock:
            if self._initialized:
                return

            self.device = device
            self.vllm_api_base = vllm_api_base
            self.model_name = model_name

            # ä» device å­—ç¬¦ä¸²ä¸­æå– GPU ID (ä¾‹å¦‚ "cuda:0" -> 0)
            if "cuda:" in device:
                self.gpu_id = int(device.split(":")[-1])
            else:
                self.gpu_id = 0
                logger.warning(f"âš ï¸  Invalid device format: {device}, using GPU 0")

            # æ£€æŸ¥ GPU å¯ç”¨æ€§
            self._check_gpu_availability()

            self._initialized = True

            logger.info("ğŸ”§ PaddleOCR-VL-VLLM Engine initialized")
            logger.info(f"   Device: {self.device} (GPU ID: {self.gpu_id})")
            logger.info(f"   VLLM API Base: {self.vllm_api_base}")
            logger.info(f"   Model: {self.model_name}")

    def _check_gpu_availability(self):
        """
        æ£€æŸ¥ GPU ä¿¡æ¯å¹¶è¾“å‡ºæ—¥å¿—
        PaddleOCR-VL ä»…æ”¯æŒ GPU æ¨ç†ï¼Œä½†ä¸é˜»æ­¢ä½ç‰ˆæœ¬ GPU è¿è¡Œ
        """
        try:
            import paddle

            # æ£€æŸ¥æ˜¯å¦ç¼–è¯‘äº† CUDA æ”¯æŒ
            if not paddle.is_compiled_with_cuda():
                logger.warning("âš ï¸  PaddlePaddle is not compiled with CUDA")
                logger.warning("   PaddleOCR-VL requires GPU support")
                logger.warning("   Install: pip install paddlepaddle-gpu==3.0.0b1 -i https://www.paddlepaddle.org.cn/packages/stable/cu118/")
                return

            # æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„ GPU
            gpu_count = paddle.device.cuda.device_count()
            if gpu_count == 0:
                logger.warning("âš ï¸  No CUDA devices found")
                logger.warning("   PaddleOCR-VL requires GPU for inference")
                return

            # è·å– GPU ä¿¡æ¯
            try:
                gpu_name = paddle.device.cuda.get_device_name(0)
                compute_capability = paddle.device.cuda.get_device_capability(0)

                logger.info(f"âœ… GPU detected: {gpu_name}")
                logger.info(f"   Compute Capability: {compute_capability[0]}.{compute_capability[1]}")
                logger.info(f"   GPU Count: {gpu_count}")

                # ä»…è¾“å‡ºå»ºè®®ï¼Œä¸é˜»æ­¢è¿è¡Œ
                cc_major = compute_capability[0]
                cc_minor = compute_capability[1]
                if cc_major < 8 or (cc_major == 8 and cc_minor < 5):
                    logger.info("â„¹ï¸  GPU Compute Capability < 8.5")
                    logger.info("   Official recommendation: CC >= 8.5 for best performance")
                    logger.info("   Your GPU may still work, but performance might vary")
            except Exception as e:
                logger.debug(f"Could not get detailed GPU info: {e}")

        except ImportError:
            logger.warning("âš ï¸  PaddlePaddle not installed")
        except Exception as e:
            logger.debug(f"GPU check warning: {e}")

    def _load_pipeline(self):
        """å»¶è¿ŸåŠ è½½ PaddleOCR-VL-VLLM ç®¡é“"""
        if self._pipeline is not None:
            return self._pipeline

        with self._lock:
            if self._pipeline is not None:
                return self._pipeline

            logger.info("=" * 60)
            logger.info("ğŸ“¥ Loading PaddleOCR-VL-VLLM Pipeline into memory...")
            logger.info("=" * 60)

            try:
                import paddle
                from paddleocr import PaddleOCRVL

                # è®¾ç½® PaddlePaddle ä½¿ç”¨æŒ‡å®šçš„ GPU
                if paddle.is_compiled_with_cuda():
                    paddle.set_device(f"gpu:{self.gpu_id}")
                    logger.info(f"ğŸ¯ PaddlePaddle device set to: gpu:{self.gpu_id}")
                else:
                    logger.warning("âš ï¸  CUDA not available, PaddleOCR-VL may not work")

                if self.vllm_api_base is None:
                    raise ValueError("vllm_api_base cannot be None for VLLM engine")

                logger.info("ğŸ¤– Initializing PaddleOCR-VL-VLLM with enhanced features...")
                
                # =========================================================================
                # æ™ºèƒ½è·¯å¾„è§£æé€»è¾‘ (é€‚é… Docker æŒä¹…åŒ–æŒ‚è½½)
                # =========================================================================
                # 1. è·å– PADDLEX_HOME ç¯å¢ƒå˜é‡ï¼Œé»˜è®¤æŒ‡å‘ /root/.paddlex
                pdx_home = os.environ.get("PADDLEX_HOME", "/root/.paddlex")
                logger.info(f"ğŸ’¾ Using PADDLEX_HOME: {pdx_home}")
                
                # 2. ä¿®æ­£ä¸ºçœŸå®çš„ PaddleX å®˜æ–¹æ¨¡å‹ç¼“å­˜ç›®å½•
                base_model_dir = Path(pdx_home) / "official_models"
                local_model_path = base_model_dir / self.model_name
                
                # æ¢æµ‹æœ¬åœ°æ˜¯å¦æœ‰æ¨¡å‹ï¼Œä»¥ä¾¿è¾“å‡ºå‡†ç¡®çš„æ—¥å¿—
                if local_model_path.exists() and local_model_path.is_dir() and any(local_model_path.iterdir()):
                    logger.info(f"ğŸ“‚ Found local model cache: {local_model_path}")
                else:
                    logger.warning(f"ğŸŒ Local model not found at {local_model_path}")
                    logger.info("   Will attempt auto-download...")

                # åˆå§‹åŒ– PaddleOCRVL
                # (é¢„æµ‹æ—¶çš„é«˜çº§å‚æ•°å°†é€šè¿‡ predict(**kwargs) ä¼ é€’)
                self._pipeline = PaddleOCRVL(
                    vl_rec_backend="vllm-server",       # ä½¿ç”¨ VLLM åç«¯
                    vl_rec_server_url=self.vllm_api_base, # VLLM æœåŠ¡å™¨åœ°å€
                )
                
                logger.info("=" * 60)
                logger.info("âœ… PaddleOCR-VL-VLLM Pipeline loaded successfully!")
                logger.info(f"   Device: GPU {self.gpu_id}")
                logger.info("=" * 60)

                return self._pipeline

            except Exception as e:
                logger.error("=" * 80)
                logger.error("âŒ ç®¡é“åŠ è½½å¤±è´¥:")
                logger.error(f"   é”™è¯¯ç±»å‹: {type(e).__name__}")
                logger.error(f"   é”™è¯¯ä¿¡æ¯: {e}")
                logger.error("")
                logger.error("ğŸ’¡ æ’æŸ¥å»ºè®®:")
                logger.error("   1. æ£€æŸ¥ vLLM æœåŠ¡æ˜¯å¦å¯åŠ¨ (http://vllm-paddleocr:30023)")
                logger.error("   2. æ£€æŸ¥ç½‘ç»œè¿æ¥ï¼ˆé¦–æ¬¡è¿è¡Œéœ€è¦ä¸‹è½½ç‰ˆé¢åˆ†ææ¨¡å‹ï¼‰")
                logger.error("   3. æ£€æŸ¥æ˜¾å­˜æ˜¯å¦å……è¶³")
                logger.error("=" * 80)

                import traceback
                logger.debug("å®Œæ•´å †æ ˆè·Ÿè¸ª:")
                logger.debug(traceback.format_exc())

                raise

    def warmup(self):
        """
        æ‰‹åŠ¨è§¦å‘æ¨¡å‹åŠ è½½ï¼ˆé¢„çƒ­ï¼‰
        """
        if self._pipeline is None:
            logger.info("ğŸ”¥ Warming up PaddleOCR-VL-VLLM engine...")
            try:
                self._load_pipeline()
                logger.info("ğŸ”¥ Warmup completed! Engine is ready.")
            except Exception as e:
                logger.error(f"ğŸ”¥ Warmup failed: {e}")

    def cleanup(self):
        """
        æ¸…ç†æ¨ç†äº§ç”Ÿçš„æ˜¾å­˜ï¼ˆä¸å¸è½½æ¨¡å‹ï¼‰
        """
        try:
            import paddle
            import gc

            if paddle.device.is_compiled_with_cuda():
                paddle.device.cuda.empty_cache()
                logger.debug("ğŸ§¹ PaddleOCR-VL-VLLM: CUDA cache cleared")

            gc.collect()
            logger.debug("ğŸ§¹ PaddleOCR-VL-VLLM: Memory cleanup completed")
        except Exception as e:
            logger.debug(f"Memory cleanup warning: {e}")

    def parse(self, file_path: str, output_path: str, **kwargs) -> Dict[str, Any]:
        """
        è§£ææ–‡æ¡£æˆ–å›¾ç‰‡

        Args:
            file_path: è¾“å…¥æ–‡ä»¶è·¯å¾„
            output_path: è¾“å‡ºç›®å½•
            **kwargs: å…¶ä»–é«˜çº§æ§åˆ¶å‚æ•°

        Returns:
            è§£æç»“æœï¼ˆåŒæ—¶ä¿å­˜ Markdown å’Œ JSON ä¸¤ç§æ ¼å¼ï¼‰
        """
        file_path = Path(file_path)
        output_path = Path(output_path)
        output_path.mkdir(parents=True, exist_ok=True)

        logger.info(f"ğŸ¤– PaddleOCR-VL-VLLM parsing: {file_path.name}")
        logger.info("   Auto language detection enabled")

        # åŠ è½½ç®¡é“
        pipeline = self._load_pipeline()

        # å‚æ•°æ˜ å°„è¡¨ (API é©¼å³° -> PaddleX ä¸‹åˆ’çº¿)
        param_mapping = {
            "useDocOrientationClassify": "use_doc_orientation_classify",
            "useDocUnwarping": "use_doc_unwarping",
            "useLayoutDetection": "use_layout_parsing",
            "useChartRecognition": "use_chart_recognition",
            "useSealRecognition": "use_seal_recognition",
            "useOcrForImageBlock": "use_ocr_for_image_block",
            "layoutNms": "layout_nms",
            "markdownIgnoreLabels": "markdown_ignore_labels",
            "mergeTables": "merge_tables",
            "relevelTitles": "relevel_titles",
            "restructurePages": "restructure_pages",
            "layoutShapeMode": "layout_shape_mode",
            "minPixels": "min_pixels",
            "maxPixels": "max_pixels",
            "promptLabel": "prompt_label", 
            "temperature": "temperature",
            "topP": "top_p",
            "repetitionPenalty": "repetition_penalty"
        }

        # è§„èŒƒåŒ–å‚æ•°å¹¶è¿‡æ»¤å¤©æ¢å…¶ä»–æ— å…³å‚æ•°
        predict_params = {}
        for k, v in kwargs.items():
            if k in param_mapping:
                predict_params[param_mapping[k]] = v

        try:
            # åŠ¨æ€æ£€æŸ¥é¢„å¤„ç†æ¨¡å—æ˜¯å¦æ”¯æŒ
            has_preprocessor = hasattr(pipeline, "doc_preprocessor_pipeline") and pipeline.doc_preprocessor_pipeline is not None
            req_orientation = predict_params.get("use_doc_orientation_classify", False)
            req_unwarping = predict_params.get("use_doc_unwarping", False)

            if (req_orientation or req_unwarping) and not has_preprocessor:
                logger.warning("âš ï¸ è¯·æ±‚äº†æ–‡æ¡£çŸ«æ­£/åˆ†ç±»ï¼Œä½†æ¨¡å‹ç¼ºå°‘é¢„å¤„ç†æ¨¡å—ã€‚å·²è‡ªåŠ¨ç¦ç”¨ä»¥é˜²æ­¢å´©æºƒã€‚")
                predict_params["use_doc_orientation_classify"] = False
                predict_params["use_doc_unwarping"] = False

            # è®¾ç½®è¾“å…¥å’ŒåŸºæœ¬é»˜è®¤å€¼
            predict_params["input"] = str(file_path)
            if "use_layout_parsing" not in predict_params: predict_params["use_layout_parsing"] = True
            if "use_doc_orientation_classify" not in predict_params: predict_params["use_doc_orientation_classify"] = False
            if "use_doc_unwarping" not in predict_params: predict_params["use_doc_unwarping"] = False

            log_params = {k: v for k, v in predict_params.items() if k != "input"}
            logger.info(f"ğŸš€ å¼€å§‹ä½¿ç”¨ PaddleOCR-VL-VLLM è¯†åˆ« (å‚æ•°: {json.dumps(log_params, default=str, ensure_ascii=False)})")

            # æ‰§è¡Œæ¨ç† (ä½¿ç”¨æµå¼ç”Ÿæˆå™¨é˜²æ­¢é•¿æ–‡æ¡£ OOM)
            output_generator = pipeline.predict(**predict_params)

            markdown_pages = []
            markdown_list_obj = [] # ç”¨äºä¿å­˜åŸå§‹ markdown å¯¹è±¡ä»¥ä¾¿è¿›è¡Œå®˜æ–¹åˆå¹¶
            json_list = []
            page_count = 0

            for res in output_generator:
                page_count += 1
                logger.info(f"ğŸ“ å¤„ç†ç»“æœ ç¬¬ {page_count} é¡µ")
                page_output_dir = output_path / f"page_{page_count}"
                page_output_dir.mkdir(parents=True, exist_ok=True)

                # ä¿å­˜æ–‡ä»¶
                if hasattr(res, "save_to_img"): res.save_to_img(str(page_output_dir))
                if hasattr(res, "save_to_json"): res.save_to_json(str(page_output_dir))

                # æ”¶é›† JSON å¯¹è±¡
                if hasattr(res, "json"):
                    json_list.append(res.json)

                # æ”¶é›† Markdown å¯¹è±¡å’Œå­—ç¬¦ä¸²
                if hasattr(res, "markdown") and res.markdown:
                    markdown_list_obj.append(res.markdown)
                
                # å¥å£®æå–å½“å‰é¡µ Markdown
                page_md = ""
                if hasattr(res, "markdown") and res.markdown:
                    if isinstance(res.markdown, dict):
                        page_md = res.markdown.get('markdown_texts', '') or res.markdown.get('text', '')
                    elif hasattr(res.markdown, 'markdown_texts'):
                        page_md = res.markdown.markdown_texts
                    elif isinstance(res.markdown, str):
                        page_md = res.markdown
                    else:
                        page_md = str(res.markdown)
                elif hasattr(res, "str") and res.str:
                    page_md = str(res.str)

                # å…œåº•æ–‡ä»¶è¯»å–
                if not page_md and hasattr(res, "save_to_markdown"):
                    try:
                        res.save_to_markdown(str(page_output_dir))
                        saved_mds = list(page_output_dir.glob("*.md"))
                        if saved_mds:
                            page_md = saved_mds[0].read_text(encoding="utf-8")
                    except Exception:
                        pass

                if page_md:
                    markdown_pages.append(page_md)
                else:
                    logger.warning(f"âš ï¸ Page {page_count}: No markdown content extracted.")

            logger.info(f"âœ… PaddleOCR-VL-VLLM completed, Processed {page_count} pages")

            # åˆå¹¶ Markdown
            markdown_text = ""
            if hasattr(pipeline, "concatenate_markdown_pages") and markdown_list_obj:
                try:
                    markdown_text = pipeline.concatenate_markdown_pages(markdown_list_obj)
                    logger.info("   ä½¿ç”¨å®˜æ–¹ concatenate_markdown_pages() æ–¹æ³•åˆå¹¶")
                except Exception as e:
                    logger.warning(f"å®˜æ–¹åˆå¹¶æ–¹æ³•å¤±è´¥: {e}, è‡ªåŠ¨å›é€€åˆ°å¸¸è§„æ‹¼æ¥")
                    markdown_text = "\n\n---\n\n".join(markdown_pages)
            else:
                markdown_text = "\n\n---\n\n".join(markdown_pages)

            # ä¿å­˜æœ€ç»ˆç»“æœ
            markdown_file = output_path / "result.md"
            markdown_file.write_text(markdown_text, encoding="utf-8")
            logger.info(f"ğŸ“„ Markdown å·²ä¿å­˜: {markdown_file}")

            json_file = output_path / "result.json"
            if json_list:
                import json as json_lib
                combined_json = {"pages": json_list, "total_pages": page_count}
                with open(json_file, "w", encoding="utf-8") as f:
                    json_lib.dump(combined_json, f, ensure_ascii=False, indent=2)
                logger.info(f"ğŸ“„ JSON å·²ä¿å­˜: {json_file}")

            return {
                "success": True,
                "output_path": str(output_path),
                "markdown": markdown_text,
                "markdown_file": str(markdown_file),
                "json_file": str(json_file),
            }

        except Exception as e:
            logger.error(f"âŒ OCR è§£æå¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            raise

        finally:
            self.cleanup()

# å…¨å±€å•ä¾‹
_engine = None

def get_engine(vllm_api_base: str = "http://localhost:17300/v1", model_name: str = "PaddleOCR-VL-1.5-0.9B") -> PaddleOCRVLVLLMEngine:
    global _engine
    if _engine is None:
        _engine = PaddleOCRVLVLLMEngine(vllm_api_base=vllm_api_base, model_name=model_name)
    return _engine
