"""
PaddleOCR-VL-VLLM è§£æå¼•æ“
å•ä¾‹æ¨¡å¼ï¼Œæ¯ä¸ªè¿›ç¨‹åªåŠ è½½ä¸€æ¬¡åŸºç¡€ç‰ˆé¢è¯†åˆ«æ¨¡å‹, OCRéƒ¨åˆ†è°ƒç”¨é…ç½®çš„API
ä½¿ç”¨æœ€æ–°çš„ PaddleOCR-VL-VLLM APIï¼ˆè‡ªåŠ¨å¤šè¯­è¨€è¯†åˆ«ï¼‰

å‚è€ƒæ–‡æ¡£ï¼šhttps://www.paddleocr.ai/latest/version3.x/pipeline_usage/PaddleOCR-VL.html#322-python-api

é‡è¦æç¤ºï¼š
- PaddleOCR-VL-VLLM ä»…æ”¯æŒ GPU æ¨ç†ï¼Œä¸æ”¯æŒ CPU åŠ Arm æ¶æ„
- GPU è¦æ±‚ï¼šCompute Capability â‰¥ 8.5 (RTX 3090, A10, A100, H100 ç­‰)
- æ”¯æŒæœ¬åœ°æ¨¡å‹åŠ è½½ï¼ˆ/app/models/paddlex/ï¼‰æˆ–è‡ªåŠ¨ä¸‹è½½ï¼ˆæŒä¹…åŒ–åˆ° /root/.paddlexï¼‰
"""

import os
from pathlib import Path
from typing import Optional, Dict, Any
from threading import Lock
import time
from loguru import logger

class PaddleOCRVLVLLMEngine:
    """
    PaddleOCR-VL-VLLM è§£æå¼•æ“ï¼ˆæ–°ç‰ˆæœ¬ï¼‰

    ç‰¹æ€§ï¼š
    - å•ä¾‹æ¨¡å¼ï¼ˆæ¯ä¸ªè¿›ç¨‹åªåŠ è½½ä¸€æ¬¡æ¨¡å‹ï¼‰
    - è‡ªåŠ¨å¤šè¯­è¨€è¯†åˆ«ï¼ˆæ— éœ€æŒ‡å®šè¯­è¨€ï¼Œæ”¯æŒ 109+ è¯­è¨€ï¼‰
    - çº¿ç¨‹å®‰å…¨
    - ä»…æ”¯æŒ GPU æ¨ç†ï¼ˆä¸æ”¯æŒ CPUï¼‰
    - åŸç”Ÿæ”¯æŒ PDF å¤šé¡µæ–‡æ¡£è§£æ
    - ç»“æ„åŒ–è¾“å‡ºï¼ˆMarkdown/JSONï¼‰
    - æ¨¡å‹è‡ªåŠ¨ä¸‹è½½å’Œç¼“å­˜ï¼ˆæ”¯æŒæŒä¹…åŒ–æŒ‚è½½ï¼‰

    GPU è¦æ±‚ï¼š
    - NVIDIA GPU with Compute Capability â‰¥ 8.5
    - æ¨èï¼šRTX 3090, RTX 4090, A10, A100, H100
    """

    _instance: Optional["PaddleOCRVLVLLMEngine"] = None
    _lock = Lock()
    _pipeline = None
    _initialized = False

    def __new__(cls, *args, **kwargs):
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
        return cls._instance

    def __init__(self, device: str = "cuda:0", vllm_api_base: str = "http://localhost:17300/v1", model_name: str = "PaddleOCR-VL-1.5-0.9B"):
        """
        åˆå§‹åŒ–å¼•æ“ï¼ˆåªæ‰§è¡Œä¸€æ¬¡ï¼‰

        Args:
            device: è®¾å¤‡ (cuda:0, cuda:1 ç­‰ï¼ŒPaddleOCR ä»…æ”¯æŒ GPU)
            vllm_api_base: VLLM API åŸºç¡€ URL
            model_name: æ¨¡å‹åç§° (é»˜è®¤: PaddleOCR-VL-1.5-0.9B)
        """
        if self._initialized:
            return

        with self._lock:
            if self._initialized:
                return

            self.device = device
            self.vllm_api_base = vllm_api_base
            self.model_name = model_name

            # ä» device å­—ç¬¦ä¸²ä¸­æå– GPU ID (ä¾‹å¦‚ "cuda:0" -> 0)
            if "cuda:" in device:
                self.gpu_id = int(device.split(":")[-1])
            else:
                self.gpu_id = 0
                logger.warning(f"âš ï¸  Invalid device format: {device}, using GPU 0")

            # æ£€æŸ¥ GPU å¯ç”¨æ€§
            self._check_gpu_availability()

            self._initialized = True

            logger.info("ğŸ”§ PaddleOCR-VL-VLLM Engine initialized")
            logger.info(f"   Device: {self.device} (GPU ID: {self.gpu_id})")
            logger.info(f"   VLLM API Base: {self.vllm_api_base}")
            logger.info(f"   Model: {self.model_name}")

    def _check_gpu_availability(self):
        """
        æ£€æŸ¥ GPU ä¿¡æ¯å¹¶è¾“å‡ºæ—¥å¿—
        PaddleOCR-VL ä»…æ”¯æŒ GPU æ¨ç†ï¼Œä½†ä¸é˜»æ­¢ä½ç‰ˆæœ¬ GPU è¿è¡Œ
        """
        try:
            import paddle

            # æ£€æŸ¥æ˜¯å¦ç¼–è¯‘äº† CUDA æ”¯æŒ
            if not paddle.is_compiled_with_cuda():
                logger.warning("âš ï¸  PaddlePaddle is not compiled with CUDA")
                logger.warning("   PaddleOCR-VL requires GPU support")
                logger.warning("   Install: pip install paddlepaddle-gpu==3.0.0b1 -i https://www.paddlepaddle.org.cn/packages/stable/cu118/")
                return

            # æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„ GPU
            gpu_count = paddle.device.cuda.device_count()
            if gpu_count == 0:
                logger.warning("âš ï¸  No CUDA devices found")
                logger.warning("   PaddleOCR-VL requires GPU for inference")
                return

            # è·å– GPU ä¿¡æ¯
            try:
                gpu_name = paddle.device.cuda.get_device_name(0)
                compute_capability = paddle.device.cuda.get_device_capability(0)

                logger.info(f"âœ… GPU detected: {gpu_name}")
                logger.info(f"   Compute Capability: {compute_capability[0]}.{compute_capability[1]}")
                logger.info(f"   GPU Count: {gpu_count}")

                # ä»…è¾“å‡ºå»ºè®®ï¼Œä¸é˜»æ­¢è¿è¡Œ
                cc_major = compute_capability[0]
                cc_minor = compute_capability[1]
                if cc_major < 8 or (cc_major == 8 and cc_minor < 5):
                    logger.info("â„¹ï¸  GPU Compute Capability < 8.5")
                    logger.info("   Official recommendation: CC â‰¥ 8.5 for best performance")
                    logger.info("   Your GPU may still work, but performance might vary")
            except Exception as e:
                logger.debug(f"Could not get detailed GPU info: {e}")

        except ImportError:
            logger.warning("âš ï¸  PaddlePaddle not installed")
        except Exception as e:
            logger.debug(f"GPU check warning: {e}")

    def _load_pipeline(self):
        """å»¶è¿ŸåŠ è½½ PaddleOCR-VL-VLLM ç®¡é“"""
        if self._pipeline is not None:
            return self._pipeline

        with self._lock:
            if self._pipeline is not None:
                return self._pipeline

            logger.info("=" * 60)
            logger.info("ğŸ“¥ Loading PaddleOCR-VL-VLLM Pipeline into memory...")
            logger.info("=" * 60)

            try:
                import paddle
                from paddleocr import PaddleOCRVL

                # è®¾ç½® PaddlePaddle ä½¿ç”¨æŒ‡å®šçš„ GPU
                if paddle.is_compiled_with_cuda():
                    paddle.set_device(f"gpu:{self.gpu_id}")
                    logger.info(f"ğŸ¯ PaddlePaddle device set to: gpu:{self.gpu_id}")
                else:
                    logger.warning("âš ï¸  CUDA not available, PaddleOCR-VL may not work")

                if self.vllm_api_base is None:
                    raise ValueError("vllm_api_base cannot be None for VLLM engine")

                logger.info("ğŸ¤– Initializing PaddleOCR-VL-VLLM with enhanced features...")
                logger.info("   âœ… Document Orientation Classification: Enabled")
                logger.info("   âœ… Document Unwarping (Text Correction): Enabled")
                logger.info("   âœ… Layout Detection & Sorting: Enabled")
                logger.info("   âœ… Auto Multi-Language Recognition: Enabled (109+ languages)")

                # =========================================================================
                # æ™ºèƒ½è·¯å¾„è§£æé€»è¾‘ (é€‚é… Docker æŒä¹…åŒ–æŒ‚è½½)
                # =========================================================================
                # 1. ä¼˜å…ˆæ£€æŸ¥ Docker æŒ‚è½½çš„ PADDLEX_HOME ç¯å¢ƒå˜é‡
                pdx_home = os.environ.get("PADDLEX_HOME")
                if pdx_home:
                    logger.info(f"ğŸ’¾ Using PADDLEX_HOME from env: {pdx_home}")
                
                # 2. å®šä¹‰æ‰‹åŠ¨æ¨¡å‹ç›®å½•
                base_model_dir = Path("/app/models/paddlex")
                local_model_path = base_model_dir / self.model_name
                
                # PaddleOCRVL ç›®å‰ç‰ˆæœ¬ä¼¼ä¹ä¸ç›´æ¥æ¥å— model_dir å‚æ•°ä½œä¸ºæœ¬åœ°è·¯å¾„
                # å®ƒä¾èµ–ç¯å¢ƒå˜é‡ PADDLEX_HOME å»æŸ¥æ‰¾æˆ–ä¸‹è½½æ¨¡å‹
                # ä½†æˆ‘ä»¬è¿˜æ˜¯è¦æ£€æŸ¥ä¸€ä¸‹æœ¬åœ°æ˜¯å¦æœ‰æ¨¡å‹ï¼Œä»¥ä¾¿è¾“å‡ºæ—¥å¿—
                if local_model_path.exists() and local_model_path.is_dir() and any(local_model_path.iterdir()):
                    logger.info(f"ğŸ“‚ Found local model cache: {local_model_path}")
                else:
                    logger.info(f"ğŸŒ Local model not found at {local_model_path}")
                    logger.info(f"   Will use auto-download to: {pdx_home if pdx_home else 'Default Cache'}")

                # åˆå§‹åŒ– PaddleOCRVL
                # æ³¨æ„ï¼šPaddleOCRVL å†…éƒ¨ä¼šä½¿ç”¨ PADDLEX_HOME ç¯å¢ƒå˜é‡æ¥å†³å®šä¸‹è½½/åŠ è½½ä½ç½®
                self._pipeline = PaddleOCRVL(
                    use_doc_orientation_classify=True,  # æ–‡æ¡£æ–¹å‘åˆ†ç±»
                    use_doc_unwarping=True,             # æ–‡æœ¬å›¾åƒçŸ«æ­£
                    use_layout_detection=True,          # ç‰ˆé¢åŒºåŸŸæ£€æµ‹
                    vl_rec_backend="vllm-server",       # ä½¿ç”¨ VLLM åç«¯
                    vl_rec_server_url=self.vllm_api_base, # VLLM æœåŠ¡å™¨åœ°å€
                )
                
                logger.info("=" * 60)
                logger.info("âœ… PaddleOCR-VL-VLLM Pipeline loaded successfully!")
                logger.info(f"   Device: GPU {self.gpu_id}")
                logger.info("   Features: Orientation correction, Text unwarping, Layout detection")
                logger.info("=" * 60)

                return self._pipeline

            except Exception as e:
                logger.error("=" * 80)
                logger.error("âŒ ç®¡é“åŠ è½½å¤±è´¥:")
                logger.error(f"   é”™è¯¯ç±»å‹: {type(e).__name__}")
                logger.error(f"   é”™è¯¯ä¿¡æ¯: {e}")
                logger.error("")
                logger.error("ğŸ’¡ æ’æŸ¥å»ºè®®:")
                logger.error("   1. æ£€æŸ¥ vLLM æœåŠ¡æ˜¯å¦å¯åŠ¨ (http://vllm-paddleocr:30023)")
                logger.error("   2. æ£€æŸ¥ç½‘ç»œè¿æ¥ï¼ˆé¦–æ¬¡è¿è¡Œéœ€è¦ä¸‹è½½ç‰ˆé¢åˆ†ææ¨¡å‹ï¼‰")
                logger.error("   3. æ£€æŸ¥æ˜¾å­˜æ˜¯å¦å……è¶³")
                logger.error("=" * 80)

                import traceback
                logger.debug("å®Œæ•´å †æ ˆè·Ÿè¸ª:")
                logger.debug(traceback.format_exc())

                raise

    def warmup(self):
        """
        æ‰‹åŠ¨è§¦å‘æ¨¡å‹åŠ è½½ï¼ˆé¢„çƒ­ï¼‰
        """
        if self._pipeline is None:
            logger.info("ğŸ”¥ Warming up PaddleOCR-VL-VLLM engine...")
            try:
                self._load_pipeline()
                logger.info("ğŸ”¥ Warmup completed! Engine is ready.")
            except Exception as e:
                logger.error(f"ğŸ”¥ Warmup failed: {e}")

    def cleanup(self):
        """
        æ¸…ç†æ¨ç†äº§ç”Ÿçš„æ˜¾å­˜ï¼ˆä¸å¸è½½æ¨¡å‹ï¼‰
        """
        try:
            import paddle
            import gc

            if paddle.device.is_compiled_with_cuda():
                paddle.device.cuda.empty_cache()
                logger.debug("ğŸ§¹ PaddleOCR-VL-VLLM: CUDA cache cleared")

            gc.collect()
            logger.debug("ğŸ§¹ PaddleOCR-VL-VLLM: Memory cleanup completed")
        except Exception as e:
            logger.debug(f"Memory cleanup warning: {e}")

    def parse(self, file_path: str, output_path: str, **kwargs) -> Dict[str, Any]:
        """
        è§£ææ–‡æ¡£æˆ–å›¾ç‰‡

        Args:
            file_path: è¾“å…¥æ–‡ä»¶è·¯å¾„
            output_path: è¾“å‡ºç›®å½•
            **kwargs: å…¶ä»–å‚æ•°

        Returns:
            è§£æç»“æœï¼ˆåŒæ—¶ä¿å­˜ Markdown å’Œ JSON ä¸¤ç§æ ¼å¼ï¼‰
        """
        file_path = Path(file_path)
        output_path = Path(output_path)
        output_path.mkdir(parents=True, exist_ok=True)

        logger.info(f"ğŸ¤– PaddleOCR-VL-VLLM parsing: {file_path.name}")
        logger.info("   Auto language detection enabled")

        # åŠ è½½ç®¡é“
        pipeline = self._load_pipeline()

        # æ‰§è¡Œæ¨ç†
        try:
            logger.info("ğŸš€ å¼€å§‹ä½¿ç”¨ PaddleOCR-VL-VLLM è¯†åˆ«...")
            logger.info(f"   è¾“å…¥æ–‡ä»¶: {file_path}")
            logger.info("   è‡ªåŠ¨è¯­è¨€æ£€æµ‹: æ”¯æŒ 109+ è¯­è¨€")

            # PaddleOCR-VL-VLLM çš„ predict æ–¹æ³•
            result = pipeline.predict(str(file_path))

            logger.info("âœ… PaddleOCR-VL-VLLM completed")
            logger.info(f"   è¯†åˆ«äº† {len(result)} é¡µ/å¼ ")

            # å¤„ç†ç»“æœ
            markdown_list = []
            json_list = []

            for idx, res in enumerate(result, 1):
                logger.info(f"ğŸ“ å¤„ç†ç»“æœ {idx}/{len(result)}")

                try:
                    page_output_dir = output_path / f"page_{idx}"
                    page_output_dir.mkdir(parents=True, exist_ok=True)

                    if hasattr(res, "save_to_json"):
                        res.save_to_json(save_path=str(page_output_dir))
                    
                    if hasattr(res, "save_to_markdown"):
                        res.save_to_markdown(save_path=str(page_output_dir))

                    if hasattr(res, "markdown"):
                        md_info = res.markdown
                        markdown_list.append(md_info)
                    
                    if hasattr(res, "json"):
                        json_list.append(res.json)

                except Exception as e:
                    logger.warning(f"   å¤„ç†å‡ºé”™: {e}")

            # åˆå¹¶ Markdown
            if hasattr(pipeline, "concatenate_markdown_pages") and markdown_list:
                try:
                    markdown_text = pipeline.concatenate_markdown_pages(markdown_list)
                    logger.info("   ä½¿ç”¨å®˜æ–¹ concatenate_markdown_pages() æ–¹æ³•åˆå¹¶")
                except Exception:
                     markdown_text = "\n\n---\n\n".join([str(m) for m in markdown_list])
            else:
                markdown_text = "\n\n---\n\n".join([str(m) for m in markdown_list])

            # ä¿å­˜ç»“æœ
            markdown_file = output_path / "result.md"
            markdown_file.write_text(markdown_text, encoding="utf-8")
            logger.info(f"ğŸ“„ Markdown å·²ä¿å­˜: {markdown_file}")

            json_file = output_path / "result.json"
            if json_list:
                import json as json_lib
                combined_json = {"pages": json_list, "total_pages": len(result)}
                with open(json_file, "w", encoding="utf-8") as f:
                    json_lib.dump(combined_json, f, ensure_ascii=False, indent=2)
                logger.info(f"ğŸ“„ JSON å·²ä¿å­˜: {json_file}")

            return {
                "success": True,
                "output_path": str(output_path),
                "markdown": markdown_text,
                "markdown_file": str(markdown_file),
                "json_file": str(json_file),
            }

        except Exception as e:
            logger.error(f"âŒ OCR è§£æå¤±è´¥: {e}")
            import traceback
            logger.debug(traceback.format_exc())
            raise

        finally:
            self.cleanup()

# å…¨å±€å•ä¾‹
_engine = None

def get_engine(vllm_api_base: str = "http://localhost:17300/v1", model_name: str = "PaddleOCR-VL-1.5-0.9B") -> PaddleOCRVLVLLMEngine:
    global _engine
    if _engine is None:
        _engine = PaddleOCRVLVLLMEngine(vllm_api_base=vllm_api_base, model_name=model_name)
    return _engine
