"""
MinerU Tianshu - API Server
å¤©æ¢ API æœåŠ¡å™¨

ä¼ä¸šçº§ AI æ•°æ®é¢„å¤„ç†å¹³å°
æ”¯æŒæ–‡æ¡£ã€å›¾ç‰‡ã€éŸ³é¢‘ã€è§†é¢‘ç­‰å¤šæ¨¡æ€æ•°æ®å¤„ç†
æä¾› RESTful API æ¥å£ç”¨äºä»»åŠ¡æäº¤ã€æŸ¥è¯¢å’Œç®¡ç†
ä¼ä¸šçº§è®¤è¯æˆæƒ: JWT Token + API Key + SSO
"""

import json
import os
import re
import uuid
import mimetypes  # âœ… [æ–°å¢] ç”¨äºè‡ªåŠ¨è¯†åˆ«æ–‡ä»¶ç±»å‹
from datetime import datetime
from pathlib import Path
from typing import Optional
from urllib.parse import quote, unquote

import uvicorn
from fastapi import FastAPI, UploadFile, File, Form, HTTPException, Query, Depends, APIRouter
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, FileResponse
from loguru import logger

# å¯¼å…¥è®¤è¯æ¨¡å—
from auth import (
    User,
    Permission,
    get_current_active_user,
    require_permission,
)
from auth.auth_db import AuthDB
from auth.routes import router as auth_router
from task_db import TaskDB

# âœ… [ä¼˜åŒ–] é¢„æ³¨å†Œ MIME ç±»å‹ï¼Œé˜²æ­¢ç²¾ç®€ç¯å¢ƒè¯†åˆ«å¤±è´¥å¯¼è‡´æµè§ˆå™¨å¼ºåˆ¶ä¸‹è½½
mimetypes.add_type('application/pdf', '.pdf')
mimetypes.add_type('image/png', '.png')
mimetypes.add_type('image/jpeg', '.jpg')
mimetypes.add_type('image/jpeg', '.jpeg')
mimetypes.add_type('text/markdown', '.md')
mimetypes.add_type('application/json', '.json')

# åˆå§‹åŒ– FastAPI åº”ç”¨
app = FastAPI(
    title="MinerU Tianshu API",
    description="å¤©æ¢ - ä¼ä¸šçº§ AI æ•°æ®é¢„å¤„ç†å¹³å° | æ”¯æŒæ–‡æ¡£ã€å›¾ç‰‡ã€éŸ³é¢‘ã€è§†é¢‘ç­‰å¤šæ¨¡æ€æ•°æ®å¤„ç† | ä¼ä¸šçº§è®¤è¯æˆæƒ",
    version="2.0.0",
    # ä¸è®¾ç½® serversï¼Œè®© FastAPI è‡ªåŠ¨æ ¹æ®è¯·æ±‚çš„ Host ç”Ÿæˆ
)

# æ·»åŠ  CORS ä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# è·å–é¡¹ç›®æ ¹ç›®å½•ï¼ˆbackend çš„çˆ¶ç›®å½•ï¼‰
PROJECT_ROOT = Path(__file__).parent.parent

# åˆå§‹åŒ–æ•°æ®åº“
# ç¡®ä¿ä½¿ç”¨ç¯å¢ƒå˜é‡ä¸­çš„æ•°æ®åº“è·¯å¾„ï¼ˆä¸ Worker ä¿æŒä¸€è‡´ï¼‰
db_path_env = os.getenv("DATABASE_PATH")
if db_path_env:
    db_path = str(Path(db_path_env).resolve())
    logger.info(f"ğŸ“Š API Server using DATABASE_PATH: {db_path_env} -> {db_path}")
    db = TaskDB(db_path)
else:
    logger.warning("âš ï¸  DATABASE_PATH not set in API Server, using default")
    # Docker ç¯å¢ƒ: /app/data/db/mineru_tianshu.db
    # æœ¬åœ°ç¯å¢ƒ: ./data/db/mineru_tianshu.db
    default_db_path = PROJECT_ROOT / "data" / "db" / "mineru_tianshu.db"
    default_db_path.parent.mkdir(parents=True, exist_ok=True)
    db_path = str(default_db_path.resolve())
    logger.info(f"ğŸ“Š Using default database path: {db_path}")
    db = TaskDB(db_path)
auth_db = AuthDB()

# æ³¨å†Œè®¤è¯è·¯ç”±
app.include_router(auth_router)

# ==============================================================================
# ç›®å½•é…ç½® (Output & Upload)
# ==============================================================================

# 1. é…ç½®è¾“å‡ºç›®å½•ï¼ˆä½¿ç”¨å…±äº«ç›®å½•ï¼ŒDocker ç¯å¢ƒå¯è®¿é—®ï¼‰
output_path_env = os.getenv("OUTPUT_PATH")
if output_path_env:
    OUTPUT_DIR = Path(output_path_env).resolve()
else:
    # Docker ç¯å¢ƒ: /app/output
    # æœ¬åœ°ç¯å¢ƒ: ./data/output
    OUTPUT_DIR = (PROJECT_ROOT / "data" / "output").resolve()
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
logger.info(f"ğŸ“ Output directory: {OUTPUT_DIR}")

# 2. é…ç½®ä¸Šä¼ ç›®å½• (ä¿®æ”¹é»˜è®¤ä¸º input)
upload_path_env = os.getenv("UPLOAD_PATH")
if upload_path_env:
    UPLOAD_DIR = Path(upload_path_env).resolve()
else:
    # Docker ç¯å¢ƒ: /app/input (å¦‚æœä¸è®¾ç½®ç¯å¢ƒå˜é‡)
    # æœ¬åœ°ç¯å¢ƒ: ./input (é¡¹ç›®æ ¹ç›®å½•ä¸‹çš„ input ç›®å½•)
    UPLOAD_DIR = (PROJECT_ROOT / "input").resolve()
UPLOAD_DIR.mkdir(parents=True, exist_ok=True)
logger.info(f"ğŸ“ Upload directory: {UPLOAD_DIR}")


# æ³¨æ„ï¼šæ­¤å‡½æ•°å·²åºŸå¼ƒï¼ŒWorker å·²è‡ªåŠ¨ä¸Šä¼ å›¾ç‰‡åˆ° RustFS å¹¶æ›¿æ¢ URL
# ä¿ç•™æ­¤å‡½æ•°ä»…ç”¨äºå‘åå…¼å®¹ï¼ˆå¤„ç†æ—§ä»»åŠ¡æˆ– RustFS å¤±è´¥çš„æƒ…å†µï¼‰
def process_markdown_images_legacy(md_content: str, image_dir: Path, result_path: str):
    """
    ã€å‘åå…¼å®¹ã€‘å¤„ç† Markdown ä¸­çš„å›¾ç‰‡å¼•ç”¨

    Worker å·²è‡ªåŠ¨ä¸Šä¼ å›¾ç‰‡åˆ° RustFS å¹¶æ›¿æ¢ URLï¼Œæ­¤å‡½æ•°ä»…ç”¨äºå‘åå…¼å®¹ã€‚
    å¦‚æœæ£€æµ‹åˆ°å›¾ç‰‡è·¯å¾„ä¸æ˜¯ URLï¼Œåˆ™è½¬æ¢ä¸ºæœ¬åœ°é™æ€æ–‡ä»¶æœåŠ¡ URLã€‚
    """
    # æ£€æŸ¥æ˜¯å¦å·²ç»åŒ…å« RustFS URL
    if "http://" in md_content or "https://" in md_content:
        logger.debug("âœ… Markdown already contains URLs (RustFS uploaded)")
        return md_content

    # å¦‚æœæ²¡æœ‰å›¾ç‰‡ç›®å½•ï¼Œç›´æ¥è¿”å›
    if not image_dir.exists():
        logger.debug("â„¹ï¸  No images directory, skipping processing")
        return md_content

    # å…¼å®¹æ¨¡å¼ï¼šè½¬æ¢ç›¸å¯¹è·¯å¾„ä¸ºæœ¬åœ° URL
    logger.warning("âš ï¸  Images not uploaded to RustFS, using local URLs (legacy mode)")

    def replace_image_path(match):
        """æ›¿æ¢å›¾ç‰‡è·¯å¾„ä¸ºæœ¬åœ° URL"""
        full_match = match.group(0)
        # æå–å›¾ç‰‡è·¯å¾„ï¼ˆMarkdown æˆ– HTMLï¼‰
        if "![" in full_match:
            # Markdown: ![alt](path)
            image_path = match.group(2)
            alt_text = match.group(1)
        else:
            # HTML: <img src="path">
            image_path = match.group(2)
            alt_text = "Image"

        # å¦‚æœå·²ç»æ˜¯ URLï¼Œè·³è¿‡
        if image_path.startswith("http"):
            return full_match

        # ç”Ÿæˆæœ¬åœ°é™æ€æ–‡ä»¶ URL
        try:
            image_filename = Path(image_path).name
            output_dir_str = str(OUTPUT_DIR).replace("\\", "/")
            result_path_str = result_path.replace("\\", "/")

            if result_path_str.startswith(output_dir_str):
                relative_path = result_path_str[len(output_dir_str) :].lstrip("/")
                # âœ… [ä¿®å¤] url ç¼–ç éœ€ä¿ç•™æ­£æ–œæ ï¼Œé˜²æ­¢ 404
                encoded_relative_path = quote(relative_path, safe="/")
                encoded_filename = quote(image_filename, safe="/")
                
                # ç»Ÿä¸€ä½¿ç”¨ /api/v1 å‰ç¼€ï¼Œç¨åé€šè¿‡ Router æ³¨å†Œå…¼å®¹ Nginx
                static_url = f"/api/v1/files/output/{encoded_relative_path}/images/{encoded_filename}"

                # è¿”å›æ›¿æ¢åçš„å†…å®¹
                if "![" in full_match:
                    return f"![{alt_text}]({static_url})"
                else:
                    return full_match.replace(image_path, static_url)
        except Exception as e:
            logger.error(f"âŒ Failed to generate local URL: {e}")

        return full_match

    try:
        # åŒ¹é… Markdown å’Œ HTML å›¾ç‰‡
        md_pattern = r"!\[([^\]]*)\]\(([^)]+)\)"
        html_pattern = r'<img\s+([^>]*\s+)?src="([^"]+)"([^>]*)>'

        new_content = re.sub(md_pattern, replace_image_path, md_content)
        new_content = re.sub(html_pattern, replace_image_path, new_content)
        return new_content
    except Exception as e:
        logger.error(f"âŒ Failed to process images: {e}")
        return md_content


@app.get("/", tags=["ç³»ç»Ÿä¿¡æ¯"])
async def root():
    """APIæ ¹è·¯å¾„"""
    return {
        "service": "MinerU Tianshu",
        "version": "2.0.0",
        "description": "å¤©æ¢ - ä¼ä¸šçº§ AI æ•°æ®é¢„å¤„ç†å¹³å°",
        "features": "æ–‡æ¡£ã€å›¾ç‰‡ã€éŸ³é¢‘ã€è§†é¢‘ç­‰å¤šæ¨¡æ€æ•°æ®å¤„ç†",
        "docs": "/docs",
    }


# ============================================================================
# åˆ›å»º API Router (æ ¸å¿ƒä¿®å¤ï¼šè§£å†³ Nginx è·¯å¾„å‰¥ç¦»é—®é¢˜)
# ============================================================================
# æ‰€æœ‰çš„ä¸šåŠ¡æ¥å£éƒ½æŒ‚è½½åˆ° router ä¸Šï¼Œç„¶åæ³¨å†Œä¸¤æ¬¡ï¼š
# 1. /api/v1 (å®Œæ•´è·¯å¾„)
# 2. /v1 (Nginx å‰¥ç¦»åè·¯å¾„)
router = APIRouter()


@router.post("/tasks/submit", tags=["ä»»åŠ¡ç®¡ç†"])
async def submit_task(
    file: UploadFile = File(..., description="æ–‡ä»¶: PDF/å›¾ç‰‡/Office/HTML/éŸ³é¢‘/è§†é¢‘ç­‰å¤šç§æ ¼å¼"),
    backend: str = Form(
        "auto",
        description="å¤„ç†åç«¯: pipeline, hybrid-auto-engine, vlm-auto-engine, hybrid-http-client, vlm-http-client, paddleocr-vl, etc.",
    ),
    lang: str = Form("auto", description="è¯­è¨€: ch/en/auto..."),
    method: str = Form("auto", description="è§£ææ–¹æ³•: auto/txt/ocr"),
    formula_enable: bool = Form(True, description="æ˜¯å¦å¯ç”¨å…¬å¼è¯†åˆ«"),
    table_enable: bool = Form(True, description="æ˜¯å¦å¯ç”¨è¡¨æ ¼è¯†åˆ«"),
    priority: int = Form(0, description="ä¼˜å…ˆçº§ï¼Œæ•°å­—è¶Šå¤§è¶Šä¼˜å…ˆ"),
    
    # === æ–°å¢å‚æ•° ===
    start_page: Optional[int] = Form(None, description="èµ·å§‹é¡µç ï¼ˆä»0å¼€å§‹ï¼‰"),
    end_page: Optional[int] = Form(None, description="ç»“æŸé¡µç "),
    # force_ocr ä¿ç•™å…¼å®¹ï¼Œä½†å»ºè®®ä½¿ç”¨ method='ocr'
    force_ocr: bool = Form(False, description="[å…¼å®¹æ—§ç‰ˆ] æ˜¯å¦å¼ºåˆ¶ä½¿ç”¨OCR"),
    
    # è¿œç¨‹æœåŠ¡å‚æ•°
    server_url: Optional[str] = Form(None, description="è¿œç¨‹æœåŠ¡å™¨åœ°å€ (ä»… Client æ¨¡å¼éœ€è¦)"),

    # MinerU è¯¦ç»†è°ƒè¯•/è¾“å‡ºé€‰é¡¹ (å¯¹åº”å‰ç«¯ Advanced Settings)
    draw_layout_bbox: bool = Form(True, description="ç»˜åˆ¶å¸ƒå±€è¾¹æ¡† (_layout.pdf)"),
    draw_span_bbox: bool = Form(True, description="ç»˜åˆ¶æ–‡æœ¬è¾¹æ¡† (_span.pdf)"),
    dump_markdown: bool = Form(True, description="è¾“å‡º Markdown"),
    dump_middle_json: bool = Form(True, description="è¾“å‡ºä¸­é—´ JSON"),
    dump_model_output: bool = Form(True, description="è¾“å‡ºæ¨¡å‹åŸå§‹æ•°æ®"),
    dump_content_list: bool = Form(True, description="è¾“å‡ºå†…å®¹åˆ—è¡¨"),
    dump_orig_pdf: bool = Form(True, description="ä¿å­˜åŸå§‹/æˆªå– PDF"),
    
    # æ—§ç‰ˆå‚æ•°å…¼å®¹ (Worker ä¼šåšæ˜ å°„)
    draw_layout: bool = Form(True, description="[å…¼å®¹æ—§ç‰ˆ] æ˜¯å¦ç»˜åˆ¶å¸ƒå±€è¾¹æ¡†"),
    draw_span: bool = Form(True, description="[å…¼å®¹æ—§ç‰ˆ] æ˜¯å¦ç»˜åˆ¶æ–‡æœ¬Spanè¾¹æ¡†"),
    
    # è§†é¢‘å¤„ç†ä¸“ç”¨å‚æ•°
    keep_audio: bool = Form(False, description="è§†é¢‘å¤„ç†æ—¶æ˜¯å¦ä¿ç•™æå–çš„éŸ³é¢‘æ–‡ä»¶"),
    enable_keyframe_ocr: bool = Form(False, description="æ˜¯å¦å¯ç”¨è§†é¢‘å…³é”®å¸§OCRè¯†åˆ«ï¼ˆå®éªŒæ€§åŠŸèƒ½ï¼‰"),
    ocr_backend: str = Form("paddleocr-vl", description="å…³é”®å¸§OCRå¼•æ“: paddleocr-vl"),
    keep_keyframes: bool = Form(False, description="æ˜¯å¦ä¿ç•™æå–çš„å…³é”®å¸§å›¾åƒ"),
    
    # éŸ³é¢‘å¤„ç†ä¸“ç”¨å‚æ•°
    enable_speaker_diarization: bool = Form(
        False, description="æ˜¯å¦å¯ç”¨è¯´è¯äººåˆ†ç¦»ï¼ˆéŸ³é¢‘å¤šè¯´è¯äººè¯†åˆ«ï¼Œéœ€è¦é¢å¤–ä¸‹è½½ Paraformer æ¨¡å‹ï¼‰"
    ),
    
    # æ°´å°å»é™¤ä¸“ç”¨å‚æ•°
    remove_watermark: bool = Form(False, description="æ˜¯å¦å¯ç”¨æ°´å°å»é™¤ï¼ˆæ”¯æŒ PDF/å›¾ç‰‡ï¼‰"),
    watermark_conf_threshold: float = Form(0.35, description="æ°´å°æ£€æµ‹ç½®ä¿¡åº¦é˜ˆå€¼ï¼ˆ0.0-1.0ï¼Œæ¨è 0.35ï¼‰"),
    watermark_dilation: int = Form(10, description="æ°´å°æ©ç è†¨èƒ€å¤§å°ï¼ˆåƒç´ ï¼Œæ¨è 10ï¼‰"),
    
    # Office æ–‡ä»¶è½¬ PDF å‚æ•°
    convert_office_to_pdf: bool = Form(
        False,
        description="æ˜¯å¦å°† Office æ–‡ä»¶è½¬æ¢ä¸º PDF åå†å¤„ç†ï¼ˆå›¾ç‰‡æå–æ›´å®Œæ•´ï¼Œä½†é€Ÿåº¦è¾ƒæ…¢ï¼‰"
    ),
    
    # è®¤è¯ä¾èµ–
    current_user: User = Depends(require_permission(Permission.TASK_SUBMIT)),
):
    """
    æäº¤æ–‡æ¡£è§£æä»»åŠ¡
    """
    try:
        # ç”Ÿæˆå”¯ä¸€çš„æ–‡ä»¶åï¼ˆé¿å…å†²çªï¼‰
        unique_filename = f"{uuid.uuid4().hex}_{file.filename}"
        temp_file_path = UPLOAD_DIR / unique_filename

        # æµå¼å†™å…¥æ–‡ä»¶åˆ°ç£ç›˜ï¼Œé¿å…é«˜å†…å­˜ä½¿ç”¨
        with open(temp_file_path, "wb") as temp_file:
            while True:
                chunk = await file.read(1 << 23)  # 8MB chunks
                if not chunk:
                    break
                temp_file.write(chunk)

        # æ„å»ºå¤„ç†é€‰é¡¹
        options = {
            "lang": lang,
            "method": method,
            "formula_enable": formula_enable,
            "table_enable": table_enable,
            "start_page": start_page,
            "end_page": end_page,
            "force_ocr": force_ocr,
            "server_url": server_url,
            "draw_layout_bbox": draw_layout_bbox,
            "draw_span_bbox": draw_span_bbox,
            "dump_markdown": dump_markdown,
            "dump_middle_json": dump_middle_json,
            "dump_model_output": dump_model_output,
            "dump_content_list": dump_content_list,
            "dump_orig_pdf": dump_orig_pdf,
            "draw_layout": draw_layout,
            "draw_span": draw_span,
            "keep_audio": keep_audio,
            "enable_keyframe_ocr": enable_keyframe_ocr,
            "ocr_backend": ocr_backend,
            "keep_keyframes": keep_keyframes,
            "enable_speaker_diarization": enable_speaker_diarization,
            "remove_watermark": remove_watermark,
            "watermark_conf_threshold": watermark_conf_threshold,
            "watermark_dilation": watermark_dilation,
            "convert_office_to_pdf": convert_office_to_pdf,
        }

        # âœ… [ä¿®å¤ Bug 3]ï¼šè‡ªåŠ¨æ£€æµ‹ç¯å¢ƒå˜é‡å¼€å¯ RustFSï¼Œé»˜è®¤ä¼ é€’ç»™ Worker
        options["upload_images"] = os.getenv("RUSTFS_ENABLED", "true").lower() == "true"

        # åˆ›å»ºä»»åŠ¡
        task_id = db.create_task(
            file_name=file.filename,
            file_path=str(temp_file_path),
            backend=backend,
            options=options,
            priority=priority,
            user_id=current_user.user_id,
        )

        logger.info(f"âœ… Task submitted: {task_id} - {file.filename}")
        return {
            "success": True,
            "task_id": task_id,
            "status": "pending",
            "message": "Task submitted successfully",
            "file_name": file.filename,
            "user_id": current_user.user_id,
            "created_at": datetime.now().isoformat(),
        }

    except Exception as e:
        logger.error(f"âŒ Failed to submit task: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/tasks/{task_id}", tags=["ä»»åŠ¡ç®¡ç†"])
async def get_task_status(
    task_id: str,
    upload_images: bool = Query(False, description="ã€å·²åºŸå¼ƒã€‘å›¾ç‰‡å·²è‡ªåŠ¨ä¸Šä¼ åˆ° RustFS"),
    format: str = Query("markdown", description="è¿”å›æ ¼å¼: markdown(é»˜è®¤)/json/both"),
    current_user: User = Depends(get_current_active_user),
):
    """
    æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€å’Œè¯¦æƒ…
    """
    task = db.get_task(task_id)

    if not task:
        raise HTTPException(status_code=404, detail="Task not found")

    # æƒé™æ£€æŸ¥
    if not current_user.has_permission(Permission.TASK_VIEW_ALL):
        if task.get("user_id") != current_user.user_id:
            raise HTTPException(status_code=403, detail="Permission denied: You can only view your own tasks")

    # === æ„å»ºæºæ–‡ä»¶è®¿é—® URL ===
    source_url = None
    if task.get("file_path"):
        try:
            source_filename = Path(task["file_path"]).name
            encoded_source_filename = quote(source_filename)
            # å§‹ç»ˆè¿”å›å®Œæ•´è·¯å¾„ /api/v1/... å‰ç«¯ä½¿ç”¨æ–¹ä¾¿
            source_url = f"/api/v1/files/upload/{encoded_source_filename}"
        except Exception as e:
            logger.warning(f"Failed to generate source_url: {e}")

    response = {
        "success": True,
        "task_id": task_id,
        "status": task["status"],
        "file_name": task["file_name"],
        "source_url": source_url,
        "backend": task["backend"],
        "priority": task["priority"],
        "error_message": task["error_message"],
        "created_at": task["created_at"],
        "started_at": task["started_at"],
        "completed_at": task["completed_at"],
        "user_id": task.get("user_id"),
    }

    if not task.get("is_parent"):
        response["worker_id"] = task.get("worker_id")
        response["retry_count"] = task.get("retry_count")

    if task.get("is_parent"):
        child_count = task.get("child_count", 0)
        child_completed = task.get("child_completed", 0)
        response["is_parent"] = True
        response["subtask_progress"] = {
            "total": child_count,
            "completed": child_completed,
            "percentage": round(child_completed / child_count * 100, 1) if child_count > 0 else 0,
        }
        try:
            children = db.get_child_tasks(task_id)
            response["subtasks"] = [
                {
                    "task_id": child["task_id"],
                    "status": child["status"],
                    "chunk_info": json.loads(child.get("options", "{}")).get("chunk_info"),
                    "error_message": child.get("error_message"),
                }
                for child in children
            ]
        except Exception as e:
            logger.warning(f"âš ï¸  Failed to load subtasks: {e}")

    if task["status"] == "completed":
        if not task["result_path"]:
            response["data"] = None
            response["message"] = "Task completed but result files have been cleaned up"
            return response

        result_dir = Path(task["result_path"])
        if result_dir.exists():
            md_files = list(result_dir.rglob("*.md"))
            json_files = [
                f for f in result_dir.rglob("*.json")
                if not f.parent.name.startswith("page_")
                and (f.name in ["content.json", "result.json"] or "_content_list.json" in f.name)
            ]
            
            if md_files or json_files:
                try:
                    response["data"] = {}
                    response["data"]["json_available"] = len(json_files) > 0
                    
                    pdf_files = list(result_dir.rglob("*.pdf"))
                    preview_pdf = None
                    for pdf in pdf_files:
                        if "_layout.pdf" in pdf.name:
                            preview_pdf = pdf
                            break
                    if not preview_pdf:
                         for pdf in pdf_files:
                             if "_span.pdf" in pdf.name:
                                 preview_pdf = pdf
                                 break
                    if not preview_pdf:
                        for pdf in pdf_files:
                            if not pdf.name.startswith("page_"):
                                preview_pdf = pdf
                                break

                    if preview_pdf:
                        try:
                             rel_path = preview_pdf.relative_to(OUTPUT_DIR)
                             encoded_path = quote(str(rel_path).replace("\\", "/"), safe="/")
                             response["data"]["pdf_path"] = encoded_path
                        except ValueError:
                             pass

                    if format in ["markdown", "both"] and md_files:
                        md_file = None
                        for f in md_files:
                            if f.name == "result.md":
                                md_file = f
                                break
                        if not md_file:
                            md_file = md_files[0]

                        image_dir = md_file.parent / "images"
                        with open(md_file, "r", encoding="utf-8") as f:
                            md_content = f.read()

                        if image_dir.exists() and ("http://" not in md_content and "https://" not in md_content):
                            md_content = process_markdown_images_legacy(md_content, image_dir, task["result_path"])

                        response["data"]["markdown_file"] = md_file.name
                        response["data"]["content"] = md_content
                        response["data"]["has_images"] = image_dir.exists()

                    if format in ["json", "both"] and json_files:
                        import json as json_lib
                        json_file = json_files[0]
                        try:
                            with open(json_file, "r", encoding="utf-8") as f:
                                json_content = json_lib.load(f)
                            response["data"]["json_file"] = json_file.name
                            response["data"]["json_content"] = json_content
                        except Exception as json_e:
                            logger.warning(f"âš ï¸  Failed to load JSON: {json_e}")
                    elif format == "json" and not json_files:
                        response["data"]["message"] = "JSON format not available for this backend"

                    if not response["data"]:
                        response["data"] = None

                except Exception as e:
                    logger.error(f"âŒ Failed to read content: {e}")
                    response["data"] = None
        else:
            logger.error(f"âŒ Result directory does not exist: {result_dir}")

    return response


@router.delete("/tasks/{task_id}", tags=["ä»»åŠ¡ç®¡ç†"])
async def cancel_task(task_id: str, current_user: User = Depends(get_current_active_user)):
    """
    å–æ¶ˆä»»åŠ¡ï¼ˆä»…é™ pending çŠ¶æ€ï¼‰
    """
    task = db.get_task(task_id)

    if not task:
        raise HTTPException(status_code=404, detail="Task not found")

    if not current_user.has_permission(Permission.TASK_DELETE_ALL):
        if task.get("user_id") != current_user.user_id:
            raise HTTPException(status_code=403, detail="Permission denied: You can only cancel your own tasks")

    if task["status"] == "pending":
        db.update_task_status(task_id, "cancelled")
        file_path = Path(task["file_path"])
        if file_path.exists():
            file_path.unlink()
        logger.info(f"â¹ï¸  Task cancelled: {task_id} by user {current_user.username}")
        return {"success": True, "message": "Task cancelled successfully"}
    else:
        raise HTTPException(status_code=400, detail=f"Cannot cancel task in {task['status']} status")


@router.get("/queue/stats", tags=["é˜Ÿåˆ—ç®¡ç†"])
async def get_queue_stats(current_user: User = Depends(require_permission(Permission.QUEUE_VIEW))):
    """
    è·å–é˜Ÿåˆ—ç»Ÿè®¡ä¿¡æ¯
    """
    stats = db.get_queue_stats()
    return {
        "success": True,
        "stats": stats,
        "total": sum(stats.values()),
        "timestamp": datetime.now().isoformat(),
        "user": current_user.username,
    }


@router.get("/queue/tasks", tags=["é˜Ÿåˆ—ç®¡ç†"])
async def list_tasks(
    status: Optional[str] = Query(None, description="ç­›é€‰çŠ¶æ€"),
    limit: int = Query(100, description="è¿”å›æ•°é‡é™åˆ¶", le=1000),
    page: int = Query(1, ge=1, description="é¡µç "),  
    page_size: int = Query(20, ge=1, le=100, description="æ¯é¡µæ•°é‡"), 
    backend: Optional[str] = Query(None, description="ç­›é€‰åç«¯å¼•æ“"), 
    search: Optional[str] = Query(None, description="æœç´¢æ–‡ä»¶åæˆ–ä»»åŠ¡ID"), 
    current_user: User = Depends(get_current_active_user),
):
    """
    è·å–ä»»åŠ¡åˆ—è¡¨
    """
    can_view_all = current_user.has_permission(Permission.TASK_VIEW_ALL)
    conditions = []
    params = []

    if not can_view_all:
        conditions.append("user_id = ?")
        params.append(current_user.user_id)

    if status:
        conditions.append("status = ?")
        params.append(status)
    if backend:
        conditions.append("backend = ?")
        params.append(backend)
    
    if search:
        search = search.strip()
        conditions.append("(file_name LIKE ? OR task_id = ?)")
        params.append(f"%{search}%")
        params.append(search)

    where_clause = " WHERE " + " AND ".join(conditions) if conditions else ""
    offset = (page - 1) * page_size

    with db.get_cursor() as cursor:
        count_sql = f"SELECT COUNT(*) FROM tasks{where_clause}"
        cursor.execute(count_sql, params)
        total = cursor.fetchone()[0]

        query_params = params + [page_size, offset]
        data_sql = f"""
            SELECT * FROM tasks
            {where_clause}
            ORDER BY created_at DESC
            LIMIT ? OFFSET ?
        """
        cursor.execute(data_sql, query_params)
        tasks = [dict(row) for row in cursor.fetchall()]

    return {
        "success": True, 
        "total": total,
        "page": page,
        "page_size": page_size,
        "count": len(tasks),
        "tasks": tasks, 
        "can_view_all": can_view_all
    }


@router.post("/admin/cleanup", tags=["ç³»ç»Ÿç®¡ç†"])
async def cleanup_old_tasks(
    days: int = Query(7, description="æ¸…ç†Nå¤©å‰çš„ä»»åŠ¡"),
    current_user: User = Depends(require_permission(Permission.QUEUE_MANAGE)),
):
    """
    æ¸…ç†æ—§ä»»åŠ¡ï¼ˆç®¡ç†æ¥å£ï¼‰
    """
    deleted_count = db.cleanup_old_task_records(days)
    logger.info(f"ğŸ§¹ Cleaned up {deleted_count} old tasks by {current_user.username}")
    return {
        "success": True,
        "deleted_count": deleted_count,
        "message": f"Cleaned up {deleted_count} tasks older than {days} days",
    }


@router.post("/admin/reset-stale", tags=["ç³»ç»Ÿç®¡ç†"])
async def reset_stale_tasks(
    timeout_minutes: int = Query(60, description="è¶…æ—¶æ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰"),
    current_user: User = Depends(require_permission(Permission.QUEUE_MANAGE)),
):
    """
    é‡ç½®è¶…æ—¶çš„ processing ä»»åŠ¡ï¼ˆç®¡ç†æ¥å£ï¼‰
    """
    reset_count = db.reset_stale_tasks(timeout_minutes)
    logger.info(f"ğŸ”„ Reset {reset_count} stale tasks by {current_user.username}")
    return {
        "success": True,
        "reset_count": reset_count,
        "message": f"Reset tasks processing for more than {timeout_minutes} minutes",
    }


@router.get("/engines", tags=["ç³»ç»Ÿä¿¡æ¯"])
async def list_engines():
    """
    åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„å¤„ç†å¼•æ“
    """
    engines = {
        "document": [
            {
                "name": "pipeline",
                "display_name": "Standard Pipeline (é€šç”¨ç®¡é“)",
                "description": "åŸºäº PDF-Extract-Kit çš„ä¼ ç»Ÿå¤šæ¨¡å‹ç®¡é“ï¼Œé€Ÿåº¦å¿«ï¼Œæ— å¹»è§‰ï¼Œé€‚åˆå¤§å¤šæ•°æ–‡æ¡£ã€‚",
                "supported_formats": [".pdf", ".png", ".jpg", ".jpeg"],
            },
            {
                "name": "vlm-auto-engine",
                "display_name": "MinerU 2.5 VLM (è§†è§‰å¤§æ¨¡å‹)",
                "description": "åŸºäº MinerU 2.5 (1.2B) è§†è§‰æ¨¡å‹ï¼Œæ“…é•¿å¤„ç†å¤æ‚æ’ç‰ˆã€å›¾è¡¨å’Œéæ ‡å‡†æ–‡æ¡£ã€‚",
                "supported_formats": [".pdf", ".png", ".jpg", ".jpeg"],
            },
            {
                "name": "hybrid-auto-engine",
                "display_name": "Hybrid High-Precision (é«˜ç²¾åº¦æ··åˆ)",
                "description": "ç»“åˆ Pipeline çš„ç¨³å®šæ€§ä¸ VLM çš„ç†è§£èƒ½åŠ›ï¼Œæä¾›æœ€é«˜ç²¾åº¦çš„è§£ææ•ˆæœã€‚",
                "supported_formats": [".pdf", ".png", ".jpg", ".jpeg"],
            },
        ],
        "ocr": [],
        "audio": [],
        "video": [],
        "format": [],
        "office": [
            {
                "name": "MarkItDown (å¿«é€Ÿ)",
                "value": "auto",
                "description": "Office æ–‡æ¡£å’Œæ–‡æœ¬æ–‡ä»¶è½¬æ¢å¼•æ“ï¼ˆå¿«é€Ÿä½†å›¾ç‰‡æå–å¯èƒ½ä¸å®Œæ•´ï¼‰",
                "supported_formats": [".docx", ".xlsx", ".pptx", ".doc", ".xls", ".ppt", ".html", ".txt", ".csv"],
            },
            {
                "name": "LibreOffice + MinerU (å®Œæ•´)",
                "value": "auto",
                "description": "å°† Office æ–‡ä»¶è½¬ä¸º PDF åä½¿ç”¨ MinerU å¤„ç†ï¼ˆæ…¢ä½†å›¾ç‰‡æå–å®Œæ•´ï¼‰",
                "supported_formats": [".docx", ".xlsx", ".pptx", ".doc", ".xls", ".ppt"],
            }
        ],
    }

    import importlib.util

    if importlib.util.find_spec("paddleocr_vl") is not None:
        engines["ocr"].append({"name": "paddleocr_vl", "display_name": "PaddleOCR-VL v1.5 (0.9B)", "supported_formats": [".pdf", ".png", ".jpg", ".jpeg"]})

    if importlib.util.find_spec("paddleocr_vl_vllm") is not None:
        engines["ocr"].append({"name": "paddleocr-vl-vllm", "display_name": "PaddleOCR-VL v1.5 (0.9B) (vLLM)", "supported_formats": [".pdf", ".png", ".jpg", ".jpeg"]})

    if importlib.util.find_spec("audio_engines") is not None:
        engines["audio"].append({"name": "sensevoice", "display_name": "SenseVoice", "supported_formats": [".wav", ".mp3", ".flac", ".m4a", ".ogg"]})

    if importlib.util.find_spec("video_engines") is not None:
        engines["video"].append({"name": "video", "display_name": "Video Processing", "supported_formats": [".mp4", ".avi", ".mkv", ".mov", ".flv", ".wmv"]})

    try:
        from format_engines import FormatEngineRegistry
        for engine_info in FormatEngineRegistry.list_engines():
            engines["format"].append({
                "name": engine_info["name"],
                "display_name": engine_info["name"].upper(),
                "description": engine_info["description"],
                "supported_formats": engine_info["extensions"],
            })
    except ImportError:
        pass

    return {
        "success": True,
        "engines": engines,
        "timestamp": datetime.now().isoformat(),
    }


@router.get("/health", tags=["ç³»ç»Ÿä¿¡æ¯"])
async def health_check():
    """
    å¥åº·æ£€æŸ¥æ¥å£
    """
    try:
        stats = db.get_queue_stats()
        return {
            "status": "healthy",
            "timestamp": datetime.now().isoformat(),
            "database": "connected",
            "queue_stats": stats,
        }
    except Exception as e:
        logger.error(f"Health check failed: {e}")
        return JSONResponse(status_code=503, content={"status": "unhealthy", "error": str(e)})


# ============================================================================
# è‡ªå®šä¹‰æ–‡ä»¶æœåŠ¡ï¼ˆç»Ÿä¸€æ¥å£ï¼Œæ”¯æŒ URL ç¼–ç ä¸ MIME è¯†åˆ«ï¼‰
# ============================================================================
@router.get("/files/output/{file_path:path}", tags=["æ–‡ä»¶æœåŠ¡"])
async def serve_output_file(file_path: str):
    """æä¾›è¾“å‡ºæ–‡ä»¶çš„è®¿é—®æœåŠ¡"""
    try:
        # è§£ç å¹¶ç§»é™¤å¼€å¤´çš„æ–œæ ï¼Œé˜²æ­¢ double slash æˆ– encoding é—®é¢˜
        decoded_path = unquote(file_path).lstrip("/")
        
        # æ‹¼æ¥å®Œæ•´è·¯å¾„
        full_path = (OUTPUT_DIR / decoded_path).resolve()
        
        logger.debug(f"ğŸ“¥ Serving output file: {full_path}")

        # é˜²æ­¢ç›®å½•ç©¿è¶Š
        if not full_path.is_relative_to(OUTPUT_DIR.resolve()) or not full_path.is_file():
            logger.warning(f"âŒ Access denied or file not found: {full_path}")
            raise HTTPException(status_code=404, detail="File not found or access denied")

        # è‡ªåŠ¨çŒœæµ‹ MIME ç±»å‹
        media_type, _ = mimetypes.guess_type(full_path)
        media_type = media_type or "application/octet-stream"

        # âœ… [ä¿®å¤ Bug 4] å¼ºåˆ¶æµè§ˆå™¨å†…è”é¢„è§ˆ (inline)ï¼Œä¸ä½¿ç”¨ filename å‚æ•°ä»¥å…è§¦å‘ attachment ä¸‹è½½
        headers = {
            "Content-Disposition": f"inline; filename*=utf-8''{quote(full_path.name)}"
        }
        
        return FileResponse(
            path=str(full_path), 
            media_type=media_type, 
            headers=headers
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ Error serving output file: {e}")
        raise HTTPException(status_code=500, detail="Internal server error")


@router.get("/files/upload/{file_path:path}", tags=["æ–‡ä»¶æœåŠ¡"])
async def serve_upload_file(file_path: str):
    """æä¾›ä¸Šä¼ æºæ–‡ä»¶çš„è®¿é—®æœåŠ¡"""
    try:
        # è§£ç å¹¶ç§»é™¤å¼€å¤´çš„æ–œæ 
        decoded_path = unquote(file_path).lstrip("/")
        
        # æ‹¼æ¥å®Œæ•´è·¯å¾„
        full_path = (UPLOAD_DIR / decoded_path).resolve()
        
        logger.debug(f"ğŸ“¥ Serving upload file: {full_path}")

        # é˜²æ­¢ç›®å½•ç©¿è¶Š
        if not full_path.is_relative_to(UPLOAD_DIR.resolve()) or not full_path.is_file():
            logger.warning(f"âŒ Access denied or file not found: {full_path}")
            raise HTTPException(status_code=404, detail="File not found or access denied")

        # è‡ªåŠ¨çŒœæµ‹ MIME ç±»å‹
        media_type, _ = mimetypes.guess_type(full_path)
        media_type = media_type or "application/octet-stream"

        # âœ… [ä¿®å¤ Bug 4] å¼ºåˆ¶æµè§ˆå™¨å†…è”é¢„è§ˆ (inline)ï¼Œä¸ä½¿ç”¨ filename å‚æ•°ä»¥å…è§¦å‘ attachment ä¸‹è½½
        headers = {
            "Content-Disposition": f"inline; filename*=utf-8''{quote(full_path.name)}"
        }

        return FileResponse(
            path=str(full_path), 
            media_type=media_type, 
            headers=headers
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ Error serving upload file: {e}")
        raise HTTPException(status_code=500, detail="Internal server error")


# ============================================================================
# æ³¨å†ŒåŒé‡è·¯ç”±
# ============================================================================
app.include_router(router, prefix="/api/v1")
app.include_router(router, prefix="/v1")


logger.info(f"ğŸ“ File service mounted: /api/v1/files/output -> {OUTPUT_DIR}")
logger.info(f"ğŸ“ File service mounted: /api/v1/files/upload -> {UPLOAD_DIR}")

if __name__ == "__main__":
    # ä»ç¯å¢ƒå˜é‡è¯»å–ç«¯å£ï¼Œé»˜è®¤ä¸º8000
    api_port = int(os.getenv("API_PORT", "8000"))

    logger.info("ğŸš€ Starting MinerU Tianshu API Server...")
    logger.info(f"ğŸ“– API Documentation: http://localhost:{api_port}/docs")

    uvicorn.run(app, host="0.0.0.0", port=api_port, log_level="info")
