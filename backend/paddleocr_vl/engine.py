"""
PaddleOCR-VL è§£æžå¼•æ“Ž (PaddleX v3 Wrapper)
å•ä¾‹æ¨¡å¼ï¼Œæ¯ä¸ªè¿›ç¨‹åªåŠ è½½ä¸€æ¬¡æ¨¡åž‹
æ”¯æŒè‡ªåŠ¨å¤šè¯­è¨€è¯†åˆ«ã€Markdown æ ¼å¼è¾“å‡º

å‚è€ƒæ–‡æ¡£ï¼šhttp://www.paddleocr.ai/main/version3.x/pipeline_usage/PaddleOCR-VL.html
"""

import os
import sys
import gc
import json
import time
import traceback
from pathlib import Path
from typing import Optional, Dict, Any
from threading import Lock
from loguru import logger

# å°è¯•å¯¼å…¥ paddle å’Œ paddlex
try:
    import paddle
    from paddlex import create_pipeline
    PADDLE_AVAILABLE = True
except ImportError:
    PADDLE_AVAILABLE = False
    logger.warning("âš ï¸ PaddlePaddle or PaddleX not installed. Please install: pip install paddlepaddle-gpu paddlex")

class PaddleOCRVLEngine:
    """
    PaddleOCR-VL è§£æžå¼•æ“Žï¼ˆåŸºäºŽ PaddleX v3ï¼‰

    ç‰¹æ€§ï¼š
    - å•ä¾‹æ¨¡å¼ï¼šç¡®ä¿è¿›ç¨‹å†…åªæœ‰ä¸€ä¸ªæ¨¡åž‹å®žä¾‹
    - æ˜¾å­˜ç®¡ç†ï¼šæ”¯æŒæŽ¨ç†åŽæ¸…ç†æ˜¾å­˜
    - æ ¼å¼æ”¯æŒï¼šè¾“å‡º Markdown å’Œ JSON
    - å‚æ•°æ”¯æŒï¼šæ”¯æŒ PaddleOCR-VL-1.5 çš„å…¨é‡å‚æ•°é…ç½®
    - å†…å­˜ä¼˜åŒ–ï¼šä½¿ç”¨ç”Ÿæˆå™¨æµå¼å¤„ç†é•¿æ–‡æ¡£ï¼Œé˜²æ­¢ OOM
    """

    _instance: Optional["PaddleOCRVLEngine"] = None
    _lock = Lock()
    _pipeline = None
    _initialized = False

    def __new__(cls, *args, **kwargs):
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
        return cls._instance

    def __init__(self, device: str = "cuda:0", model_name: str = "PaddleOCR-VL-1.5-0.9B"):
        if self._initialized:
            return

        with self._lock:
            if self._initialized:
                return

            self.device = device
            self.model_name = model_name
            self.gpu_id = 0

            # è§£æž GPU ID
            if "cuda" in device.lower():
                try:
                    parts = device.split(":")
                    if len(parts) > 1:
                        self.gpu_id = int(parts[-1])
                except ValueError:
                    logger.warning(f"âš ï¸ Invalid device format '{device}', defaulting to GPU 0")

            self._check_environment()
            
            self._initialized = True
            logger.info(f"ðŸ”§ PaddleOCR-VL Engine initialized (Model: {self.model_name}, Device: {self.device})")

    def _check_environment(self):
        """æ£€æŸ¥ GPU å’Œ Paddle çŽ¯å¢ƒ"""
        if not PADDLE_AVAILABLE:
            raise ImportError("PaddlePaddle environment is missing.")

        if not paddle.device.is_compiled_with_cuda():
            logger.error("âŒ PaddlePaddle is installed but NOT compiled with CUDA.")
            raise RuntimeError("PaddlePaddle CUDA version required.")

        try:
            gpu_name = paddle.device.cuda.get_device_name(self.gpu_id)
            logger.info(f"âœ… GPU Detected: {gpu_name}")
        except Exception:
            pass

    def _load_pipeline(self):
        """å»¶è¿ŸåŠ è½½ PaddleX Pipeline"""
        if self._pipeline is not None:
            return self._pipeline

        with self._lock:
            if self._pipeline is not None:
                return self._pipeline

            logger.info(f"ðŸ“¥ Loading PaddleOCR-VL Pipeline: {self.model_name}...")
            start_time = time.time()

            # è®¾ç½®è®¾å¤‡
            paddle.set_device(f"gpu:{self.gpu_id}")

            # ç¡®å®šæ¨¡åž‹è·¯å¾„ (ä¼˜å…ˆä½¿ç”¨æœ¬åœ°ç¼“å­˜)
            pipeline_source = self.model_name
            local_base = Path("/app/models/paddlex") / self.model_name
            pdx_home = os.environ.get("PADDLEX_HOME")

            if local_base.exists() and any(local_base.iterdir()):
                logger.info(f"ðŸ“‚ Using local model: {local_base}")
                pipeline_source = str(local_base)
            elif pdx_home:
                logger.info(f"ðŸ’¾ Using PADDLEX_HOME: {pdx_home}")
            
            try:
                # åˆ›å»º Pipeline
                self._pipeline = create_pipeline(
                    pipeline=pipeline_source,
                    device=f"gpu:{self.gpu_id}",
                    use_hpip=False 
                )
                
                logger.success(f"âœ… Pipeline loaded in {time.time() - start_time:.2f}s")
                return self._pipeline

            except Exception as e:
                logger.error(f"âŒ Failed to load pipeline: {e}")
                raise RuntimeError(f"PaddleOCR-VL load failed: {e}")

    def parse(self, file_path: str, output_path: str, **kwargs) -> Dict[str, Any]:
        """
        æ‰§è¡Œè§£æž

        Args:
            file_path: è¾“å…¥æ–‡ä»¶è·¯å¾„
            output_path: è¾“å‡ºç›®å½•
            **kwargs: æ”¯æŒ PaddleOCR-VL çš„æ‰€æœ‰å‚æ•° (æ”¯æŒé©¼å³°æˆ–ä¸‹åˆ’çº¿å‘½å)
        """
        file_path = Path(file_path)
        output_path = Path(output_path)
        output_path.mkdir(parents=True, exist_ok=True)

        logger.info(f"ðŸ¤– Processing: {file_path.name}")
        
        pipeline = self._load_pipeline()
        
        # å‚æ•°æ˜ å°„è¡¨ (API é©¼å³° -> PaddleX ä¸‹åˆ’çº¿)
        param_mapping = {
            # åŠŸèƒ½å¼€å…³
            "useDocOrientationClassify": "use_doc_orientation_classify",
            "useDocUnwarping": "use_doc_unwarping",
            "useLayoutDetection": "use_layout_parsing",
            "useChartRecognition": "use_chart_recognition",
            "useSealRecognition": "use_seal_recognition",
            "useOcrForImageBlock": "use_ocr_for_image_block",
            "layoutNms": "layout_nms",
            # åŽå¤„ç†å‚æ•°
            "markdownIgnoreLabels": "markdown_ignore_labels",
            "mergeTables": "merge_tables",
            "relevelTitles": "relevel_titles",
            "restructurePages": "restructure_pages",
            "layoutShapeMode": "layout_shape_mode",
            "minPixels": "min_pixels",
            "maxPixels": "max_pixels",
            # ç”Ÿæˆå‚æ•°
            "promptLabel": "prompt_label", 
            "temperature": "temperature",
            "topP": "top_p",
            "repetitionPenalty": "repetition_penalty"
        }

        # 1. è§„èŒƒåŒ–å‚æ•°å¹¶è¿‡æ»¤å¤©æž¢å…¶ä»–æ— å…³å‚æ•°
        # (åªä¼ é€’è¢« param_mapping è®°å½•çš„ PaddleX å‚æ•°ï¼Œé˜²æ­¢ predict æŠ¥é”™ TypeError: unexpected keyword argument)
        predict_params = {}
        for k, v in kwargs.items():
            if k in param_mapping:
                predict_params[param_mapping[k]] = v

        try:
            # =================================================================
            # åŠ¨æ€æ£€æŸ¥ pipeline æ˜¯å¦å…·å¤‡é¢„å¤„ç†èƒ½åŠ›
            # =================================================================
            has_preprocessor = hasattr(pipeline, "doc_preprocessor_pipeline") and pipeline.doc_preprocessor_pipeline is not None
            
            req_orientation = predict_params.get("use_doc_orientation_classify", False)
            req_unwarping = predict_params.get("use_doc_unwarping", False)

            # å¦‚æžœè¯·æ±‚äº†é¢„å¤„ç†åŠŸèƒ½ä½†æ¨¡åž‹ä¸æ”¯æŒï¼Œå¼ºåˆ¶å…³é—­å¹¶è­¦å‘Š
            if (req_orientation or req_unwarping) and not has_preprocessor:
                logger.warning("âš ï¸ è¯·æ±‚äº†æ–‡æ¡£çŸ«æ­£/åˆ†ç±»ï¼Œä½†æ¨¡åž‹ç¼ºå°‘é¢„å¤„ç†æ¨¡å—ã€‚å·²è‡ªåŠ¨ç¦ç”¨ä»¥é˜²æ­¢å´©æºƒã€‚")
                predict_params["use_doc_orientation_classify"] = False
                predict_params["use_doc_unwarping"] = False
            
            # é»˜è®¤å‚æ•°å…œåº•
            if "use_layout_parsing" not in predict_params:
                predict_params["use_layout_parsing"] = True
            if "use_doc_orientation_classify" not in predict_params:
                predict_params["use_doc_orientation_classify"] = False
            if "use_doc_unwarping" not in predict_params:
                predict_params["use_doc_unwarping"] = False

            # è®¾ç½®è¾“å…¥æ–‡ä»¶
            predict_params["input"] = str(file_path)

            # æ‰“å°æœ€ç»ˆå‚æ•° (æŽ’é™¤ input ä»¥é˜²æ—¥å¿—è¿‡é•¿)
            log_params = {k: v for k, v in predict_params.items() if k != "input"}
            logger.info(f"ðŸš€ å¼€å§‹æŽ¨ç† (å‚æ•°: {json.dumps(log_params, default=str, ensure_ascii=False)})")
            
            # æ‰§è¡ŒæŽ¨ç†
            # ã€æ€§èƒ½ä¼˜åŒ–ã€‘ä¸ä½¿ç”¨ list(output) å…¨éƒ¨åŠ è½½åˆ°å†…å­˜ï¼Œæ”¹ä¸ºç”Ÿæˆå™¨æµå¼å¤„ç†ï¼Œé˜²æ­¢é•¿ PDF å¯¼è‡´ OOM
            output_generator = pipeline.predict(**predict_params)
            
            markdown_pages = []
            page_count = 0
            
            for res in output_generator:
                page_count += 1
                page_dir = output_path / f"page_{page_count}"
                page_dir.mkdir(parents=True, exist_ok=True)

                # ä¿å­˜å›¾ç‰‡å’ŒJSON
                if hasattr(res, "save_to_img"): res.save_to_img(str(page_dir))
                if hasattr(res, "save_to_json"): res.save_to_json(str(page_dir))

                # æå– Markdown
                page_md = ""
                
                # å…¼å®¹ PaddleX ä¸åŒçš„ Markdown å­˜å‚¨ç»“æž„
                if hasattr(res, "markdown") and res.markdown:
                    if isinstance(res.markdown, dict):
                        page_md = res.markdown.get('markdown_texts', '')
                        if not page_md:
                            page_md = res.markdown.get('text', '')
                    elif hasattr(res.markdown, 'markdown_texts'):
                        page_md = res.markdown.markdown_texts
                    elif isinstance(res.markdown, str):
                        page_md = res.markdown
                    else:
                        page_md = str(res.markdown)
                
                elif hasattr(res, "str") and res.str:
                    page_md = str(res.str)
                
                # å°è¯•ä»Žä¿å­˜çš„æ–‡ä»¶è¯»å–ï¼ˆæœ€å¯é çš„æ–¹å¼å…œåº•ï¼‰
                if not page_md and hasattr(res, "save_to_markdown"):
                    try:
                        res.save_to_markdown(str(page_dir))
                        saved_mds = list(page_dir.glob("*.md"))
                        if saved_mds:
                            page_md = saved_mds[0].read_text(encoding="utf-8")
                    except Exception:
                        pass

                if page_md:
                    markdown_pages.append(page_md)
                else:
                    logger.warning(f"âš ï¸ Page {page_count}: No markdown content extracted.")

            logger.info(f"ðŸ“„ Successfully processed {page_count} pages")

            # åˆå¹¶ç»“æžœ
            full_markdown = "\n\n---\n\n".join(markdown_pages)
            final_md_path = output_path / "result.md"
            final_md_path.write_text(full_markdown, encoding="utf-8")
            
            return {
                "success": True,
                "result_path": str(output_path),
                "markdown": full_markdown,
                "markdown_file": str(final_md_path)
            }

        except Exception as e:
            logger.error(f"âŒ Inference failed: {e}")
            logger.error(traceback.format_exc())
            raise
        finally:
            self.cleanup()

    def cleanup(self):
        """æ¸…ç†æ˜¾å­˜"""
        if PADDLE_AVAILABLE and paddle.device.is_compiled_with_cuda():
            paddle.device.cuda.empty_cache()
            gc.collect()

# å…¨å±€å•ä¾‹
_engine_instance = None

def get_engine(model_name: str = "PaddleOCR-VL-1.5-0.9B") -> PaddleOCRVLEngine:
    global _engine_instance
    if _engine_instance is None:
        _engine_instance = PaddleOCRVLEngine(model_name=model_name)
    return _engine_instance
