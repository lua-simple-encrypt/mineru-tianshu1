"""
PaddleOCR-VL è§£æžå¼•æ“Ž (PaddleX v3 Wrapper)
å•ä¾‹æ¨¡å¼ï¼Œæ¯ä¸ªè¿›ç¨‹åªåŠ è½½ä¸€æ¬¡æ¨¡åž‹
æ”¯æŒè‡ªåŠ¨å¤šè¯­è¨€è¯†åˆ«ã€Markdown æ ¼å¼è¾“å‡º

å‚è€ƒæ–‡æ¡£ï¼šhttp://www.paddleocr.ai/main/version3.x/pipeline_usage/PaddleOCR-VL.html
"""

import os
import sys
import gc
import json
import time
import traceback
from pathlib import Path
from typing import Optional, Dict, Any
from threading import Lock
from loguru import logger

# å°è¯•å¯¼å…¥ paddle å’Œ paddlex
try:
    import paddle
    from paddlex import create_pipeline
    PADDLE_AVAILABLE = True
except ImportError:
    PADDLE_AVAILABLE = False
    logger.warning("âš ï¸ PaddlePaddle or PaddleX not installed. Please install: pip install paddlepaddle-gpu paddlex")

class PaddleOCRVLEngine:
    """
    PaddleOCR-VL è§£æžå¼•æ“Žï¼ˆåŸºäºŽ PaddleX v3ï¼‰

    ç‰¹æ€§ï¼š
    - å•ä¾‹æ¨¡å¼ï¼šç¡®ä¿è¿›ç¨‹å†…åªæœ‰ä¸€ä¸ªæ¨¡åž‹å®žä¾‹
    - æ˜¾å­˜ç®¡ç†ï¼šæ”¯æŒæŽ¨ç†åŽæ¸…ç†æ˜¾å­˜
    - æ ¼å¼æ”¯æŒï¼šè¾“å‡º Markdown å’Œ JSON
    - å…¼å®¹æ€§ä¿®å¤ï¼šè‡ªåŠ¨å¤„ç† doc_preprocessor_pipeline ç¼ºå¤±é—®é¢˜
    - å‚æ•°æ”¯æŒï¼šæ”¯æŒ PaddleOCR-VL-1.5 çš„å…¨é‡å‚æ•°é…ç½®
    """

    _instance: Optional["PaddleOCRVLEngine"] = None
    _lock = Lock()
    _pipeline = None
    _initialized = False

    def __new__(cls, *args, **kwargs):
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
        return cls._instance

    def __init__(self, device: str = "cuda:0", model_name: str = "PaddleOCR-VL-1.5-0.9B"):
        if self._initialized:
            return

        with self._lock:
            if self._initialized:
                return

            self.device = device
            self.model_name = model_name
            self.gpu_id = 0

            # è§£æž GPU ID
            if "cuda" in device.lower():
                try:
                    parts = device.split(":")
                    if len(parts) > 1:
                        self.gpu_id = int(parts[-1])
                except ValueError:
                    logger.warning(f"âš ï¸ Invalid device format '{device}', defaulting to GPU 0")

            self._check_environment()
            
            self._initialized = True
            logger.info(f"ðŸ”§ PaddleOCR-VL Engine initialized (Model: {self.model_name}, Device: {self.device})")

    def _check_environment(self):
        """æ£€æŸ¥ GPU å’Œ Paddle çŽ¯å¢ƒ"""
        if not PADDLE_AVAILABLE:
            raise ImportError("PaddlePaddle environment is missing.")

        if not paddle.device.is_compiled_with_cuda():
            logger.error("âŒ PaddlePaddle is installed but NOT compiled with CUDA.")
            raise RuntimeError("PaddlePaddle CUDA version required.")

        try:
            gpu_name = paddle.device.cuda.get_device_name(self.gpu_id)
            logger.info(f"âœ… GPU Detected: {gpu_name}")
        except Exception:
            pass

    def _load_pipeline(self):
        """å»¶è¿ŸåŠ è½½ PaddleX Pipeline"""
        if self._pipeline is not None:
            return self._pipeline

        with self._lock:
            if self._pipeline is not None:
                return self._pipeline

            logger.info(f"ðŸ“¥ Loading PaddleOCR-VL Pipeline: {self.model_name}...")
            start_time = time.time()

            # è®¾ç½®è®¾å¤‡
            paddle.set_device(f"gpu:{self.gpu_id}")

            # ç¡®å®šæ¨¡åž‹è·¯å¾„ (ä¼˜å…ˆä½¿ç”¨æœ¬åœ°ç¼“å­˜)
            pipeline_source = self.model_name
            local_base = Path("/app/models/paddlex") / self.model_name
            pdx_home = os.environ.get("PADDLEX_HOME")

            if local_base.exists() and any(local_base.iterdir()):
                logger.info(f"ðŸ“‚ Using local model: {local_base}")
                pipeline_source = str(local_base)
            elif pdx_home:
                logger.info(f"ðŸ’¾ Using PADDLEX_HOME: {pdx_home}")
            
            try:
                # åˆ›å»º Pipeline
                self._pipeline = create_pipeline(
                    pipeline=pipeline_source,
                    device=f"gpu:{self.gpu_id}",
                    use_hpip=False 
                )
                
                logger.success(f"âœ… Pipeline loaded in {time.time() - start_time:.2f}s")
                return self._pipeline

            except Exception as e:
                logger.error(f"âŒ Failed to load pipeline: {e}")
                raise RuntimeError(f"PaddleOCR-VL load failed: {e}")

    def parse(self, file_path: str, output_path: str, **kwargs) -> Dict[str, Any]:
        """
        æ‰§è¡Œè§£æž

        Args:
            file_path: è¾“å…¥æ–‡ä»¶è·¯å¾„
            output_path: è¾“å‡ºç›®å½•
            **kwargs: æ”¯æŒ PaddleOCR-VL çš„æ‰€æœ‰å‚æ•° (æ”¯æŒé©¼å³°æˆ–ä¸‹åˆ’çº¿å‘½å)
        """
        file_path = Path(file_path)
        output_path = Path(output_path)
        output_path.mkdir(parents=True, exist_ok=True)

        logger.info(f"ðŸ¤– Processing: {file_path.name}")
        
        pipeline = self._load_pipeline()
        
        # å‚æ•°æ˜ å°„è¡¨ (API é©¼å³° -> PaddleX ä¸‹åˆ’çº¿)
        param_mapping = {
            # åŠŸèƒ½å¼€å…³
            "useDocOrientationClassify": "use_doc_orientation_classify",
            "useDocUnwarping": "use_doc_unwarping",
            "useLayoutDetection": "use_layout_parsing", # API å« useLayoutDetection, PaddleX å†…éƒ¨å« use_layout_parsing
            "useChartRecognition": "use_chart_recognition",
            "useSealRecognition": "use_seal_recognition",
            "useOcrForImageBlock": "use_ocr_for_image_block",
            "layoutNms": "layout_nms",
            # åŽå¤„ç†å‚æ•°
            "markdownIgnoreLabels": "markdown_ignore_labels",
            "mergeTables": "merge_tables",
            "relevelTitles": "relevel_titles",
            "restructurePages": "restructure_pages",
            "layoutShapeMode": "layout_shape_mode",
            "minPixels": "min_pixels",
            "maxPixels": "max_pixels",
            # ç”Ÿæˆå‚æ•°
            "promptLabel": "prompt_label", 
            "temperature": "temperature",
            "topP": "top_p",
            "repetitionPenalty": "repetition_penalty"
        }

        # 1. è§„èŒƒåŒ–å‚æ•° (å°† kwargs ä¸­çš„ CamelCase è½¬ä¸º snake_case)
        predict_params = {}
        for k, v in kwargs.items():
            if k in param_mapping:
                predict_params[param_mapping[k]] = v
            else:
                predict_params[k] = v

        try:
            # =================================================================
            # ã€å…³é”®ä¿®å¤ã€‘åŠ¨æ€æ£€æŸ¥ pipeline æ˜¯å¦å…·å¤‡é¢„å¤„ç†èƒ½åŠ›
            # =================================================================
            # æ£€æŸ¥ pipeline å®žä¾‹æ˜¯å¦æœ‰ doc_preprocessor_pipeline å±žæ€§ä¸”ä¸ä¸ºç©º
            has_preprocessor = hasattr(pipeline, "doc_preprocessor_pipeline") and pipeline.doc_preprocessor_pipeline is not None
            
            # èŽ·å–ç”¨æˆ·è®¾ç½® (å¦‚æžœæœªè®¾ç½®ï¼Œé»˜è®¤å€¼å°†åœ¨ä¸‹é¢å¤„ç†)
            req_orientation = predict_params.get("use_doc_orientation_classify", False)
            req_unwarping = predict_params.get("use_doc_unwarping", False)

            # å¦‚æžœè¯·æ±‚äº†é¢„å¤„ç†åŠŸèƒ½ä½†æ¨¡åž‹ä¸æ”¯æŒï¼Œå¼ºåˆ¶å…³é—­å¹¶è­¦å‘Š
            if (req_orientation or req_unwarping) and not has_preprocessor:
                logger.warning("âš ï¸ è¯·æ±‚äº†æ–‡æ¡£çŸ«æ­£/åˆ†ç±»ï¼Œä½†æ¨¡åž‹ç¼ºå°‘é¢„å¤„ç†æ¨¡å—ã€‚å·²è‡ªåŠ¨ç¦ç”¨ä»¥é˜²æ­¢å´©æºƒã€‚")
                predict_params["use_doc_orientation_classify"] = False
                predict_params["use_doc_unwarping"] = False
            
            # è®¾ç½®é»˜è®¤å€¼ (å¦‚æžœ predict_params ä¸­æ²¡æœ‰æŒ‡å®š)
            # æ ¹æ® API ä¹ æƒ¯ï¼Œå¦‚æžœç”¨æˆ·æ²¡ä¼ ï¼Œæˆ‘ä»¬è®¾ç½®é»˜è®¤å€¼ã€‚
            # æ³¨æ„ï¼šuse_layout_parsing é»˜è®¤ä¸º True
            if "use_layout_parsing" not in predict_params:
                predict_params["use_layout_parsing"] = True
            
            # å¯¹äºŽæ–¹å‘åˆ†ç±»å’ŒåŽ»å¼¯æ›²ï¼Œå¦‚æžœæ¨¡åž‹æ”¯æŒä¸”ç”¨æˆ·æ²¡æŒ‡å®šï¼Œå¯ä»¥é€‰æ‹©å¼€å¯æˆ–å…³é—­
            # ä¸ºäº†ç¨³å®šæ€§ï¼Œæˆ‘ä»¬é»˜è®¤å…³é—­ï¼ˆé™¤éžç”¨æˆ·æ˜¾å¼å¼€å¯ï¼‰ï¼Œæˆ–è€…å¦‚æžœæ¨¡åž‹æ”¯æŒåˆ™å¼€å¯ã€‚
            # è¿™é‡Œé‡‡å–ç­–ç•¥ï¼šå¦‚æžœæ¨¡åž‹æ”¯æŒï¼Œä¸”ç”¨æˆ·æœªæ˜¾å¼è®¾ç½® Falseï¼Œåˆ™é»˜è®¤å¼€å¯ï¼Ÿ
            # ä¸ï¼Œä¸ºäº†å¯¹é½ API é»˜è®¤è¡Œä¸º (False)ï¼Œæˆ‘ä»¬ä¿æŒ Falseï¼Œé™¤éžç”¨æˆ·ä¼ å…¥ Trueã€‚
            if "use_doc_orientation_classify" not in predict_params:
                predict_params["use_doc_orientation_classify"] = False # é»˜è®¤å…³é—­ï¼Œæå‡é€Ÿåº¦
            
            if "use_doc_unwarping" not in predict_params:
                predict_params["use_doc_unwarping"] = False # é»˜è®¤å…³é—­ï¼Œæå‡é€Ÿåº¦

            # è®¾ç½®è¾“å…¥
            predict_params["input"] = str(file_path)

            # æ‰“å°æœ€ç»ˆä½¿ç”¨çš„å‚æ•° (æŽ’é™¤ input ä»¥é˜²æ—¥å¿—è¿‡é•¿)
            log_params = {k: v for k, v in predict_params.items() if k != "input"}
            logger.info(f"ðŸš€ å¼€å§‹æŽ¨ç† (å‚æ•°: {json.dumps(log_params, default=str, ensure_ascii=False)})")
            
            # æ‰§è¡ŒæŽ¨ç†
            output = pipeline.predict(**predict_params)
            
            results = list(output)
            logger.info(f"ðŸ“„ Processed {len(results)} pages")

            markdown_pages = []
            
            for idx, res in enumerate(results, 1):
                page_dir = output_path / f"page_{idx}"
                page_dir.mkdir(parents=True, exist_ok=True)

                # ä¿å­˜å›¾ç‰‡å’ŒJSON
                if hasattr(res, "save_to_img"): res.save_to_img(str(page_dir))
                if hasattr(res, "save_to_json"): res.save_to_json(str(page_dir))

                # æå– Markdown
                page_md = ""
                if hasattr(res, "markdown") and res.markdown:
                    page_md = str(res.markdown)
                elif hasattr(res, "str") and res.str:
                    page_md = str(res.str)
                elif hasattr(res, "save_to_markdown"):
                    try:
                        res.save_to_markdown(str(page_dir))
                        saved_mds = list(page_dir.glob("*.md"))
                        if saved_mds:
                            page_md = saved_mds[0].read_text(encoding="utf-8")
                    except Exception:
                        pass

                if page_md:
                    markdown_pages.append(page_md)

            # åˆå¹¶ç»“æžœ
            full_markdown = "\n\n---\n\n".join(markdown_pages)
            final_md_path = output_path / "result.md"
            final_md_path.write_text(full_markdown, encoding="utf-8")
            
            self.cleanup()

            return {
                "success": True,
                "result_path": str(output_path),
                "markdown": full_markdown,
                "markdown_file": str(final_md_path)
            }

        except Exception as e:
            logger.error(f"âŒ Inference failed: {e}")
            logger.error(traceback.format_exc())
            self.cleanup()
            raise

    def cleanup(self):
        """æ¸…ç†æ˜¾å­˜"""
        if PADDLE_AVAILABLE and paddle.device.is_compiled_with_cuda():
            paddle.device.cuda.empty_cache()
            gc.collect()

# å…¨å±€å•ä¾‹
_engine_instance = None

def get_engine(model_name: str = "PaddleOCR-VL-1.5-0.9B") -> PaddleOCRVLEngine:
    global _engine_instance
    if _engine_instance is None:
        _engine_instance = PaddleOCRVLEngine(model_name=model_name)
    return _engine_instance
