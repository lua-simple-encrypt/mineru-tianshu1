"""
PaddleOCR-VL è§£æå¼•æ“
å•ä¾‹æ¨¡å¼ï¼Œæ¯ä¸ªè¿›ç¨‹åªåŠ è½½ä¸€æ¬¡æ¨¡å‹
ä½¿ç”¨æœ€æ–°çš„ PaddleOCR-VL APIï¼ˆè‡ªåŠ¨å¤šè¯­è¨€è¯†åˆ«ï¼‰

å‚è€ƒæ–‡æ¡£ï¼šhttp://www.paddleocr.ai/main/version3.x/pipeline_usage/PaddleOCR-VL.html

é‡è¦æç¤ºï¼š
- PaddleOCR-VL ä»…æ”¯æŒ GPU æ¨ç†ï¼Œä¸æ”¯æŒ CPU åŠ Arm æ¶æ„
- GPU è¦æ±‚ï¼šCompute Capability â‰¥ 8.5 (RTX 3090, A10, A100, H100 ç­‰)
- æ”¯æŒæœ¬åœ°æ¨¡å‹åŠ è½½ï¼ˆ/app/models/paddlex/ï¼‰æˆ–è‡ªåŠ¨ä¸‹è½½
"""

import os
from pathlib import Path
from typing import Optional, Dict, Any
from threading import Lock
import time
from loguru import logger


class PaddleOCRVLEngine:
    """
    PaddleOCR-VL è§£æå¼•æ“ï¼ˆæ–°ç‰ˆæœ¬ï¼‰

    ç‰¹æ€§ï¼š
    - å•ä¾‹æ¨¡å¼ï¼ˆæ¯ä¸ªè¿›ç¨‹åªåŠ è½½ä¸€æ¬¡æ¨¡å‹ï¼‰
    - è‡ªåŠ¨å¤šè¯­è¨€è¯†åˆ«ï¼ˆæ— éœ€æŒ‡å®šè¯­è¨€ï¼Œæ”¯æŒ 109+ è¯­è¨€ï¼‰
    - çº¿ç¨‹å®‰å…¨
    - ä»…æ”¯æŒ GPU æ¨ç†ï¼ˆä¸æ”¯æŒ CPUï¼‰
    - åŸç”Ÿæ”¯æŒ PDF å¤šé¡µæ–‡æ¡£
    - ç»“æ„åŒ–è¾“å‡ºï¼ˆMarkdown/JSONï¼‰
    - æ”¯æŒåŠ è½½æœ¬åœ°æ¨¡å‹ç¼“å­˜ï¼Œé¿å…é‡å¤ä¸‹è½½

    GPU è¦æ±‚ï¼š
    - NVIDIA GPU with Compute Capability â‰¥ 8.5
    - æ¨èï¼šRTX 3090, RTX 4090, A10, A100, H100
    """

    _instance: Optional["PaddleOCRVLEngine"] = None
    _lock = Lock()
    _pipeline = None
    _initialized = False

    def __new__(cls, *args, **kwargs):
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
        return cls._instance

    def __init__(self, device: str = "cuda:0", model_name: str = "PaddleOCR-VL-1.5-0.9B"):
        """
        åˆå§‹åŒ–å¼•æ“ï¼ˆåªæ‰§è¡Œä¸€æ¬¡ï¼‰

        Args:
            device: è®¾å¤‡ (cuda:0, cuda:1 ç­‰ï¼ŒPaddleOCR ä»…æ”¯æŒ GPU)
            model_name: æ¨¡å‹åç§°æˆ–è·¯å¾„ (é»˜è®¤: PaddleOCR-VL-1.5-0.9B)
        """
        if self._initialized:
            return

        with self._lock:
            if self._initialized:
                return

            self.device = device
            self.model_name = model_name

            # ä» device å­—ç¬¦ä¸²ä¸­æå– GPU ID (ä¾‹å¦‚ "cuda:0" -> 0)
            if "cuda:" in device:
                self.gpu_id = int(device.split(":")[-1])
            else:
                self.gpu_id = 0
                logger.warning(f"âš ï¸  Invalid device format: {device}, using GPU 0")

            # æ£€æŸ¥ GPU å¯ç”¨æ€§ï¼ˆPaddleOCR-VL ä»…æ”¯æŒ GPUï¼‰
            self._check_gpu_availability()

            self._initialized = True

            logger.info("ğŸ”§ PaddleOCR-VL Engine initialized")
            logger.info(f"   Device: {self.device} (GPU ID: {self.gpu_id})")
            logger.info(f"   Target Model: {self.model_name}")

    def _check_gpu_availability(self):
        """
        æ£€æŸ¥ GPU ä¿¡æ¯å¹¶è¾“å‡ºæ—¥å¿—
        PaddleOCR-VL ä»…æ”¯æŒ GPU æ¨ç†ï¼Œä½†ä¸é˜»æ­¢ä½ç‰ˆæœ¬ GPU è¿è¡Œ
        """
        try:
            import paddle

            # æ£€æŸ¥æ˜¯å¦ç¼–è¯‘äº† CUDA æ”¯æŒ
            if not paddle.is_compiled_with_cuda():
                logger.warning("âš ï¸  PaddlePaddle is not compiled with CUDA")
                logger.warning("   PaddleOCR-VL requires GPU support")
                logger.warning("   Install: pip install paddlepaddle-gpu==3.2.0")
                return

            # æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„ GPU
            gpu_count = paddle.device.cuda.device_count()
            if gpu_count == 0:
                logger.warning("âš ï¸  No CUDA devices found")
                logger.warning("   PaddleOCR-VL requires GPU for inference")
                return

            # è·å– GPU ä¿¡æ¯
            try:
                gpu_name = paddle.device.cuda.get_device_name(0)
                compute_capability = paddle.device.cuda.get_device_capability(0)

                logger.info(f"âœ… GPU detected: {gpu_name}")
                logger.info(f"   Compute Capability: {compute_capability[0]}.{compute_capability[1]}")
                logger.info(f"   GPU Count: {gpu_count}")

                # ä»…è¾“å‡ºå»ºè®®ï¼Œä¸é˜»æ­¢è¿è¡Œ
                cc_major = compute_capability[0]
                cc_minor = compute_capability[1]
                if cc_major < 8 or (cc_major == 8 and cc_minor < 5):
                    logger.info("â„¹ï¸  GPU Compute Capability < 8.5")
                    logger.info("   Official recommendation: CC â‰¥ 8.5 for best performance")
                    logger.info("   Your GPU may still work, but performance might vary")
            except Exception as e:
                logger.debug(f"Could not get detailed GPU info: {e}")

        except ImportError:
            logger.warning("âš ï¸  PaddlePaddle not installed")
            logger.warning("   Install: pip install paddlepaddle-gpu==3.2.0")
        except Exception as e:
            logger.debug(f"GPU check warning: {e}")

    def _load_pipeline(self):
        """å»¶è¿ŸåŠ è½½ PaddleOCR-VL ç®¡é“"""
        if self._pipeline is not None:
            return self._pipeline

        with self._lock:
            if self._pipeline is not None:
                return self._pipeline

            logger.info("=" * 60)
            logger.info(f"ğŸ“¥ Loading PaddleOCR-VL Pipeline ({self.model_name})...")
            logger.info("=" * 60)

            try:
                import paddle
                from paddlex import create_pipeline

                # è®¾ç½® PaddlePaddle ä½¿ç”¨æŒ‡å®šçš„ GPU
                if paddle.is_compiled_with_cuda():
                    paddle.set_device(f"gpu:{self.gpu_id}")
                    logger.info(f"ğŸ¯ PaddlePaddle device set to: gpu:{self.gpu_id}")
                else:
                    logger.warning("âš ï¸  CUDA not available, PaddleOCR-VL may not work")

                # =========================================================================
                # æ™ºèƒ½è·¯å¾„è§£æé€»è¾‘
                # =========================================================================
                # 1. å®šä¹‰æœ¬åœ°æ¨¡å‹æ ¹ç›®å½• (æŒ‡å‘ paddlex å­ç›®å½•)
                base_model_dir = Path("/app/models/paddlex")
                
                # 2. å°è¯•æ‹¼æ¥æœ¬åœ°è·¯å¾„
                # PaddleX å®˜æ–¹æ¨¡å‹åç§°é€šå¸¸åŒ…å«ç‰ˆæœ¬å·
                local_model_path = base_model_dir / self.model_name
                
                pipeline_source = self.model_name # é»˜è®¤ä½¿ç”¨æ¨¡å‹åç§°ï¼ˆè§¦å‘åœ¨çº¿æŸ¥æ‰¾/ç¼“å­˜æŸ¥æ‰¾ï¼‰

                if local_model_path.exists() and local_model_path.is_dir():
                    logger.info(f"ğŸ“‚ Found local model cache: {local_model_path}")
                    # å¼ºåˆ¶ä½¿ç”¨æœ¬åœ°ç»å¯¹è·¯å¾„ï¼Œé˜²æ­¢ PaddleX é‡æ–°å» ~/.paddlex ä¸‹è½½
                    pipeline_source = str(local_model_path)
                    
                    # è®¾ç½® PaddleX ç¼“å­˜ç›®å½•åˆ° paddlex ä¸‹ï¼Œä¿æŒæ•´æ´
                    # è¿™æ ·å³ä½¿ä¸‹è½½è¾…åŠ©æ¨¡å‹ï¼Œä¹Ÿä¼šå­˜æ”¾åœ¨æˆ‘ä»¬æŒ‚è½½çš„ç›®å½•ä¸­
                    os.environ["PADDLEX_HOME"] = "/app/models/paddlex/.paddlex_cache"
                else:
                    logger.warning(f"âš ï¸  Local model not found at: {local_model_path}")
                    logger.info(f"   Will attempt to load '{self.model_name}' from official source/cache...")

                # åˆå§‹åŒ–ç®¡é“
                start_time = time.time()
                
                # ä½¿ç”¨ PaddleX çš„ create_pipeline API
                self._pipeline = create_pipeline(
                    pipeline=pipeline_source,
                    device=f"gpu:{self.gpu_id}" if paddle.is_compiled_with_cuda() else "cpu",
                    # å¯ä»¥åœ¨è¿™é‡Œä¼ é€’å…¶ä»–å‚æ•°ï¼Œä¾‹å¦‚ use_hp_ip=True ç­‰
                )

                logger.info("=" * 60)
                logger.info(f"âœ… PaddleOCR-VL Pipeline loaded in {time.time() - start_time:.2f}s!")
                logger.info(f"   Source: {pipeline_source}")
                logger.info(f"   Device: GPU {self.gpu_id}")
                logger.info("=" * 60)

                return self._pipeline

            except Exception as e:
                logger.error("=" * 80)
                logger.error("âŒ ç®¡é“åŠ è½½å¤±è´¥:")
                logger.error(f"   é”™è¯¯ç±»å‹: {type(e).__name__}")
                logger.error(f"   é”™è¯¯ä¿¡æ¯: {e}")
                logger.error("")
                logger.error("ğŸ’¡ æ’æŸ¥å»ºè®®:")
                logger.error("   1. ç¡®ä¿æ¨¡å‹æ–‡ä»¶å­˜åœ¨äº /app/models/paddlex/")
                logger.error("   2. æ£€æŸ¥æ˜¾å­˜æ˜¯å¦å……è¶³")
                logger.error("   3. æ£€æŸ¥ CUDA ç‰ˆæœ¬å…¼å®¹æ€§")
                logger.error("=" * 80)

                import traceback
                logger.debug("å®Œæ•´å †æ ˆè·Ÿè¸ª:")
                logger.debug(traceback.format_exc())

                raise

    def cleanup(self):
        """
        æ¸…ç†æ¨ç†äº§ç”Ÿçš„æ˜¾å­˜ï¼ˆä¸å¸è½½æ¨¡å‹ï¼‰
        """
        try:
            import paddle
            import gc

            # æ¸…ç† PaddlePaddle æ˜¾å­˜
            if paddle.device.is_compiled_with_cuda():
                paddle.device.cuda.empty_cache()
                logger.debug("ğŸ§¹ PaddleOCR-VL: CUDA cache cleared")

            # æ¸…ç† Python å¯¹è±¡
            gc.collect()

            logger.debug("ğŸ§¹ PaddleOCR-VL: Memory cleanup completed")
        except Exception as e:
            logger.debug(f"Memory cleanup warning: {e}")

    def parse(self, file_path: str, output_path: str, **kwargs) -> Dict[str, Any]:
        """
        è§£ææ–‡æ¡£æˆ–å›¾ç‰‡

        Args:
            file_path: è¾“å…¥æ–‡ä»¶è·¯å¾„
            output_path: è¾“å‡ºç›®å½•
            **kwargs: å…¶ä»–å‚æ•°

        Returns:
            è§£æç»“æœï¼ˆåŒæ—¶ä¿å­˜ Markdown å’Œ JSON ä¸¤ç§æ ¼å¼ï¼‰
        """
        file_path = Path(file_path)
        output_path = Path(output_path)
        output_path.mkdir(parents=True, exist_ok=True)

        logger.info(f"ğŸ¤– PaddleOCR-VL parsing: {file_path.name}")
        
        # åŠ è½½ç®¡é“
        pipeline = self._load_pipeline()

        # æ‰§è¡Œæ¨ç†
        try:
            logger.info("ğŸš€ å¼€å§‹ä½¿ç”¨ PaddleOCR-VL è¯†åˆ«...")
            
            # PaddleX v3 predict æ–¹æ³•å‚æ•°
            # use_doc_orientation_classify: å¯ç”¨æ–‡æ¡£æ–¹å‘åˆ†ç±»
            # use_doc_unwarping: å¯ç”¨æ–‡æ¡£çŸ«æ­£
            # use_layout_parsing: å¯ç”¨ç‰ˆé¢åˆ†æ
            result = pipeline.predict(
                str(file_path),
                use_doc_orientation_classify=True,
                use_doc_unwarping=True,
                use_layout_parsing=True
            )
            
            # ç»“æœå¯èƒ½æ˜¯ä¸€ä¸ªç”Ÿæˆå™¨æˆ–åˆ—è¡¨
            results = list(result)

            logger.info("âœ… PaddleOCR-VL completed")
            logger.info(f"   è¯†åˆ«äº† {len(results)} é¡µ/å¼ ")

            markdown_list = []
            json_list = []

            for idx, res in enumerate(results, 1):
                logger.info(f"ğŸ“ å¤„ç†ç»“æœ {idx}/{len(results)}")

                try:
                    # ä¸ºæ¯é¡µåˆ›å»ºå­ç›®å½•
                    page_output_dir = output_path / f"page_{idx}"
                    page_output_dir.mkdir(parents=True, exist_ok=True)

                    # ä¿å­˜å¯è§†åŒ–ç»“æœå’ŒJSON
                    if hasattr(res, "save_to_img"):
                        res.save_to_img(str(page_output_dir))
                    if hasattr(res, "save_to_json"):
                        res.save_to_json(str(page_output_dir))
                    
                    # å°è¯•ä¿å­˜ Markdown (å¦‚æœæ”¯æŒ)
                    if hasattr(res, "save_to_markdown"):
                        res.save_to_markdown(str(page_output_dir))

                    # æ”¶é›† Markdown å†…å®¹
                    # æ³¨æ„ï¼šPaddleX ä¸åŒç‰ˆæœ¬çš„å±æ€§åå¯èƒ½ä¸åŒï¼Œå°è¯•åšå…¼å®¹
                    if hasattr(res, "markdown"):
                        # å¦‚æœ res.markdown æ˜¯å¯¹è±¡ï¼Œå°è¯•è½¬å­—ç¬¦ä¸²æˆ–å– text
                        md_content = res.markdown
                        markdown_list.append(md_content)
                    elif hasattr(res, "str"):
                         # æŸäº›ä»»åŠ¡å¯èƒ½ç”¨ str å±æ€§è¿”å›æ–‡æœ¬
                         markdown_list.append(res.str)

                    # æ”¶é›† JSON æ•°æ® (å¦‚æœæœ‰)
                    # æœ‰äº›ç»“æœå¯¹è±¡å¯èƒ½æ²¡æœ‰ç›´æ¥çš„ json å±æ€§ï¼Œè€Œæ˜¯é€šè¿‡ save_to_json ç”Ÿæˆ
                    # è¿™é‡Œå°è¯•ä»å·²ä¿å­˜çš„æ–‡ä»¶è¯»å–ï¼Œæˆ–è€…å¦‚æœå¯¹è±¡æœ‰ dict/json æ–¹æ³•
                    # ç®€å•èµ·è§ï¼Œå¦‚æœ res æœ¬èº«æ˜¯å¯åºåˆ—åŒ–çš„ï¼Œä¹Ÿå¯ä»¥ç›´æ¥ç”¨
                    pass 

                except Exception as e:
                    logger.warning(f"   é¡µå¤„ç†å‡ºé”™: {e}")
            
            # åˆå¹¶ Markdown
            markdown_text = ""
            
            # ä¼˜å…ˆä½¿ç”¨ pipeline è‡ªå¸¦çš„åˆå¹¶æ–¹æ³•ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if hasattr(pipeline, "concatenate_markdown_pages") and markdown_list:
                try:
                    markdown_text = pipeline.concatenate_markdown_pages(markdown_list)
                    logger.info("   ä½¿ç”¨å®˜æ–¹ concatenate_markdown_pages() æ–¹æ³•åˆå¹¶")
                except Exception as e:
                    logger.warning(f"   åˆå¹¶å¤±è´¥ï¼Œé™çº§ä¸ºæ‰‹åŠ¨åˆå¹¶: {e}")
                    markdown_text = "\n\n---\n\n".join([str(m) for m in markdown_list])
            elif markdown_list:
                # æ‰‹åŠ¨åˆå¹¶
                markdown_text = "\n\n---\n\n".join([str(m) for m in markdown_list])
            
            # å¦‚æœæ²¡æœ‰ç›´æ¥è·å¾— markdownï¼Œå°è¯•è¯»å–ç”Ÿæˆçš„ .md æ–‡ä»¶
            if not markdown_text:
                logger.info("   å°è¯•ä»è¾“å‡ºç›®å½•è¯»å– Markdown æ–‡ä»¶...")
                for md_file in output_path.rglob("*.md"):
                    if md_file.name != "result.md": # æ’é™¤è‡ªå·±
                        text = md_file.read_text(encoding="utf-8")
                        markdown_text += text + "\n\n---\n\n"

            # ä¿å­˜æœ€ç»ˆç»“æœ
            markdown_file = output_path / "result.md"
            markdown_file.write_text(markdown_text, encoding="utf-8")
            logger.info(f"ğŸ“„ Markdown å·²ä¿å­˜: {markdown_file}")

            return {
                "success": True,
                "output_path": str(output_path),
                "markdown": markdown_text,
                "markdown_file": str(markdown_file),
                # "json_file": ... (å¦‚æœç”Ÿæˆäº†åˆå¹¶çš„JSON)
            }

        except Exception as e:
            logger.error(f"âŒ OCR è§£æå¤±è´¥: {e}")
            import traceback
            logger.debug(traceback.format_exc())
            raise

        finally:
            self.cleanup()


# å…¨å±€å•ä¾‹
_engine = None


def get_engine(model_name: str = "PaddleOCR-VL-1.5-0.9B") -> PaddleOCRVLEngine:
    """
    è·å–å…¨å±€å¼•æ“å®ä¾‹
    æ³¨æ„ï¼šå•ä¾‹æ¨¡å¼ä¸‹ï¼Œç¬¬ä¸€æ¬¡è°ƒç”¨æ—¶çš„ model_name ä¼šå†³å®šåç»­ä¸€ç›´ä½¿ç”¨çš„æ¨¡å‹
    """
    global _engine
    if _engine is None:
        _engine = PaddleOCRVLEngine(model_name=model_name)
    return _engine
