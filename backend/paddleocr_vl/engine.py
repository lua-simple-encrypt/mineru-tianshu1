"""
PaddleOCR-VL è§£æå¼•æ“
å•ä¾‹æ¨¡å¼ï¼Œæ¯ä¸ªè¿›ç¨‹åªåŠ è½½ä¸€æ¬¡æ¨¡å‹
ä½¿ç”¨æœ€æ–°çš„ PaddleOCR-VL APIï¼ˆè‡ªåŠ¨å¤šè¯­è¨€è¯†åˆ«ï¼‰

å‚è€ƒæ–‡æ¡£ï¼šhttp://www.paddleocr.ai/main/version3.x/pipeline_usage/PaddleOCR-VL.html

é‡è¦æç¤ºï¼š
- PaddleOCR-VL ä»…æ”¯æŒ GPU æ¨ç†ï¼Œä¸æ”¯æŒ CPU åŠ Arm æ¶æ„
- GPU è¦æ±‚ï¼šCompute Capability â‰¥ 8.5 (RTX 3090, A10, A100, H100 ç­‰)
- æ”¯æŒæœ¬åœ°æ¨¡å‹åŠ è½½ï¼ˆ/app/models/paddlex/ï¼‰æˆ–è‡ªåŠ¨ä¸‹è½½
"""

import os
from pathlib import Path
from typing import Optional, Dict, Any
from threading import Lock
import time
from loguru import logger

class PaddleOCRVLEngine:
    """
    PaddleOCR-VL è§£æå¼•æ“ï¼ˆæ–°ç‰ˆæœ¬ï¼‰

    ç‰¹æ€§ï¼š
    - å•ä¾‹æ¨¡å¼ï¼ˆæ¯ä¸ªè¿›ç¨‹åªåŠ è½½ä¸€æ¬¡æ¨¡å‹ï¼‰
    - è‡ªåŠ¨å¤šè¯­è¨€è¯†åˆ«ï¼ˆæ— éœ€æŒ‡å®šè¯­è¨€ï¼Œæ”¯æŒ 109+ è¯­è¨€ï¼‰
    - çº¿ç¨‹å®‰å…¨
    - ä»…æ”¯æŒ GPU æ¨ç†ï¼ˆä¸æ”¯æŒ CPUï¼‰
    - åŸç”Ÿæ”¯æŒ PDF å¤šé¡µæ–‡æ¡£
    - ç»“æ„åŒ–è¾“å‡ºï¼ˆMarkdown/JSONï¼‰
    - æ”¯æŒåŠ è½½æœ¬åœ°æ¨¡å‹ç¼“å­˜ï¼Œé¿å…é‡å¤ä¸‹è½½

    GPU è¦æ±‚ï¼š
    - NVIDIA GPU with Compute Capability â‰¥ 8.5
    - æ¨èï¼šRTX 3090, RTX 4090, A10, A100, H100
    """

    _instance: Optional["PaddleOCRVLEngine"] = None
    _lock = Lock()
    _pipeline = None
    _initialized = False

    def __new__(cls, *args, **kwargs):
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
        return cls._instance

    def __init__(self, device: str = "cuda:0", model_name: str = "PaddleOCR-VL-1.5-0.9B"):
        """
        åˆå§‹åŒ–å¼•æ“ï¼ˆåªæ‰§è¡Œä¸€æ¬¡ï¼‰

        Args:
            device: è®¾å¤‡ (cuda:0, cuda:1 ç­‰ï¼ŒPaddleOCR ä»…æ”¯æŒ GPU)
            model_name: æ¨¡å‹åç§°æˆ–è·¯å¾„ (é»˜è®¤: PaddleOCR-VL-1.5-0.9B)
        """
        if self._initialized:
            return

        with self._lock:
            if self._initialized:
                return

            self.device = device
            self.model_name = model_name

            # ä» device å­—ç¬¦ä¸²ä¸­æå– GPU ID (ä¾‹å¦‚ "cuda:0" -> 0)
            if "cuda:" in device:
                self.gpu_id = int(device.split(":")[-1])
            else:
                self.gpu_id = 0
                logger.warning(f"âš ï¸  Invalid device format: {device}, using GPU 0")

            # æ£€æŸ¥ GPU å¯ç”¨æ€§ï¼ˆPaddleOCR-VL ä»…æ”¯æŒ GPUï¼‰
            self._check_gpu_availability()

            self._initialized = True

            logger.info("ğŸ”§ PaddleOCR-VL Engine initialized")
            logger.info(f"   Device: {self.device} (GPU ID: {self.gpu_id})")
            logger.info(f"   Target Model: {self.model_name}")

    def _check_gpu_availability(self):
        """
        æ£€æŸ¥ GPU ä¿¡æ¯å¹¶è¾“å‡ºæ—¥å¿—
        PaddleOCR-VL ä»…æ”¯æŒ GPU æ¨ç†ï¼Œä½†ä¸é˜»æ­¢ä½ç‰ˆæœ¬ GPU è¿è¡Œ
        """
        try:
            import paddle

            # æ£€æŸ¥æ˜¯å¦ç¼–è¯‘äº† CUDA æ”¯æŒ
            if not paddle.is_compiled_with_cuda():
                logger.warning("âš ï¸  PaddlePaddle is not compiled with CUDA")
                logger.warning("   PaddleOCR-VL requires GPU support")
                logger.warning("   Install: pip install paddlepaddle-gpu==3.0.0b1 -i https://www.paddlepaddle.org.cn/packages/stable/cu118/")
                return

            # æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„ GPU
            gpu_count = paddle.device.cuda.device_count()
            if gpu_count == 0:
                logger.warning("âš ï¸  No CUDA devices found")
                logger.warning("   PaddleOCR-VL requires GPU for inference")
                return

            # è·å– GPU ä¿¡æ¯
            try:
                gpu_name = paddle.device.cuda.get_device_name(0)
                compute_capability = paddle.device.cuda.get_device_capability(0)

                logger.info(f"âœ… GPU detected: {gpu_name}")
                logger.info(f"   Compute Capability: {compute_capability[0]}.{compute_capability[1]}")
                logger.info(f"   GPU Count: {gpu_count}")

                # ä»…è¾“å‡ºå»ºè®®ï¼Œä¸é˜»æ­¢è¿è¡Œ
                cc_major = compute_capability[0]
                cc_minor = compute_capability[1]
                if cc_major < 8 or (cc_major == 8 and cc_minor < 5):
                    logger.info("â„¹ï¸  GPU Compute Capability < 8.5")
                    logger.info("   Official recommendation: CC â‰¥ 8.5 for best performance")
                    logger.info("   Your GPU may still work, but performance might vary")
            except Exception as e:
                logger.debug(f"Could not get detailed GPU info: {e}")

        except ImportError:
            logger.warning("âš ï¸  PaddlePaddle not installed")
        except Exception as e:
            logger.debug(f"GPU check warning: {e}")

    def _load_pipeline(self):
        """å»¶è¿ŸåŠ è½½ PaddleOCR-VL ç®¡é“"""
        if self._pipeline is not None:
            return self._pipeline

        with self._lock:
            if self._pipeline is not None:
                return self._pipeline

            logger.info("=" * 60)
            logger.info(f"ğŸ“¥ Loading PaddleOCR-VL Pipeline ({self.model_name})...")
            logger.info("=" * 60)

            try:
                import paddle
                from paddlex import create_pipeline

                # è®¾ç½® PaddlePaddle ä½¿ç”¨æŒ‡å®šçš„ GPU
                if paddle.is_compiled_with_cuda():
                    paddle.set_device(f"gpu:{self.gpu_id}")
                    logger.info(f"ğŸ¯ PaddlePaddle device set to: gpu:{self.gpu_id}")
                else:
                    logger.warning("âš ï¸  CUDA not available, PaddleOCR-VL may not work")

                # =========================================================================
                # æ™ºèƒ½è·¯å¾„è§£æé€»è¾‘ (è§£å†³é‡å¤ä¸‹è½½çš„æ ¸å¿ƒ)
                # =========================================================================
                # 1. å®šä¹‰æœ¬åœ°æ¨¡å‹æ ¹ç›®å½• (æŒ‡å‘æˆ‘ä»¬æŒ‚è½½çš„ /app/models/paddlex)
                base_model_dir = Path("/app/models/paddlex")
                
                # 2. å°è¯•æ‹¼æ¥æœ¬åœ°è·¯å¾„
                local_model_path = base_model_dir / self.model_name
                
                # é»˜è®¤è¡Œä¸ºï¼šå¦‚æœæœ¬åœ°æ²¡æ‰¾åˆ°ï¼Œä½¿ç”¨æ¨¡å‹åç§°ï¼ˆè¿™å°†è§¦å‘ PaddleX å»ç½‘ç»œä¸‹è½½ï¼‰
                pipeline_source = self.model_name 

                # 3. è®¾ç½® PaddleX ç¼“å­˜ç›®å½• [å…³é”®ä¿®æ”¹]
                # å°† PADDLEX_HOME è®¾ç½®åˆ°æŒ‚è½½å·ä¸­ï¼Œè¿™æ ·å³ä½¿è‡ªåŠ¨ä¸‹è½½ï¼Œä¸‹æ¬¡é‡å¯ä¹Ÿåœ¨
                # è¿™è§£å†³äº† "Using official model... automatically downloaded" é‡å¤å‘ç”Ÿçš„é—®é¢˜
                cache_dir = base_model_dir / ".paddlex_cache"
                cache_dir.mkdir(exist_ok=True, parents=True)
                os.environ["PADDLEX_HOME"] = str(cache_dir)
                logger.info(f"ğŸ’¾ Set PADDLEX_HOME to: {os.environ['PADDLEX_HOME']}")

                # 4. ä¸¥æ ¼æ£€æŸ¥æœ¬åœ°æ¨¡å‹è·¯å¾„
                if local_model_path.exists() and local_model_path.is_dir():
                    # æ£€æŸ¥ç›®å½•ä¸‹æ˜¯å¦æœ‰æ–‡ä»¶ï¼Œé¿å…ç©ºæŒ‚è½½å¯¼è‡´ "pipeline does not exist" é”™è¯¯
                    if any(local_model_path.iterdir()): 
                        logger.info(f"ğŸ“‚ Found local model files: {local_model_path}")
                        # å¼ºåˆ¶ä½¿ç”¨æœ¬åœ°ç»å¯¹è·¯å¾„
                        pipeline_source = str(local_model_path)
                    else:
                        logger.warning(f"âš ï¸  Directory exists but is EMPTY: {local_model_path}")
                        logger.warning("   Falling back to auto-download mode.")
                else:
                    logger.warning(f"âš ï¸  Local model path not found: {local_model_path}")
                    logger.info(f"   Will attempt to download '{self.model_name}' to cache...")

                # åˆå§‹åŒ–ç®¡é“
                start_time = time.time()
                
                # ä½¿ç”¨ PaddleX çš„ create_pipeline API
                self._pipeline = create_pipeline(
                    pipeline=pipeline_source,
                    device=f"gpu:{self.gpu_id}" if paddle.is_compiled_with_cuda() else "cpu",
                    # å¯ä»¥åœ¨è¿™é‡Œä¼ é€’å…¶ä»–å‚æ•°
                )

                logger.info("=" * 60)
                logger.info(f"âœ… PaddleOCR-VL Pipeline loaded in {time.time() - start_time:.2f}s!")
                logger.info(f"   Source: {pipeline_source}")
                logger.info(f"   Device: GPU {self.gpu_id}")
                logger.info("=" * 60)

                return self._pipeline

            except Exception as e:
                logger.error("=" * 80)
                logger.error("âŒ ç®¡é“åŠ è½½å¤±è´¥:")
                logger.error(f"   é”™è¯¯ç±»å‹: {type(e).__name__}")
                logger.error(f"   é”™è¯¯ä¿¡æ¯: {e}")
                logger.error("")
                logger.error("ğŸ’¡ æ’æŸ¥å»ºè®®:")
                logger.error("   1. æ£€æŸ¥ /app/models/paddlex/ ç›®å½•æ˜¯å¦æŒ‚è½½æ­£ç¡®")
                logger.error("   2. æ£€æŸ¥ç›®å½•æ˜¯å¦ä¸ºç©º")
                logger.error("   3. æ£€æŸ¥æ˜¾å­˜å’Œ CUDA ç‰ˆæœ¬")
                logger.error("=" * 80)

                import traceback
                logger.debug("å®Œæ•´å †æ ˆè·Ÿè¸ª:")
                logger.debug(traceback.format_exc())

                raise

    def warmup(self):
        """
        æ‰‹åŠ¨è§¦å‘æ¨¡å‹åŠ è½½ï¼ˆé¢„çƒ­ï¼‰
        å»ºè®®åœ¨ Worker å¯åŠ¨æ—¶è°ƒç”¨ï¼Œé¿å…ç¬¬ä¸€ä¸ªè¯·æ±‚å¤„ç†è¿‡æ…¢
        """
        if self._pipeline is None:
            logger.info("ğŸ”¥ Warming up PaddleOCR-VL engine...")
            try:
                self._load_pipeline()
                logger.info("ğŸ”¥ Warmup completed! Engine is ready.")
            except Exception as e:
                logger.error(f"ğŸ”¥ Warmup failed: {e}")

    def cleanup(self):
        """
        æ¸…ç†æ¨ç†äº§ç”Ÿçš„æ˜¾å­˜ï¼ˆä¸å¸è½½æ¨¡å‹ï¼‰
        """
        try:
            import paddle
            import gc

            # æ¸…ç† PaddlePaddle æ˜¾å­˜
            if paddle.device.is_compiled_with_cuda():
                paddle.device.cuda.empty_cache()
                logger.debug("ğŸ§¹ PaddleOCR-VL: CUDA cache cleared")

            # æ¸…ç† Python å¯¹è±¡
            gc.collect()

            logger.debug("ğŸ§¹ PaddleOCR-VL: Memory cleanup completed")
        except Exception as e:
            logger.debug(f"Memory cleanup warning: {e}")

    def parse(self, file_path: str, output_path: str, **kwargs) -> Dict[str, Any]:
        """
        è§£ææ–‡æ¡£æˆ–å›¾ç‰‡

        Args:
            file_path: è¾“å…¥æ–‡ä»¶è·¯å¾„
            output_path: è¾“å‡ºç›®å½•
            **kwargs: å…¶ä»–å‚æ•°

        Returns:
            è§£æç»“æœï¼ˆåŒæ—¶ä¿å­˜ Markdown å’Œ JSON ä¸¤ç§æ ¼å¼ï¼‰
        """
        file_path = Path(file_path)
        output_path = Path(output_path)
        output_path.mkdir(parents=True, exist_ok=True)

        logger.info(f"ğŸ¤– PaddleOCR-VL parsing: {file_path.name}")
        
        # åŠ è½½ç®¡é“
        pipeline = self._load_pipeline()

        # æ‰§è¡Œæ¨ç†
        try:
            logger.info("ğŸš€ å¼€å§‹ä½¿ç”¨ PaddleOCR-VL è¯†åˆ«...")
            
            # PaddleX v3 predict æ–¹æ³•å‚æ•°
            # use_doc_orientation_classify: å¯ç”¨æ–‡æ¡£æ–¹å‘åˆ†ç±»
            # use_doc_unwarping: å¯ç”¨æ–‡æ¡£çŸ«æ­£
            # use_layout_parsing: å¯ç”¨ç‰ˆé¢åˆ†æ
            result = pipeline.predict(
                str(file_path),
                use_doc_orientation_classify=True,
                use_doc_unwarping=True,
                use_layout_parsing=True
            )
            
            # ç»“æœå¯èƒ½æ˜¯ä¸€ä¸ªç”Ÿæˆå™¨æˆ–åˆ—è¡¨
            results = list(result)

            logger.info("âœ… PaddleOCR-VL completed")
            logger.info(f"   è¯†åˆ«äº† {len(results)} é¡µ/å¼ ")

            markdown_list = []

            for idx, res in enumerate(results, 1):
                logger.info(f"ğŸ“ å¤„ç†ç»“æœ {idx}/{len(results)}")

                try:
                    # ä¸ºæ¯é¡µåˆ›å»ºå­ç›®å½•
                    page_output_dir = output_path / f"page_{idx}"
                    page_output_dir.mkdir(parents=True, exist_ok=True)

                    # ä¿å­˜å¯è§†åŒ–ç»“æœå’ŒJSON
                    if hasattr(res, "save_to_img"):
                        res.save_to_img(str(page_output_dir))
                    if hasattr(res, "save_to_json"):
                        res.save_to_json(str(page_output_dir))
                    
                    # å°è¯•ä¿å­˜ Markdown (å¦‚æœæ”¯æŒ)
                    if hasattr(res, "save_to_markdown"):
                        res.save_to_markdown(str(page_output_dir))

                    # æ”¶é›† Markdown å†…å®¹
                    md_content = ""
                    if hasattr(res, "markdown"):
                        # å¦‚æœ res.markdown æ˜¯å¯¹è±¡ï¼Œå°è¯•è½¬å­—ç¬¦ä¸²
                        md_content = str(res.markdown)
                    elif hasattr(res, "str"):
                         md_content = str(res.str)
                    
                    if md_content:
                        markdown_list.append(md_content)

                except Exception as e:
                    logger.warning(f"   é¡µå¤„ç†å‡ºé”™: {e}")
            
            # åˆå¹¶ Markdown
            markdown_text = ""
            
            # ä¼˜å…ˆä½¿ç”¨ pipeline è‡ªå¸¦çš„åˆå¹¶æ–¹æ³•ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if hasattr(pipeline, "concatenate_markdown_pages") and markdown_list:
                try:
                    markdown_text = pipeline.concatenate_markdown_pages(markdown_list)
                    logger.info("   ä½¿ç”¨å®˜æ–¹ concatenate_markdown_pages() æ–¹æ³•åˆå¹¶")
                except Exception as e:
                    logger.warning(f"   åˆå¹¶å¤±è´¥ï¼Œé™çº§ä¸ºæ‰‹åŠ¨åˆå¹¶: {e}")
                    markdown_text = "\n\n---\n\n".join(markdown_list)
            elif markdown_list:
                # æ‰‹åŠ¨åˆå¹¶
                markdown_text = "\n\n---\n\n".join(markdown_list)
            
            # å¦‚æœæ²¡æœ‰ç›´æ¥è·å¾— markdownï¼Œå°è¯•è¯»å–ç”Ÿæˆçš„ .md æ–‡ä»¶
            if not markdown_text:
                logger.info("   å°è¯•ä»è¾“å‡ºç›®å½•è¯»å– Markdown æ–‡ä»¶...")
                for md_file in output_path.rglob("*.md"):
                    if md_file.name != "result.md": # æ’é™¤è‡ªå·±
                        text = md_file.read_text(encoding="utf-8")
                        markdown_text += text + "\n\n---\n\n"

            # ä¿å­˜æœ€ç»ˆç»“æœ
            markdown_file = output_path / "result.md"
            markdown_file.write_text(markdown_text, encoding="utf-8")
            logger.info(f"ğŸ“„ Markdown å·²ä¿å­˜: {markdown_file}")

            return {
                "success": True,
                "output_path": str(output_path),
                "markdown": markdown_text,
                "markdown_file": str(markdown_file),
            }

        except Exception as e:
            logger.error(f"âŒ OCR è§£æå¤±è´¥: {e}")
            import traceback
            logger.debug(traceback.format_exc())
            raise

        finally:
            self.cleanup()


# å…¨å±€å•ä¾‹
_engine = None


def get_engine(model_name: str = "PaddleOCR-VL-1.5-0.9B") -> PaddleOCRVLEngine:
    """
    è·å–å…¨å±€å¼•æ“å®ä¾‹
    æ³¨æ„ï¼šå•ä¾‹æ¨¡å¼ä¸‹ï¼Œç¬¬ä¸€æ¬¡è°ƒç”¨æ—¶çš„ model_name ä¼šå†³å®šåç»­ä¸€ç›´ä½¿ç”¨çš„æ¨¡å‹
    """
    global _engine
    if _engine is None:
        _engine = PaddleOCRVLEngine(model_name=model_name)
    return _engine
