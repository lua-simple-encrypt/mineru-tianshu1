#!/usr/bin/env python3
"""
æ¨¡å‹é¢„ä¸‹è½½è„šæœ¬ - Tianshu (Runtime Auto-Download for Paddle + Pre-download for others)

ç­–ç•¥è¯´æ˜:
1. MinerU / YOLO / Audio / PaddleOCR-VL æ¨¡å‹: ä½¿ç”¨æ­¤è„šæœ¬é¢„å…ˆä¸‹è½½åˆ° ./models ç›®å½•ã€‚
2. å…¶ä»–æ™®é€š PaddleOCR / PaddleX æ¨¡å‹:  è®¾ç½®ä¸º auto_downloadã€‚
   - å®ƒä»¬å°†åœ¨å®¹å™¨è¿è¡Œæ—¶ç”±å¼•æ“è‡ªåŠ¨ä¸‹è½½ã€‚
   - æ•°æ®ä¼šæŒä¹…åŒ–ä¿å­˜åˆ°å®¿ä¸»æœºçš„ ./models/paddlex_cache å’Œ ./models/paddleocr_cache ç›®å½•ä¸­ã€‚
   - (é€šè¿‡ docker-compose.yml çš„ /root/.paddlex å’Œ /root/.paddleocr æŒ‚è½½å®ç°)
"""

import os
import sys
import json
import argparse
from pathlib import Path
from datetime import datetime
from loguru import logger

# é…ç½®æ—¥å¿—
logger.remove()
logger.add(sys.stdout, format="<green>{time:HH:mm:ss}</green> | <level>{level: <8}</level> | <level>{message}</level>")

# ==============================================================================
# æ¨¡å‹é…ç½®æ¸…å•
# ==============================================================================
MODELS = {
    # -------------------------------------------------------------------------
    # 1. MinerU æ ¸å¿ƒæ¨¡å‹ (éœ€è¦é¢„ä¸‹è½½)
    # -------------------------------------------------------------------------
    "mineru_pipeline": {
        "name": "MinerU Pipeline (PDF-Extract-Kit)",
        "repo_id": "OpenDataLab/PDF-Extract-Kit-1.0",
        "source": "modelscope",
        "target_dir": "PDF-Extract-Kit-1.0",
        "description": "PDF OCR, Layout Analysis models (For 'pipeline' mode)",
        "required": True
    },
    "mineru_vlm": {
        "name": "MinerU 2.5 VLM (1.2B)",
        "model_id": "opendatalab/MinerU2.5-2509-1.2B",
        "source": "modelscope",
        "target_dir": "MinerU2.5-2509-1.2B",
        "description": "Vision Language Model (For 'vlm-auto-engine' & 'hybrid-auto-engine')",
        "required": True
    },

    # -------------------------------------------------------------------------
    # 2. PaddleX / PaddleOCR æ¨¡å‹ 
    # -------------------------------------------------------------------------
    
    # --- å¤šæ¨¡æ€æ–‡æ¡£è§£æ (VLM) - å¼ºåˆ¶é¢„ä¸‹è½½ä¾› vLLM æœåŠ¡ä½¿ç”¨ ---
    "paddleocr_vl_1_5": {
        "name": "PaddleOCR-VL-1.5-0.9B",
        "repo_id": "PaddlePaddle/PaddleOCR-VL-1.5",
        "source": "huggingface",
        "target_dir": "paddlex_cache/official_models/PaddleOCR-VL-1.5-0.9B",
        "description": "Pre-downloaded for vLLM Server to avoid crash loops",
        "required": True
    },
    "paddleocr_vl_0_9": {
        "name": "PaddleOCR-VL-0.9B",
        "repo_id": "PaddlePaddle/PaddleOCR-VL",
        "source": "huggingface",
        "target_dir": "paddlex_cache/official_models/PaddleOCR-VL-0.9B",
        "description": "Pre-downloaded for vLLM Server to avoid crash loops",
        "required": False
    },

    # --- ç‰ˆé¢åˆ†æ (Layout) - è¿è¡Œæ—¶è‡ªåŠ¨ä¸‹è½½ ---
    "pp_doclayout_v3": {
        "name": "PP-DocLayoutV3",
        "auto_download": True,
        "description": "Runtime auto-download to ./models/paddlex_cache/",
        "required": False
    },
    "pp_doclayout_v2": {
        "name": "PP-DocLayoutV2",
        "auto_download": True, 
        "required": False
    },
    "pp_doclayout_plus_l": {
        "name": "PP-DocLayout_plus-L",
        "auto_download": True,
        "required": False
    },
    "pp_docblocklayout": {
        "name": "PP-DocBlockLayout",
        "auto_download": True,
        "required": False
    },

    # --- æ–‡æ¡£çŸ«æ­£/æ–¹å‘åˆ†ç±» - è¿è¡Œæ—¶è‡ªåŠ¨ä¸‹è½½ ---
    "pp_lcnet_doc_ori": {
        "name": "PP-LCNet_x1_0_doc_ori",
        "auto_download": True,
        "description": "Runtime auto-download to ./models/paddlex_cache/",
        "required": False
    },
    "pp_lcnet_textline_ori": {
        "name": "PP-LCNet_x1_0_textline_ori",
        "auto_download": True,
        "required": False
    },
    "pp_lcnet_x0_25_textline_ori": {
        "name": "PP-LCNet_x0_25_textline_ori",
        "auto_download": True,
        "required": False
    },
    "uvdoc": {
        "name": "UVDoc (Doc Unwarping)",
        "auto_download": True,
        "description": "Runtime auto-download to ./models/paddlex_cache/",
        "required": False
    },

    # --- é€šç”¨ OCR (PP-OCRv5) - è¿è¡Œæ—¶è‡ªåŠ¨ä¸‹è½½ ---
    "pp_ocrv5_det": {
        "name": "PP-OCRv5_mobile_det",
        "auto_download": True,
        "required": False
    },
    "pp_ocrv5_rec": {
        "name": "PP-OCRv5_mobile_rec",
        "auto_download": True,
        "required": False
    },
    "pp_ocrv5_server_rec": {
        "name": "PP-OCRv5_server_rec",
        "auto_download": True,
        "required": False
    },
    "pp_ocrv4_server_seal_det": {
        "name": "PP-OCRv4_server_seal_det",
        "auto_download": True,
        "required": False
    },

    # --- å¤šè¯­è¨€ OCR - è¿è¡Œæ—¶è‡ªåŠ¨ä¸‹è½½ ---
    "eslav_pp_ocrv5_mobile_rec": {
        "name": "eslav_PP-OCRv5_mobile_rec",
        "auto_download": True,
        "required": False
    },
    "korean_pp_ocrv5_mobile_rec": {
        "name": "korean_PP-OCRv5_mobile_rec",
        "auto_download": True,
        "required": False
    },
    "latin_pp_ocrv5_mobile_rec": {
        "name": "latin_PP-OCRv5_mobile_rec",
        "auto_download": True,
        "required": False
    },

    # --- å…¬å¼/è¡¨æ ¼è¯†åˆ« - è¿è¡Œæ—¶è‡ªåŠ¨ä¸‹è½½ ---
    "pp_formulanet": {
        "name": "PP-FormulaNet_plus-L",
        "auto_download": True,
        "required": False
    },
    "pp_lcnet_table_cls": {
        "name": "PP-LCNet_x1_0_table_cls",
        "auto_download": True,
        "required": False
    },
    "pp_chart2table": {
        "name": "PP-Chart2Table",
        "auto_download": True,
        "required": False
    },
    "slanext_wired": {
        "name": "SLANeXt_wired",
        "auto_download": True,
        "required": False
    },
    "slanet_plus": {
        "name": "SLANet_plus",
        "auto_download": True,
        "required": False
    },
    "rtdetr_wired": {
        "name": "RT-DETR-L_wired_table_cell_det",
        "auto_download": True,
        "required": False
    },
    "rtdetr_wireless": {
        "name": "RT-DETR-L_wireless_table_cell_det",
        "auto_download": True,
        "required": False
    },

    # -------------------------------------------------------------------------
    # 3. å…¶ä»–æ¨¡å‹ (éœ€è¦é¢„ä¸‹è½½)
    # -------------------------------------------------------------------------
    "sensevoice": {
        "name": "SenseVoice Audio Recognition",
        "model_id": "iic/SenseVoiceSmall",
        "source": "modelscope",
        "target_dir": "SenseVoiceSmall",
        "description": "Multi-language speech recognition model",
        "required": True
    },
    "paraformer": {
        "name": "Paraformer Speaker Diarization",
        "model_id": "iic/speech_seaco_paraformer_large_asr_nat-zh-cn-16k-common-vocab8404-pytorch",
        "source": "modelscope",
        "target_dir": "Paraformer",
        "description": "Speaker diarization and VAD model",
        "required": False
    },
    "yolo11": {
        "name": "YOLO11x Watermark Detection",
        "repo_id": "corzent/yolo11x_watermark_detection",
        "filename": "best.pt",
        "source": "huggingface",
        "target_dir": "YOLO11",
        "description": "Watermark detection model",
        "required": False
    },
    "lama": {
        "name": "LaMa Watermark Inpainting",
        "auto_download": True,
        "description": "Will be downloaded by simple_lama_inpainting on first use",
        "required": False
    }
}

# ==============================================================================
# ä¸‹è½½å‡½æ•°
# ==============================================================================

def download_from_huggingface(repo_id, target_dir, filename=None):
    """ä» HuggingFace ä¸‹è½½"""
    try:
        from huggingface_hub import snapshot_download, hf_hub_download
        
        # é…ç½®å›½å†…é•œåƒ
        hf_endpoint = os.getenv("HF_ENDPOINT", "https://hf-mirror.com")
        os.environ.setdefault("HF_ENDPOINT", hf_endpoint)
        
        if filename:
            logger.info(f"   Downloading file: {filename}")
            path = hf_hub_download(
                repo_id=repo_id, 
                filename=filename, 
                local_dir=str(target_dir), 
                local_dir_use_symlinks=False, 
                resume_download=True
            )
        else:
            logger.info(f"   Downloading repository: {repo_id}")
            path = snapshot_download(
                repo_id=repo_id, 
                local_dir=str(target_dir), 
                local_dir_use_symlinks=False, 
                resume_download=True
            )
        return path
    except Exception as e:
        logger.error(f"   âŒ Download failed: {e}")
        return None

def download_from_modelscope(model_id, target_dir):
    """ä» ModelScope ä¸‹è½½"""
    try:
        from modelscope import snapshot_download
        
        logger.info(f"   Downloading from ModelScope: {model_id}")
        path = snapshot_download(
            model_id, 
            local_dir=str(target_dir), 
            revision="master"
        )
        return path
    except Exception as e:
        logger.error(f"   âŒ Download failed: {e}")
        return None

# ==============================================================================
# éªŒè¯ä¸è¾…åŠ©å‡½æ•°
# ==============================================================================

def verify_model_files(path, model_name):
    """éªŒè¯ä¸‹è½½æ˜¯å¦å®Œæ•´"""
    path_obj = Path(path)
    if not path_obj.exists(): return False

    # 1. MinerU Pipeline
    if model_name == "mineru_pipeline":
        if not (any(path_obj.rglob("*.safetensors")) or any(path_obj.rglob("*.bin"))):
            if (path_obj / "models").exists(): return True
            logger.warning(f"   âš ï¸  No model files in {path}")
            return False
            
    # 2. MinerU VLM
    elif model_name == "mineru_vlm":
        if not any(path_obj.rglob("*.safetensors")):
            logger.warning(f"   âš ï¸  No safetensors found in {path}")
            return False
    
    # 3. PaddleOCR-VL VLM æ¨¡å‹éªŒè¯
    elif model_name in ["paddleocr_vl_1_5", "paddleocr_vl_0_9"]:
        if not any(path_obj.rglob("*.safetensors")):
            logger.warning(f"   âš ï¸  No safetensors found in {path}")
            return False
            
    # 4. YOLO (å•æ–‡ä»¶æˆ–ç›®å½•)
    elif model_name == "yolo11":
        if path_obj.is_file():
            if path_obj.suffix != ".pt":
                return False
        elif not list(path_obj.rglob("*.pt")):
            logger.warning(f"   âš ï¸  No .pt files found")
            return False
            
    logger.info(f"   âœ… Model files verified")
    return True

def get_directory_size(path):
    path_obj = Path(path)
    if not path_obj.exists(): return 0
    if path_obj.is_file(): return path_obj.stat().st_size / (1024 * 1024)
    return sum(f.stat().st_size for f in path_obj.rglob("*") if f.is_file()) / (1024 * 1024)

def check_model_exists(output_path, config, name):
    target_dir = output_path / config["target_dir"]
    if config.get("filename"):
        f = target_dir / config["filename"]
        return (f.exists() and f.stat().st_size > 0), "File found"
    if not target_dir.exists(): return False, "Dir missing"
    if any(target_dir.iterdir()): return True, "Files found"
    return False, "Dir empty"

def generate_magic_pdf_json(output_dir):
    """ç”Ÿæˆ magic-pdf.jsonï¼ŒåŒæ—¶é…ç½® Pipeline å’Œ VLM"""
    project_root = Path(output_dir).parent
    config_path = project_root / "magic-pdf.json"
    
    # æ³¨æ„ï¼šè¿™é‡Œçš„è·¯å¾„æ˜¯ Docker å®¹å™¨å†…çš„è·¯å¾„
    # models-dir æŒ‡å‘ MinerU Pipeline çš„ models å­ç›®å½•
    config_content = r"""{
  "models-dir": "/app/models/PDF-Extract-Kit-1.0/models",
  "vlm-models-dir": "/app/models/MinerU2.5-2509-1.2B",
  "device-mode": "cuda",
  "layout-config": {
    "model": "doclayout_yolo"
  },
  "formula-config": {
    "mfd_model": "yolo_v8_mfd",
    "mre_model": "unimernet_small"
  }
}"""
    try:
        with open(config_path, "w", encoding="utf-8") as f:
            f.write(config_content)
        logger.success(f"âœ… Configuration file created at: {config_path}")
        logger.info("   -> Confirmed support for: pipeline, vlm-auto-engine, hybrid-auto-engine")
    except Exception as e:
        logger.error(f"âŒ Failed to create config: {e}")

# ==============================================================================
# ä¸»ç¨‹åº
# ==============================================================================

def main(output_dir, selected_models=None, force=False):
    logger.info("=" * 60)
    logger.info("ğŸš€ Tianshu Model Download Script (Hybrid Strategy)")
    logger.info("=" * 60)

    output_path = Path(output_dir).resolve()
    output_path.mkdir(parents=True, exist_ok=True)
    logger.info(f"ğŸ“ Output directory (Container/Host mapped): {output_path}")

    # ç­›é€‰æ¨¡å‹
    models_to_download = MODELS
    if selected_models:
        selected_list = [m.strip() for m in selected_models.split(",")]
        models_to_download = {k: v for k, v in MODELS.items() if k in selected_list}

    manifest = {"created": datetime.now().isoformat(), "models": {}, "total_size_mb": 0}
    total_dl, total_skip, total_fail = 0, 0, 0

    for name, config in models_to_download.items():
        logger.info(f"ğŸ“¦ [{name.upper()}] {config['name']}")
        
        try:
            # ç­–ç•¥ï¼šè‡ªåŠ¨ä¸‹è½½æ¨¡å‹ï¼ˆPaddleç­‰ï¼‰ç›´æ¥è·³è¿‡
            if config.get("auto_download"):
                logger.info(f"   â„¹ï¸  {name} will be auto-downloaded by runtime engine")
                logger.info(f"       Target: {config.get('description', 'Cache directory')}")
                manifest["models"][name] = {"status": "auto_download"}
                continue

            target = output_path / config["target_dir"]
            
            # æ£€æŸ¥å­˜åœ¨
            if not force:
                exists, reason = check_model_exists(output_path, config, name)
                if exists:
                    size_mb = get_directory_size(target)
                    logger.info(f"   âœ… Already exists ({size_mb:.1f} MB)")
                    logger.info(f"   ğŸ“‚ Path: {target}")
                    manifest["models"][name] = {"status": "exists", "path": str(target), "size_mb": round(size_mb, 2)}
                    total_skip += 1
                    logger.info("")
                    continue

            # ä¸‹è½½
            logger.info(f"   â¬‡ï¸  Downloading to {config['target_dir']}...")
            path = None
            src = config["source"]
            
            if src == "huggingface":
                path = download_from_huggingface(
                    config["repo_id"], 
                    str(target), 
                    config.get("filename")
                )
            elif src == "modelscope":
                # ä¼˜å…ˆä½¿ç”¨ model_idï¼Œå¦‚æœæ²¡æœ‰åˆ™ç”¨ repo_id (å…¼å®¹æ—§é…ç½®)
                mid = config.get("model_id") or config.get("repo_id")
                path = download_from_modelscope(mid, str(target))

            # âœ… æ ¸å¿ƒä¼˜åŒ–ï¼šå®¹é”™å¤„ç†
            if path and verify_model_files(path, name):
                size_mb = get_directory_size(path)
                manifest["models"][name] = {"status": "downloaded", "path": str(path)}
                logger.info(f"   âœ… Success ({size_mb:.1f} MB)")
                logger.info(f"   ğŸ“‚ Path: {path}")
                total_dl += 1
            else:
                logger.error(f"   âŒ Validation failed for {name}")
                if config.get("required", False):
                    total_fail += 1
                else:
                    logger.warning(f"   âš ï¸ [IGNORED] Optional model {name} failed, but not required. Skipping...")

        except Exception as e:
            logger.error(f"   âŒ Error: {e}")
            if config.get("required", False):
                total_fail += 1
            else:
                logger.warning(f"   âš ï¸ [IGNORED] Optional model {name} failed, but not required. Skipping...")
        logger.info("")

    generate_magic_pdf_json(output_path)
    
    with open(output_path / "manifest.json", "w", encoding="utf-8") as f:
        json.dump(manifest, f, indent=2)

    logger.info("=" * 60)
    logger.info(f"âœ… Downloaded: {total_dl} | â­ï¸  Skipped: {total_skip} | âŒ Failed: {total_fail}")
    
    # åªè¦å¿…å¡«é¡¹æ²¡æœ‰å¤±è´¥ï¼Œè„šæœ¬å³ä»¥ 0 çŠ¶æ€é€€å‡ºï¼Œç¡®ä¿åç»­æœåŠ¡(å¦‚ vllm)èƒ½å¤Ÿå¯åŠ¨
    return 0 if total_fail == 0 else 1

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--output", default="./models")
    parser.add_argument("--models")
    parser.add_argument("--force", action="store_true")
    args = parser.parse_args()
    
    try:
        sys.exit(main(args.output, args.models, args.force))
    except KeyboardInterrupt:
        sys.exit(130)
