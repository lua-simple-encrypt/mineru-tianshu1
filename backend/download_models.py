#!/usr/bin/env python3
"""
æ¨¡å‹é¢„ä¸‹è½½è„šæœ¬ - ä¸º CPU/GPU ç¦»çº¿éƒ¨ç½²å‡†å¤‡æ‰€æœ‰å¿…éœ€æ¨¡å‹ (æ‰å¹³åŒ–ç›®å½•ç‰ˆ)

åŠŸèƒ½:
1. ä¸‹è½½ MinerU æ¨¡å‹åˆ° models/PDF-Extract-Kit-1.0
2. ä¸‹è½½ PaddleOCR æ¨¡å‹åˆ° models/PaddleOCR-VL-1.5
3. ä¸‹è½½ SenseVoice ç­‰å…¶ä»–æ¨¡å‹åˆ°å¯¹åº”ä¸€çº§ç›®å½•
4. è‡ªåŠ¨ç”Ÿæˆ magic-pdf.json é…ç½®æ–‡ä»¶
5. ç”Ÿæˆæ¨¡å‹æ¸…å• manifest.json
"""

import os
import sys
import json
import argparse
from pathlib import Path
from datetime import datetime
from loguru import logger

# é…ç½®æ—¥å¿—
logger.remove()
logger.add(sys.stdout, format="<green>{time:HH:mm:ss}</green> | <level>{level: <8}</level> | <level>{message}</level>")

# ==============================================================================
# æ¨¡å‹é…ç½® (ä¿®æ”¹ï¼štarget_dir æ”¹ä¸ºä¸€çº§ç›®å½•ï¼ŒPaddleOCR æ”¹ä¸ºæ˜¾å¼ä¸‹è½½)
# ==============================================================================
MODELS = {
    "mineru": {
        "name": "MinerU PDF-Extract-Kit",
        "repo_id": "OpenDataLab/PDF-Extract-Kit-1.0",
        "source": "modelscope",  # å»ºè®®ä½¿ç”¨ modelscope é€Ÿåº¦æ›´å¿«
        "target_dir": "PDF-Extract-Kit-1.0", # ä¿®æ”¹ï¼šç›´æ¥ä¸‹è½½åˆ° models/PDF-Extract-Kit-1.0
        "description": "PDF OCR and layout analysis models",
        "required": True
    },
    "paddleocr": {
        "name": "PaddleOCR-VL 1.5",
        "model_id": "OpenDataLab/PaddleOCR-VL-1.5", # æŒ‡å®šæ¨¡å‹ ID
        "source": "modelscope",
        "auto_download": False,          # ä¿®æ”¹ï¼šå…³é—­è‡ªåŠ¨ä¸‹è½½ï¼Œç”±è„šæœ¬æ§åˆ¶è·¯å¾„
        "target_dir": "PaddleOCR-VL-1.5", # ä¿®æ”¹ï¼šç›´æ¥ä¸‹è½½åˆ° models/PaddleOCR-VL-1.5
        "description": "PaddlePaddle Vision-Language OCR model",
        "required": True
    },
    "sensevoice": {
        "name": "SenseVoice Audio Recognition",
        "model_id": "iic/SenseVoiceSmall",
        "source": "modelscope",
        "target_dir": "SenseVoiceSmall", # ä¿®æ”¹ï¼šæ‰å¹³åŒ–ç›®å½•
        "description": "Multi-language speech recognition model",
        "required": True
    },
    "paraformer": {
        "name": "Paraformer Speaker Diarization",
        "model_id": "iic/speech_seaco_paraformer_large_asr_nat-zh-cn-16k-common-vocab8404-pytorch",
        "source": "modelscope",
        "target_dir": "Paraformer", # ä¿®æ”¹ï¼šæ‰å¹³åŒ–ç›®å½•
        "description": "Speaker diarization and VAD model",
        "required": False
    },
    "yolo11": {
        "name": "YOLO11x Watermark Detection",
        "repo_id": "corzent/yolo11x_watermark_detection",
        "filename": "best.pt",
        "source": "huggingface",
        "target_dir": "YOLO11", # ä¿®æ”¹ï¼šæ‰å¹³åŒ–ç›®å½•
        "description": "Watermark detection model for document processing",
        "required": False
    },
    "lama": {
        "name": "LaMa Watermark Inpainting",
        "auto_download": True, # LaMa ä¿æŒåº“å†…éƒ¨è‡ªåŠ¨å¤„ç†
        "description": "Will be downloaded by simple_lama_inpainting on first use",
        "required": False
    }
}


def download_from_huggingface(repo_id, target_dir, filename=None):
    """ä» HuggingFace ä¸‹è½½æ¨¡å‹ (ä¿®æ”¹ï¼šä½¿ç”¨ local_dir)"""
    try:
        from huggingface_hub import snapshot_download, hf_hub_download

        # é…ç½®é•œåƒï¼ˆå›½å†…åŠ é€Ÿï¼‰
        hf_endpoint = os.getenv("HF_ENDPOINT", "https://hf-mirror.com")
        os.environ.setdefault("HF_ENDPOINT", hf_endpoint)

        if filename:
            # ä¸‹è½½å•ä¸ªæ–‡ä»¶
            logger.info(f"   Downloading file: {filename}")
            path = hf_hub_download(
                repo_id=repo_id,
                filename=filename,
                local_dir=str(target_dir),      # ä¿®æ”¹ï¼šä½¿ç”¨ local_dir å¼ºåˆ¶æŒ‡å®šç›®å½•
                local_dir_use_symlinks=False,   # ä¿®æ”¹ï¼šç¦ç”¨è½¯é“¾æ¥
                resume_download=True
            )
        else:
            # ä¸‹è½½æ•´ä¸ªä»“åº“
            logger.info(f"   Downloading repository: {repo_id}")
            path = snapshot_download(
                repo_id=repo_id,
                local_dir=str(target_dir),      # ä¿®æ”¹ï¼šä½¿ç”¨ local_dir å¼ºåˆ¶æŒ‡å®šç›®å½•
                local_dir_use_symlinks=False,   # ä¿®æ”¹ï¼šç¦ç”¨è½¯é“¾æ¥
                resume_download=True
            )

        return path

    except ImportError:
        logger.error("   âŒ huggingface_hub not installed. Install: pip install huggingface-hub")
        return None
    except Exception as e:
        logger.error(f"   âŒ Download failed: {e}")
        return None


def download_from_modelscope(model_id, target_dir):
    """ä» ModelScope ä¸‹è½½æ¨¡å‹ (ä¿®æ”¹ï¼šä½¿ç”¨ local_dir)"""
    try:
        from modelscope import snapshot_download

        logger.info(f"   Downloading from ModelScope: {model_id}")
        # ä¿®æ”¹ï¼šä½¿ç”¨ local_dir å‚æ•°ï¼ŒModelScope ä¼šç›´æ¥ä¸‹è½½åˆ°è¯¥ç›®å½•ï¼Œä¸ç”Ÿæˆéšæœºç¼“å­˜å
        path = snapshot_download(
            model_id,
            local_dir=str(target_dir), 
            revision="master"
        )

        return path

    except ImportError:
        logger.error("   âŒ modelscope not installed. Install: pip install modelscope")
        return None
    except Exception as e:
        logger.error(f"   âŒ Download failed: {e}")
        return None


def verify_model_files(path, model_name):
    """éªŒè¯æ¨¡å‹æ–‡ä»¶å®Œæ•´æ€§"""
    if not path or not Path(path).exists():
        return False

    path_obj = Path(path)

    # æ£€æŸ¥å…³é”®æ–‡ä»¶ï¼ˆæ ¹æ®ä¸åŒæ¨¡å‹ç±»å‹ï¼‰
    if model_name == "mineru":
        # å…¼å®¹ä¸¤ç§ç»“æ„
        has_weights = any(path_obj.rglob("*.safetensors")) or any(path_obj.rglob("*.bin"))
        has_subdir = (path_obj / "models").exists()
        if not (has_weights or has_subdir):
            logger.warning(f"   âš ï¸  No model files or 'models' dir found in {path}")
            return False

    elif model_name == "paddleocr":
        # PaddleOCR æ£€æŸ¥
        has_model = any(path_obj.rglob("*.safetensors")) or any(path_obj.rglob("*.pdparams"))
        if not has_model:
             logger.warning(f"   âš ï¸  No PaddleOCR model files found in {path}")
             return False

    elif model_name in ["sensevoice", "paraformer"]:
        config_file = path_obj / "configuration.json"
        if not config_file.exists():
            config_file = path_obj / "config.json"
        if not any(path_obj.iterdir()):
            logger.warning(f"   âš ï¸  Directory is empty: {path}")
            return False

    elif model_name == "yolo11":
        if not list(path_obj.rglob("*.pt")):
            logger.warning(f"   âš ï¸  No .pt files found in {path}")
            return False

    logger.info(f"   âœ… Model files verified")
    return True


def get_directory_size(path):
    """è·å–ç›®å½•å¤§å°ï¼ˆMBï¼‰"""
    if not path or not Path(path).exists():
        return 0
    path_obj = Path(path)
    if path_obj.is_file():
        return path_obj.stat().st_size / (1024 * 1024)
    total_size = sum(f.stat().st_size for f in path_obj.rglob("*") if f.is_file())
    return total_size / (1024 * 1024)


def check_model_exists(output_path, config, name):
    """æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²å­˜åœ¨"""
    target_dir = output_path / config["target_dir"]
    if not target_dir.exists():
        return False, "Directory not found"
    if any(target_dir.iterdir()):
        return True, "Files found"
    return False, "Directory empty"


def generate_magic_pdf_json(output_dir):
    """ç”Ÿæˆ magic-pdf.json é…ç½®æ–‡ä»¶ (æ–°å¢)"""
    project_root = Path(output_dir).parent
    config_path = project_root / "magic-pdf.json"
    
    # è·¯å¾„å¯¹åº”å®¹å™¨å†…çš„æŒ‚è½½ç‚¹ /app/models/PDF-Extract-Kit-1.0/models
    config_content = r"""{
  "models-dir": "/app/models/PDF-Extract-Kit-1.0/models",
  "device-mode": "cuda",
  "layout-config": {
    "model": "layoutlmv3",
    "batch_size": 2
  },
  "formula-config": {
    "mfd_model": "yolo_v8",
    "mre_model": "unimernet",
    "batch_size": 2
  }
}"""
    try:
        with open(config_path, "w", encoding="utf-8") as f:
            f.write(config_content)
        logger.success(f"âœ… Configuration file created at: {config_path}")
    except Exception as e:
        logger.error(f"âŒ Failed to create config file: {e}")


def main(output_dir, selected_models=None, force=False):
    """ä¸»å‡½æ•°"""
    logger.info("=" * 60)
    logger.info("ğŸš€ Tianshu Model Download Script")
    logger.info("=" * 60)

    output_path = Path(output_dir).resolve()
    output_path.mkdir(parents=True, exist_ok=True)

    logger.info(f"ğŸ“ Output directory: {output_path}")
    if force:
        logger.info("âš ï¸  Force mode: Will re-download existing models")
    logger.info("")

    # ç­›é€‰è¦ä¸‹è½½çš„æ¨¡å‹
    models_to_download = MODELS
    if selected_models:
        selected_list = [m.strip() for m in selected_models.split(",")]
        models_to_download = {k: v for k, v in MODELS.items() if k in selected_list}
        logger.info(f"ğŸ“‹ Selected models: {', '.join(models_to_download.keys())}")
    else:
        logger.info(f"ğŸ“‹ Downloading all models ({len(MODELS)} total)")

    logger.info("")

    manifest = {
        "created": datetime.now().isoformat(),
        "platform": "cpu",
        "output_dir": str(output_path),
        "models": {},
        "total_size_mb": 0
    }

    total_downloaded = 0
    total_skipped = 0
    total_failed = 0

    # ä¸‹è½½æ¯ä¸ªæ¨¡å‹
    for name, config in models_to_download.items():
        logger.info(f"ğŸ“¦ [{name.upper()}] {config['name']}")
        logger.info(f"   {config['description']}")

        try:
            if config.get("auto_download"):
                logger.info(f"   â„¹ï¸  {name} will be downloaded automatically by library")
                
                # è®°å½• auto_download çš„æ¨¡å‹åˆ° manifest
                manifest["models"][name] = {
                    "name": config["name"],
                    "status": "auto_download",
                    "description": config["description"]
                }
                continue

            # åˆ›å»ºç›®æ ‡ç›®å½•
            target = output_path / config["target_dir"]
            target.mkdir(parents=True, exist_ok=True)

            # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²å­˜åœ¨
            if not force:
                exists, reason = check_model_exists(output_path, config, name)
                if exists:
                    size_mb = get_directory_size(target)
                    logger.info(f"   âœ… Already exists ({size_mb:.1f} MB)")
                    logger.info(f"   ğŸ“‚ Path: {target}")
                    manifest["models"][name] = {"status": "exists", "path": str(target), "size_mb": round(size_mb, 2)}
                    total_skipped += 1
                    logger.info("")
                    continue
                else:
                    logger.info(f"   â„¹ï¸  Not found: {reason}")

            # ä¸‹è½½æ¨¡å‹
            logger.info(f"   â¬‡ï¸  Downloading...")
            path = None
            if config["source"] == "huggingface":
                path = download_from_huggingface(
                    config.get("repo_id"), # ModelScope å…¼å®¹
                    str(target), 
                    config.get("filename")
                )
            elif config["source"] == "modelscope":
                # ä¼˜å…ˆä½¿ç”¨ model_idï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨ repo_id
                mid = config.get("model_id") or config.get("repo_id")
                path = download_from_modelscope(mid, str(target))

            if path:
                if verify_model_files(path, name):
                    size_mb = get_directory_size(path)
                    manifest["models"][name] = {"status": "downloaded", "path": str(path), "size_mb": round(size_mb, 2)}
                    logger.info(f"   âœ… Downloaded successfully ({size_mb:.1f} MB)")
                    logger.info(f"   ğŸ“‚ Path: {path}")
                    total_downloaded += 1
                else:
                    total_failed += 1
            else:
                total_failed += 1

        except Exception as e:
            logger.error(f"   âŒ Error downloading {name}: {e}")
            total_failed += 1
        logger.info("")

    # è‡ªåŠ¨ç”Ÿæˆé…ç½®æ–‡ä»¶
    generate_magic_pdf_json(output_path)

    # ä¿å­˜æ¸…å•
    manifest_file = output_path / "manifest.json"
    with open(manifest_file, "w", encoding="utf-8") as f:
        json.dump(manifest, f, indent=2, ensure_ascii=False)

    # è¾“å‡ºæ€»ç»“
    logger.info("=" * 60)
    logger.info("ğŸ“Š Download Summary")
    logger.info("=" * 60)
    logger.info(f"âœ… Successfully downloaded: {total_downloaded} models")
    if total_skipped > 0:
        logger.info(f"â­ï¸  Skipped (already exists): {total_skipped} models")
    logger.info(f"âŒ Failed: {total_failed} models")
    logger.info(f"ğŸ“„ Manifest saved to: {manifest_file}")
    logger.info(f"ğŸ“„ Config saved to: {output_path.parent / 'magic-pdf.json'}")
    logger.info("")

    return 0


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Download models for Tianshu (Flat Directory)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Download models to ./models
  python download_models.py --output ./models

  # Force re-download
  python download_models.py --force
        """
    )
    parser.add_argument(
        "--output",
        default="./models-offline",
        help="Output directory for downloaded models (default: ./models-offline)"
    )
    parser.add_argument(
        "--models",
        help="Comma-separated list of models to download (default: all)"
    )
    parser.add_argument(
        "--force",
        action="store_true",
        help="Force re-download all models"
    )

    args = parser.parse_args()

    try:
        exit_code = main(args.output, args.models, args.force)
        sys.exit(exit_code)
    except KeyboardInterrupt:
        logger.warning("\nâš ï¸  Download interrupted by user")
        sys.exit(130)
    except Exception as e:
        logger.error(f"\nâŒ Fatal error: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
