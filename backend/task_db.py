"""
MinerU Tianshu - SQLite Task Database Manager
å¤©æ¢ä»»åŠ¡æ•°æ®åº“ç®¡ç†å™¨

è´Ÿè´£ä»»åŠ¡çš„æŒä¹…åŒ–å­˜å‚¨ã€çŠ¶æ€ç®¡ç†å’ŒåŸå­æ€§æ“ä½œ

æ¶æ„è¯´æ˜ (Hybrid Queue):
    - SQLite: ä»»åŠ¡å…ƒæ•°æ®å­˜å‚¨ã€å†å²è®°å½•ã€ç»“æœç®¡ç†
    - Redis (å¯é€‰): é«˜æ€§èƒ½ä»»åŠ¡é˜Ÿåˆ—ã€ä¼˜å…ˆçº§è°ƒåº¦
    - å½“ Redis å¯ç”¨æ—¶ï¼Œé˜Ÿåˆ—æ“ä½œç”± Redis å¤„ç†
    - å½“ Redis ä¸å¯ç”¨æ—¶ï¼Œè‡ªåŠ¨å›é€€åˆ° SQLite

æ›´æ–°æ—¥å¿—:
    - [æ–°å¢] data å­—æ®µæ”¯æŒï¼Œç”¨äºå­˜å‚¨ json_content å’Œ pdf_path ç­‰æ‰©å±•å…ƒæ•°æ®
    - [ä¿®å¤] clear_failed_tasks å¢åŠ ç‰©ç†æ–‡ä»¶åˆ é™¤é€»è¾‘
"""

import sqlite3
import json
import uuid
import shutil
import os
from contextlib import contextmanager
from typing import Optional, List, Dict
from pathlib import Path
from loguru import logger

# å¯¼å…¥ Redis é˜Ÿåˆ—ï¼ˆå¯é€‰ï¼‰
try:
    from redis_queue import get_redis_queue

    REDIS_QUEUE_AVAILABLE = True
except ImportError:
    REDIS_QUEUE_AVAILABLE = False

    def get_redis_queue():
        return None


class TaskDB:
    """ä»»åŠ¡æ•°æ®åº“ç®¡ç†ç±»"""

    def __init__(self, db_path=None):
        # å¯¼å…¥æ‰€éœ€æ¨¡å—
        import os
        from pathlib import Path

        # ä¼˜å…ˆä½¿ç”¨ä¼ å…¥çš„è·¯å¾„ï¼Œå…¶æ¬¡ä½¿ç”¨ç¯å¢ƒå˜é‡ï¼Œæœ€åä½¿ç”¨é»˜è®¤è·¯å¾„
        if db_path is None:
            # è·å–é¡¹ç›®æ ¹ç›®å½•
            project_root = Path(__file__).parent.parent
            default_db = project_root / "data" / "db" / "mineru_tianshu.db"
            db_path = os.getenv("DATABASE_PATH", str(default_db))
            # ç¡®ä¿çˆ¶ç›®å½•å­˜åœ¨
            Path(db_path).parent.mkdir(parents=True, exist_ok=True)
            # ç¡®ä¿ä½¿ç”¨ç»å¯¹è·¯å¾„
            db_path = str(Path(db_path).resolve())
        else:
            # ç¡®ä¿ä½¿ç”¨ç»å¯¹è·¯å¾„
            db_path = str(Path(db_path).resolve())

        # ç¡®ä¿ db_path æ˜¯ç»å¯¹è·¯å¾„å­—ç¬¦ä¸²
        self.db_path = str(Path(db_path).resolve())
        self._init_db()

    def _get_conn(self):
        """è·å–æ•°æ®åº“è¿æ¥ï¼ˆæ¯æ¬¡åˆ›å»ºæ–°è¿æ¥ï¼Œé¿å… pickle é—®é¢˜ï¼‰

        å¹¶å‘å®‰å…¨è¯´æ˜ï¼š
            - ä½¿ç”¨ check_same_thread=False æ˜¯å®‰å…¨çš„ï¼Œå› ä¸ºï¼š
              1. æ¯æ¬¡è°ƒç”¨éƒ½åˆ›å»ºæ–°è¿æ¥ï¼Œä¸è·¨çº¿ç¨‹å…±äº«
              2. è¿æ¥ä½¿ç”¨å®Œç«‹å³å…³é—­ï¼ˆåœ¨ get_cursor ä¸Šä¸‹æ–‡ç®¡ç†å™¨ä¸­ï¼‰
              3. ä¸ä½¿ç”¨è¿æ¥æ± ï¼Œé¿å…çº¿ç¨‹é—´å…±äº«åŒä¸€è¿æ¥
            - timeout=30.0 é˜²æ­¢æ­»é”ï¼Œå¦‚æœé”ç­‰å¾…è¶…è¿‡30ç§’ä¼šæŠ›å‡ºå¼‚å¸¸
        """
        conn = sqlite3.connect(self.db_path, check_same_thread=False, timeout=30.0)
        conn.row_factory = sqlite3.Row
        return conn

    @contextmanager
    def get_cursor(self):
        """ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œè‡ªåŠ¨æäº¤å’Œé”™è¯¯å¤„ç†"""
        conn = self._get_conn()
        cursor = conn.cursor()
        try:
            yield cursor
            conn.commit()
        except Exception as e:
            conn.rollback()
            raise e
        finally:
            conn.close()  # å…³é—­è¿æ¥

    def _init_db(self):
        """åˆå§‹åŒ–æ•°æ®åº“è¡¨"""
        with self.get_cursor() as cursor:
            # åˆ›å»ºè¡¨ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS tasks (
                    task_id TEXT PRIMARY KEY,
                    file_name TEXT NOT NULL,
                    file_path TEXT,
                    status TEXT DEFAULT 'pending',
                    priority INTEGER DEFAULT 0,
                    backend TEXT DEFAULT 'pipeline',
                    options TEXT,
                    result_path TEXT,
                    error_message TEXT,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    started_at TIMESTAMP,
                    completed_at TIMESTAMP,
                    worker_id TEXT,
                    retry_count INTEGER DEFAULT 0
                )
            """)

            # åˆ›å»ºåŸºç¡€ç´¢å¼•
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_status ON tasks(status)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_priority ON tasks(priority DESC)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_created_at ON tasks(created_at)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_worker_id ON tasks(worker_id)")

            # è¿ç§»ï¼šæ·»åŠ  parent_task_id ç­‰å­—æ®µï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            try:
                cursor.execute("SELECT parent_task_id FROM tasks LIMIT 1")
            except sqlite3.OperationalError:
                # å­—æ®µä¸å­˜åœ¨ï¼Œæ·»åŠ æ–°å­—æ®µ
                logger.info("ğŸ“Š Migrating database schema: adding parent-child task support")
                cursor.execute("ALTER TABLE tasks ADD COLUMN parent_task_id TEXT")
                cursor.execute("ALTER TABLE tasks ADD COLUMN is_parent INTEGER DEFAULT 0")
                cursor.execute("ALTER TABLE tasks ADD COLUMN child_count INTEGER DEFAULT 0")
                cursor.execute("ALTER TABLE tasks ADD COLUMN child_completed INTEGER DEFAULT 0")
                logger.info("âœ… Parent-child task fields added")

            # åˆ›å»ºä¸»å­ä»»åŠ¡ç´¢å¼•ï¼ˆå­—æ®µå­˜åœ¨åæ‰åˆ›å»ºï¼‰
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_parent_task ON tasks(parent_task_id)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_is_parent ON tasks(is_parent)")

            # è¿ç§»ï¼šæ·»åŠ  user_id å­—æ®µï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            try:
                cursor.execute("SELECT user_id FROM tasks LIMIT 1")
            except sqlite3.OperationalError:
                logger.info("ğŸ“Š Migrating database schema: adding user_id field")
                cursor.execute("ALTER TABLE tasks ADD COLUMN user_id TEXT")
                logger.info("âœ… user_id field added")

            # è¿ç§»ï¼šæ·»åŠ  data å­—æ®µï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰- ç”¨äºå­˜å‚¨ pdf_path, json_content ç­‰
            try:
                cursor.execute("SELECT data FROM tasks LIMIT 1")
            except sqlite3.OperationalError:
                logger.info("ğŸ“Š Migrating database schema: adding data field")
                cursor.execute("ALTER TABLE tasks ADD COLUMN data TEXT")
                logger.info("âœ… data field added")

    def create_task(
        self,
        file_name: str,
        file_path: str,
        backend: str = "pipeline",
        options: dict = None,
        priority: int = 0,
        user_id: str = None,
    ) -> str:
        """
        åˆ›å»ºæ–°ä»»åŠ¡
        """
        task_id = str(uuid.uuid4())
        with self.get_cursor() as cursor:
            cursor.execute(
                """
                INSERT INTO tasks (task_id, file_name, file_path, backend, options, priority, user_id)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            """,
                (task_id, file_name, file_path, backend, json.dumps(options or {}), priority, user_id),
            )

        # å…¥é˜Ÿåˆ° Redisï¼ˆå¦‚æœå¯ç”¨ï¼‰
        self._enqueue_to_redis(
            task_id,
            priority,
            {
                "file_name": file_name,
                "backend": backend,
            },
        )

        return task_id

    def _enqueue_to_redis(self, task_id: str, priority: int, task_data: dict = None) -> bool:
        """å°†ä»»åŠ¡åŠ å…¥ Redis é˜Ÿåˆ—"""
        if not REDIS_QUEUE_AVAILABLE:
            return False

        redis_queue = get_redis_queue()
        if redis_queue:
            try:
                return redis_queue.enqueue(task_id, priority, task_data)
            except Exception as e:
                logger.warning(f"âš ï¸  Failed to enqueue to Redis, SQLite fallback active: {e}")
        return False

    def get_next_task(self, worker_id: str, max_retries: int = 3) -> Optional[Dict]:
        """
        è·å–ä¸‹ä¸€ä¸ªå¾…å¤„ç†ä»»åŠ¡ï¼ˆåŸå­æ“ä½œï¼Œé˜²æ­¢å¹¶å‘å†²çªï¼‰
        """
        from loguru import logger

        # å°è¯•ä½¿ç”¨ Redis é˜Ÿåˆ—ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        task = self._get_next_task_redis(worker_id)
        if task is not None:
            return task

        # Redis ä¸å¯ç”¨æˆ–å‡ºé”™ï¼Œå›é€€åˆ° SQLite
        for attempt in range(max_retries):
            try:
                with self.get_cursor() as cursor:
                    # ä½¿ç”¨äº‹åŠ¡ç¡®ä¿åŸå­æ€§
                    cursor.execute("BEGIN IMMEDIATE")

                    # æŒ‰ä¼˜å…ˆçº§å’Œåˆ›å»ºæ—¶é—´è·å–ä»»åŠ¡
                    cursor.execute("""
                        SELECT * FROM tasks
                        WHERE status = 'pending'
                        ORDER BY priority DESC, created_at ASC
                        LIMIT 1
                    """)

                    task = cursor.fetchone()
                    if task:
                        task_id = task["task_id"]
                        # ç«‹å³æ ‡è®°ä¸º processingï¼Œå¹¶ç¡®ä¿çŠ¶æ€ä»æ˜¯ pending
                        cursor.execute(
                            """
                            UPDATE tasks
                            SET status = 'processing',
                                started_at = CURRENT_TIMESTAMP,
                                worker_id = ?
                            WHERE task_id = ? AND status = 'pending'
                        """,
                            (worker_id, task_id),
                        )

                        # æ£€æŸ¥æ˜¯å¦æ›´æ–°æˆåŠŸï¼ˆé˜²æ­¢è¢«å…¶ä»– worker æŠ¢èµ°ï¼‰
                        if cursor.rowcount == 0:
                            # ä»»åŠ¡è¢«å…¶ä»–è¿›ç¨‹æŠ¢èµ°äº†ï¼Œç«‹å³é‡è¯•
                            if attempt == 0:  # åªåœ¨ç¬¬ä¸€æ¬¡å°è¯•æ—¶è®°å½•æ—¥å¿—
                                logger.debug(f"Task {task_id} was grabbed by another worker, retrying...")
                            continue

                        return dict(task)
                    else:
                        # é˜Ÿåˆ—ä¸­æ²¡æœ‰å¾…å¤„ç†ä»»åŠ¡ï¼Œè¿”å› None
                        if attempt == 0:
                            # æ£€æŸ¥æ˜¯å¦æœ‰ pending ä»»åŠ¡ï¼ˆç”¨äºè¯Šæ–­ï¼‰
                            cursor.execute("SELECT COUNT(*) as count FROM tasks WHERE status = 'pending'")
                            pending_count = cursor.fetchone()["count"]
                            if pending_count > 0:
                                logger.warning(
                                    f"âš ï¸  Found {pending_count} pending tasks but failed to grab one "
                                    f"(attempt {attempt + 1}/{max_retries})"
                                )
                        return None

            except Exception as e:
                logger.error(f"âŒ Error in get_next_task (attempt {attempt + 1}/{max_retries}): {e}")
                logger.exception(e)
                if attempt == max_retries - 1:
                    return None
                # ç­‰å¾…ä¸€å°æ®µæ—¶é—´åé‡è¯•
                import time

                time.sleep(0.1)

        # é‡è¯•æ¬¡æ•°ç”¨å°½ï¼Œä»æœªè·å–åˆ°ä»»åŠ¡ï¼ˆé«˜å¹¶å‘åœºæ™¯ï¼‰
        logger.warning(f"âš ï¸  Failed to get task after {max_retries} attempts")
        return None

    def _get_next_task_redis(self, worker_id: str) -> Optional[Dict]:
        """ä» Redis é˜Ÿåˆ—è·å–ä¸‹ä¸€ä¸ªä»»åŠ¡"""
        if not REDIS_QUEUE_AVAILABLE:
            return None

        redis_queue = get_redis_queue()
        if not redis_queue:
            return None

        try:
            # ä» Redis è·å–ä»»åŠ¡ IDï¼ˆé˜»å¡å¼ï¼Œ1ç§’è¶…æ—¶ï¼‰
            task_id = redis_queue.dequeue(worker_id, timeout=1.0)
            if not task_id:
                return None

            # ä» SQLite è·å–å®Œæ•´ä»»åŠ¡æ•°æ®
            with self.get_cursor() as cursor:
                cursor.execute("SELECT * FROM tasks WHERE task_id = ?", (task_id,))
                task = cursor.fetchone()

                if not task:
                    logger.error(f"âŒ Task {task_id} found in Redis but not in SQLite")
                    redis_queue.fail(task_id, worker_id, requeue=False)
                    return None

                # æ›´æ–° SQLite ä¸­çš„ä»»åŠ¡çŠ¶æ€
                cursor.execute(
                    """
                    UPDATE tasks
                    SET status = 'processing',
                        started_at = CURRENT_TIMESTAMP,
                        worker_id = ?
                    WHERE task_id = ? AND status = 'pending'
                    """,
                    (worker_id, task_id),
                )

                if cursor.rowcount == 0:
                    logger.warning(f"âš ï¸  Task {task_id} status changed, skipping")
                    redis_queue.fail(task_id, worker_id, requeue=False)
                    return None

                logger.info(f"ğŸ“¤ [Redis] Task {task_id} claimed by worker {worker_id}")
                return dict(task)

        except Exception as e:
            logger.error(f"âŒ Redis dequeue failed, falling back to SQLite: {e}")
            return None

    def update_task_status(
        self,
        task_id: str,
        status: str,
        result_path: str = None,
        error_message: str = None,
        worker_id: str = None,
        data: str = None,  # æ–°å¢ï¼šæ¥æ”¶æ‰©å±•æ•°æ®ï¼ˆJSONå­—ç¬¦ä¸²ï¼‰
    ):
        """
        æ›´æ–°ä»»åŠ¡çŠ¶æ€
        """
        with self.get_cursor() as cursor:
            success = False

            # æ ¹æ®ä¸åŒçŠ¶æ€ä½¿ç”¨é¢„å®šä¹‰çš„ SQL æ¨¡æ¿
            if status == "completed":
                # ä¿®å¤ï¼šå†™å…¥ data å­—æ®µ
                if worker_id:
                    sql = """
                        UPDATE tasks
                        SET status = ?,
                            completed_at = CURRENT_TIMESTAMP,
                            result_path = ?,
                            data = ?
                        WHERE task_id = ?
                        AND status = 'processing'
                        AND worker_id = ?
                    """
                    cursor.execute(sql, (status, result_path, data, task_id, worker_id))
                else:
                    sql = """
                        UPDATE tasks
                        SET status = ?,
                            completed_at = CURRENT_TIMESTAMP,
                            result_path = ?,
                            data = ?
                        WHERE task_id = ?
                        AND status = 'processing'
                    """
                    cursor.execute(sql, (status, result_path, data, task_id))

                success = cursor.rowcount > 0

            elif status == "failed":
                if worker_id:
                    sql = """
                        UPDATE tasks
                        SET status = ?,
                            completed_at = CURRENT_TIMESTAMP,
                            error_message = ?
                        WHERE task_id = ?
                        AND status = 'processing'
                        AND worker_id = ?
                    """
                    cursor.execute(sql, (status, error_message, task_id, worker_id))
                else:
                    sql = """
                        UPDATE tasks
                        SET status = ?,
                            completed_at = CURRENT_TIMESTAMP,
                            error_message = ?
                        WHERE task_id = ?
                        AND status = 'processing'
                    """
                    cursor.execute(sql, (status, error_message, task_id))

                success = cursor.rowcount > 0

            elif status == "cancelled":
                sql = """
                    UPDATE tasks
                    SET status = ?,
                        completed_at = CURRENT_TIMESTAMP
                    WHERE task_id = ?
                """
                cursor.execute(sql, (status, task_id))
                success = cursor.rowcount > 0

            elif status == "pending":
                sql = """
                    UPDATE tasks
                    SET status = ?,
                        worker_id = NULL,
                        started_at = NULL
                    WHERE task_id = ?
                """
                cursor.execute(sql, (status, task_id))
                success = cursor.rowcount > 0

            else:
                sql = """
                    UPDATE tasks
                    SET status = ?
                    WHERE task_id = ?
                """
                cursor.execute(sql, (status, task_id))
                success = cursor.rowcount > 0

            # è°ƒè¯•æ—¥å¿—ï¼ˆä»…åœ¨å¤±è´¥æ—¶ï¼‰
            if not success and status in ["completed", "failed"]:
                from loguru import logger

                logger.debug(f"Status update failed: task_id={task_id}, status={status}, " f"worker_id={worker_id}")

            # é€šçŸ¥ Redis ä»»åŠ¡å®Œæˆ/å¤±è´¥ï¼ˆæ¸…ç† processing setï¼‰
            if success and status in ["completed", "failed"]:
                self._notify_redis_task_done(task_id, worker_id or "", status)

            return success

    def _notify_redis_task_done(self, task_id: str, worker_id: str, status: str):
        """é€šçŸ¥ Redis ä»»åŠ¡å·²å®Œæˆ/å¤±è´¥"""
        if not REDIS_QUEUE_AVAILABLE:
            return

        redis_queue = get_redis_queue()
        if redis_queue:
            try:
                if status == "completed":
                    redis_queue.complete(task_id, worker_id)
                else:
                    redis_queue.fail(task_id, worker_id, requeue=False)
            except Exception as e:
                logger.warning(f"âš ï¸  Failed to notify Redis about task {task_id}: {e}")

    def get_task(self, task_id: str) -> Optional[Dict]:
        """æŸ¥è¯¢ä»»åŠ¡è¯¦æƒ…"""
        with self.get_cursor() as cursor:
            cursor.execute("SELECT * FROM tasks WHERE task_id = ?", (task_id,))
            task = cursor.fetchone()
            return dict(task) if task else None

    def get_queue_stats(self) -> Dict[str, int]:
        """è·å–é˜Ÿåˆ—ç»Ÿè®¡ä¿¡æ¯"""
        with self.get_cursor() as cursor:
            cursor.execute("""
                SELECT status, COUNT(*) as count
                FROM tasks
                GROUP BY status
            """)
            stats = {row["status"]: row["count"] for row in cursor.fetchall()}

        # æ·»åŠ  Redis é˜Ÿåˆ—ç»Ÿè®¡ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if REDIS_QUEUE_AVAILABLE:
            redis_queue = get_redis_queue()
            if redis_queue:
                try:
                    redis_stats = redis_queue.get_stats()
                    stats["_redis_enabled"] = True
                    stats["_redis_pending"] = redis_stats.get("pending", 0)
                    stats["_redis_processing"] = redis_stats.get("processing", 0)
                except Exception as e:
                    stats["_redis_enabled"] = False
                    stats["_redis_error"] = str(e)
            else:
                stats["_redis_enabled"] = False
        else:
            stats["_redis_enabled"] = False

        return stats

    def get_tasks_by_status(self, status: str, limit: int = 100) -> List[Dict]:
        """æ ¹æ®çŠ¶æ€è·å–ä»»åŠ¡åˆ—è¡¨"""
        with self.get_cursor() as cursor:
            cursor.execute(
                """
                SELECT * FROM tasks
                WHERE status = ?
                ORDER BY created_at DESC
                LIMIT ?
            """,
                (status, limit),
            )
            return [dict(row) for row in cursor.fetchall()]

    # -------------------------------------------------------------------------
    # æ ¸å¿ƒä¿®å¤ï¼šç‰©ç†åˆ é™¤æ–‡ä»¶é€»è¾‘
    # -------------------------------------------------------------------------
    def _delete_task_files(self, task_row):
        """è¾…åŠ©æ–¹æ³•ï¼šå®‰å…¨åˆ é™¤ä»»åŠ¡çš„æºæ–‡ä»¶å’Œç»“æœç›®å½•"""
        task_id = task_row["task_id"]
        
        # 1. åˆ é™¤ä¸Šä¼ çš„æºæ–‡ä»¶
        if task_row["file_path"]:
            try:
                fp = Path(task_row["file_path"])
                if fp.exists() and fp.is_file():
                    fp.unlink()
                    logger.debug(f"Deleted source file for task {task_id}")
            except Exception as e:
                logger.warning(f"Failed to delete source file for task {task_id}: {e}")
        
        # 2. åˆ é™¤ç»“æœç›®å½•
        if task_row["result_path"]:
            try:
                rp = Path(task_row["result_path"])
                if rp.exists() and rp.is_dir():
                    shutil.rmtree(rp)
                    logger.debug(f"Deleted result dir for task {task_id}")
            except Exception as e:
                logger.warning(f"Failed to delete result dir for task {task_id}: {e}")

    def cleanup_old_task_records(self, days: int = 30):
        """æ¸…ç†æ—§ä»»åŠ¡"""
        with self.get_cursor() as cursor:
            # å…ˆæŸ¥è¯¢è¦åˆ é™¤çš„ä»»åŠ¡åŠå…¶æ–‡ä»¶è·¯å¾„
            cursor.execute("""
                SELECT task_id, file_path, result_path FROM tasks
                WHERE completed_at < datetime('now', '-' || ? || ' days')
                AND status IN ('completed', 'failed')
            """, (days,))
            old_tasks = cursor.fetchall()
            
            # åˆ é™¤æ‰€æœ‰ç›¸å…³æ–‡ä»¶
            for task in old_tasks:
                self._delete_task_files(task)
            
            # åˆ é™¤æ•°æ®åº“è®°å½•
            cursor.execute("""
                DELETE FROM tasks
                WHERE completed_at < datetime('now', '-' || ? || ' days')
                AND status IN ('completed', 'failed')
            """, (days,))
            
            return cursor.rowcount

    def reset_stale_tasks(self, timeout_minutes: int = 60):
        """é‡ç½®è¶…æ—¶çš„ processing ä»»åŠ¡ä¸º pending"""
        with self.get_cursor() as cursor:
            cursor.execute(
                """
                UPDATE tasks
                SET status = 'pending',
                    worker_id = NULL,
                    retry_count = retry_count + 1
                WHERE status = 'processing'
                AND started_at < datetime('now', '-' || ? || ' minutes')
            """,
                (timeout_minutes,),
            )
            reset_count = cursor.rowcount
            return reset_count

    # -------------------------------------------------------------------------
    # æ–°å¢åŠŸèƒ½ï¼šæ¸…ç†å¤±è´¥ä»»åŠ¡ (åŒ…å«ç‰©ç†æ–‡ä»¶åˆ é™¤)
    # -------------------------------------------------------------------------
    def clear_failed_tasks(self) -> int:
        """
        ä¸€é”®æ¸…ç†æ‰€æœ‰å¤±è´¥çš„ä»»åŠ¡
        æ‰§è¡Œæ­¥éª¤: 1.æŸ¥è¯¢è·¯å¾„ -> 2.åˆ é™¤ç£ç›˜æ–‡ä»¶ -> 3.åˆ é™¤æ•°æ®åº“è®°å½•
        """
        with self.get_cursor() as cursor:
            # 1. æŸ¥è¯¢æ‰€æœ‰ failed ä»»åŠ¡
            cursor.execute("SELECT task_id, file_path, result_path FROM tasks WHERE status = 'failed'")
            failed_tasks = cursor.fetchall()
            
            count = 0
            # 2. ç‰©ç†åˆ é™¤
            for task in failed_tasks:
                self._delete_task_files(task)
                count += 1
            
            # 3. æ•°æ®åº“åˆ é™¤
            cursor.execute("DELETE FROM tasks WHERE status = 'failed'")
            logger.info(f"ğŸ§¹ Cleared {cursor.rowcount} failed tasks (files deleted for {count} tasks)")
            return cursor.rowcount

    # ============================================================================
    # ä¸»å­ä»»åŠ¡æ”¯æŒ (Parent-Child Task Support)
    # ============================================================================

    def create_parent_task(
        self,
        file_name: str,
        file_path: str,
        backend: str = "pipeline",
        options: dict = None,
        priority: int = 0,
        user_id: str = None,
    ) -> str:
        """åˆ›å»ºä¸»ä»»åŠ¡"""
        task_id = str(uuid.uuid4())
        with self.get_cursor() as cursor:
            cursor.execute(
                """
                INSERT INTO tasks (
                    task_id, file_name, file_path, backend, options,
                    status, priority, user_id, is_parent, child_count
                ) VALUES (?, ?, ?, ?, ?, 'processing', ?, ?, 1, 0)
            """,
                (task_id, file_name, file_path, backend, json.dumps(options or {}), priority, user_id),
            )
        logger.info(f"ğŸ“‹ Created parent task: {task_id}")
        return task_id

    def convert_to_parent_task(self, task_id: str, child_count: int = 0):
        """å°†æ™®é€šä»»åŠ¡è½¬æ¢ä¸ºçˆ¶ä»»åŠ¡"""
        with self.get_cursor() as cursor:
            cursor.execute(
                """
                UPDATE tasks
                SET is_parent = 1, child_count = ?, status = 'processing'
                WHERE task_id = ?
                """,
                (child_count, task_id),
            )
        logger.info(f"ğŸ”„ Converted task {task_id} to parent task with {child_count} children")

    def create_child_task(
        self,
        parent_task_id: str,
        file_name: str,
        file_path: str,
        backend: str = "pipeline",
        options: dict = None,
        priority: int = 0,
        user_id: str = None,
    ) -> str:
        """åˆ›å»ºå­ä»»åŠ¡"""
        task_id = str(uuid.uuid4())
        with self.get_cursor() as cursor:
            # åˆ›å»ºå­ä»»åŠ¡
            cursor.execute(
                """
                INSERT INTO tasks (
                    task_id, parent_task_id, file_name, file_path,
                    backend, options, status, priority, user_id
                ) VALUES (?, ?, ?, ?, ?, ?, 'pending', ?, ?)
            """,
                (
                    task_id,
                    parent_task_id,
                    file_name,
                    file_path,
                    backend,
                    json.dumps(options or {}),
                    priority,
                    user_id,
                ),
            )

            # æ›´æ–°çˆ¶ä»»åŠ¡çš„å­ä»»åŠ¡è®¡æ•°
            cursor.execute(
                """
                UPDATE tasks
                SET child_count = child_count + 1
                WHERE task_id = ?
            """,
                (parent_task_id,),
            )

        logger.debug(f"ğŸ“„ Created child task: {task_id} (parent: {parent_task_id})")
        return task_id

    def on_child_task_completed(self, child_task_id: str) -> Optional[str]:
        """å­ä»»åŠ¡å®Œæˆå›è°ƒ"""
        with self.get_cursor() as cursor:
            # è·å–çˆ¶ä»»åŠ¡ID
            cursor.execute(
                """
                SELECT parent_task_id FROM tasks WHERE task_id = ?
            """,
                (child_task_id,),
            )
            row = cursor.fetchone()

            if not row or not row["parent_task_id"]:
                return None  # ä¸æ˜¯å­ä»»åŠ¡

            parent_task_id = row["parent_task_id"]

            # æ›´æ–°çˆ¶ä»»åŠ¡çš„å®Œæˆè®¡æ•°
            cursor.execute(
                """
                UPDATE tasks
                SET child_completed = child_completed + 1
                WHERE task_id = ?
            """,
                (parent_task_id,),
            )

            # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰å­ä»»åŠ¡éƒ½å®Œæˆäº†
            cursor.execute(
                """
                SELECT child_count, child_completed, file_name
                FROM tasks WHERE task_id = ?
            """,
                (parent_task_id,),
            )
            parent = cursor.fetchone()

            if parent and parent["child_completed"] >= parent["child_count"]:
                # æ‰€æœ‰å­ä»»åŠ¡å®Œæˆ
                logger.info(
                    f"ğŸ‰ All subtasks completed for parent task {parent_task_id} "
                    f"({parent['child_completed']}/{parent['child_count']}) - {parent['file_name']}"
                )
                return parent_task_id

            if parent:
                logger.info(
                    f"â³ Subtask progress: {parent['child_completed']}/{parent['child_count']} "
                    f"for parent task {parent_task_id}"
                )

        return None

    def on_child_task_failed(self, child_task_id: str, error_message: str):
        """å­ä»»åŠ¡å¤±è´¥å›è°ƒ"""
        with self.get_cursor() as cursor:
            # è·å–çˆ¶ä»»åŠ¡ID
            cursor.execute(
                """
                SELECT parent_task_id FROM tasks WHERE task_id = ?
            """,
                (child_task_id,),
            )
            row = cursor.fetchone()

            if not row or not row["parent_task_id"]:
                return  # ä¸æ˜¯å­ä»»åŠ¡

            parent_task_id = row["parent_task_id"]

            # æ ‡è®°çˆ¶ä»»åŠ¡ä¸ºå¤±è´¥
            cursor.execute(
                """
                UPDATE tasks
                SET status = 'failed',
                    completed_at = CURRENT_TIMESTAMP,
                    error_message = ?
                WHERE task_id = ?
                AND status = 'processing'
            """,
                (f"Subtask {child_task_id} failed: {error_message}", parent_task_id),
            )

            if cursor.rowcount > 0:
                logger.error(f"âŒ Parent task {parent_task_id} marked as failed due to subtask failure")

    def get_task_with_children(self, task_id: str) -> Optional[Dict]:
        """è·å–ä»»åŠ¡åŠå…¶æ‰€æœ‰å­ä»»åŠ¡"""
        with self.get_cursor() as cursor:
            # è·å–ä¸»ä»»åŠ¡
            cursor.execute("SELECT * FROM tasks WHERE task_id = ?", (task_id,))
            parent_row = cursor.fetchone()

            if not parent_row:
                return None

            parent = dict(parent_row)

            # å¦‚æœæ˜¯ä¸»ä»»åŠ¡ï¼Œè·å–æ‰€æœ‰å­ä»»åŠ¡
            if parent.get("is_parent"):
                cursor.execute(
                    """
                    SELECT * FROM tasks
                    WHERE parent_task_id = ?
                    ORDER BY created_at
                """,
                    (task_id,),
                )
                children = [dict(row) for row in cursor.fetchall()]
                parent["children"] = children
            else:
                parent["children"] = []

            return parent

    def get_child_tasks(self, parent_task_id: str) -> List[Dict]:
        """è·å–çˆ¶ä»»åŠ¡çš„æ‰€æœ‰å­ä»»åŠ¡"""
        with self.get_cursor() as cursor:
            cursor.execute(
                """
                SELECT * FROM tasks
                WHERE parent_task_id = ?
                ORDER BY created_at
            """,
                (parent_task_id,),
            )
            return [dict(row) for row in cursor.fetchall()]

    # ========================================================================
    # æ–°å¢åŠŸèƒ½ï¼šé‡è¯•ã€æ¸…ç†ã€æš‚åœã€æ¢å¤ã€æ¸…ç†ç¼“å­˜
    # ========================================================================

    def retry_task(self, task_id: str) -> bool:
        """
        é‡è¯•ä»»åŠ¡ï¼šå°†ä»»åŠ¡çŠ¶æ€é‡ç½®ä¸º pendingï¼Œæ¸…ç©ºé”™è¯¯å’Œæ—¶é—´ï¼Œé‡è¯•æ¬¡æ•° +1
        """
        with self.get_cursor() as cursor:
            cursor.execute(
                """
                UPDATE tasks 
                SET status = 'pending', 
                    error_message = NULL, 
                    started_at = NULL, 
                    completed_at = NULL, 
                    worker_id = NULL,
                    retry_count = retry_count + 1
                WHERE task_id = ?
                """,
                (task_id,)
            )
            return cursor.rowcount > 0

    def pause_task(self, task_id: str) -> bool:
        """
        æš‚åœä»»åŠ¡ï¼šä»…å…è®¸æš‚åœå¤„äº pendingï¼ˆæ’é˜Ÿä¸­ï¼‰çš„ä»»åŠ¡
        """
        with self.get_cursor() as cursor:
            cursor.execute(
                """
                UPDATE tasks 
                SET status = 'paused' 
                WHERE task_id = ? AND status = 'pending'
                """,
                (task_id,)
            )
            return cursor.rowcount > 0

    def resume_task(self, task_id: str) -> bool:
        """
        æ¢å¤ä»»åŠ¡ï¼šå°† paused çŠ¶æ€çš„ä»»åŠ¡é‡æ–°æ”¾å› pending é˜Ÿåˆ—
        """
        with self.get_cursor() as cursor:
            cursor.execute(
                """
                UPDATE tasks 
                SET status = 'pending' 
                WHERE task_id = ? AND status = 'paused'
                """,
                (task_id,)
            )
            return cursor.rowcount > 0

    def clear_task_cache(self, task_id: str) -> bool:
        """
        æ¸…ç†ä»»åŠ¡ç¼“å­˜ï¼šä¿ç•™æ•°æ®åº“å†å²è®°å½•ï¼Œä½†å°† result_path æ ‡è®°ä¸ºå·²æ¸…ç†
        """
        with self.get_cursor() as cursor:
            cursor.execute(
                """
                UPDATE tasks 
                SET result_path = 'CLEARED' 
                WHERE task_id = ?
                """,
                (task_id,)
            )
            return cursor.rowcount > 0


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    db = TaskDB("test_tianshu.db")

    # åˆ›å»ºæµ‹è¯•ä»»åŠ¡
    task_id = db.create_task(
        file_name="test.pdf",
        file_path="/tmp/test.pdf",
        backend="pipeline",
        options={"lang": "ch", "formula_enable": True},
        priority=1,
    )
    print(f"Created task: {task_id}")

    # æŸ¥è¯¢ä»»åŠ¡
    task = db.get_task(task_id)
    print(f"Task details: {task}")

    # è·å–ç»Ÿè®¡
    stats = db.get_queue_stats()
    print(f"Queue stats: {stats}")

    # æ¸…ç†æµ‹è¯•æ•°æ®åº“
    Path("test_tianshu.db").unlink(missing_ok=True)
    print("Test completed!")
