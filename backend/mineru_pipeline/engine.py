"""
MinerU Pipeline Engine
å•ä¾‹æ¨¡å¼ï¼Œæ¯ä¸ªè¿›ç¨‹åªåŠ è½½ä¸€æ¬¡æ¨¡åž‹
ä½¿ç”¨ MinerU å¤„ç† PDF å’Œå›¾ç‰‡

ä¿®å¤è¯´æ˜Žï¼š
- [æ ¸å¿ƒä¿®å¤] ä¿®æ­£ç»“æžœç›®å½•æŸ¥æ‰¾é€»è¾‘ï¼Œé€‚é… MinerU çš„è¾“å‡ºç»“æž„ (input_filename_dir/auto/...)
- [å¢žå¼º] å¢žåŠ å¯¹è¾“å‡ºç›®å½•çš„é€’å½’æœç´¢ï¼Œé˜²æ­¢ç›®å½•å±‚çº§å˜åŒ–å¯¼è‡´æ‰¾ä¸åˆ°æ–‡ä»¶
- [åŽŸæœ‰] ä¿æŒä¸´æ—¶ç›®å½•å¤„ç†æ–¹æ¡ˆï¼Œè§„é¿ä¸­æ–‡è·¯å¾„é—®é¢˜
- [åŽŸæœ‰] ä¿æŒ VLLM å‚æ•°é€ä¼ 
"""

import json
import os
import shutil
import tempfile
from pathlib import Path
from typing import Optional, Dict, Any
from threading import Lock
from loguru import logger
import img2pdf


class MinerUPipelineEngine:
    """
    MinerU Pipeline å¼•æ“Ž
    """

    _instance: Optional["MinerUPipelineEngine"] = None
    _lock = Lock()
    _pipeline = None  # è¿™é‡Œçš„ pipeline å®žé™…ä¸Šæ˜¯ do_parse å‡½æ•°
    _initialized = False

    def __new__(cls, *args, **kwargs):
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
        return cls._instance

    def __init__(self, device: str = "cuda:0", vlm_api_base: str = None):
        if self._initialized:
            return

        with self._lock:
            if self._initialized:
                return

            self.device = device
            self.vlm_api_base = vlm_api_base

            if "cuda:" in device:
                self.gpu_id = device.split(":")[-1]
            else:
                self.gpu_id = "0"

            self._initialized = True
            logger.info(f"ðŸ”§ MinerU Pipeline Engine initialized on {device}")
            if self.vlm_api_base:
                logger.info(f"   VLLM API Base: {self.vlm_api_base}")

    def _load_pipeline(self):
        """å»¶è¿ŸåŠ è½½ MinerU ç®¡é“ (do_parse)"""
        if self._pipeline is not None:
            return self._pipeline

        with self._lock:
            if self._pipeline is not None:
                return self._pipeline

            logger.info("=" * 60)
            logger.info("ðŸ“¥ Loading MinerU Pipeline (do_parse)...")
            logger.info("=" * 60)

            try:
                from mineru.cli.common import do_parse
                self._pipeline = do_parse
                logger.info("âœ… MinerU Pipeline loaded successfully!")
                return self._pipeline
            except Exception as e:
                logger.error(f"âŒ Error loading MinerU pipeline: {e}")
                raise

    def cleanup(self):
        """æ¸…ç†æ˜¾å­˜"""
        try:
            from mineru.utils.model_utils import clean_memory
            clean_memory()
            logger.debug("ðŸ§¹ MinerU: Memory cleanup completed")
        except Exception:
            pass

    def parse(self, file_path: str, output_path: str, options: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        å¤„ç†æ–‡ä»¶ (å¢žå¼ºç‰ˆï¼šä½¿ç”¨ä¸´æ—¶ç›®å½•è§„é¿è·¯å¾„é—®é¢˜)
        """
        options = options or {}
        
        # ç”¨æˆ·æŒ‡å®šçš„æœ€ç»ˆè¾“å‡ºç›®å½• (å¯èƒ½åŒ…å«ä¸­æ–‡)
        final_output_dir = Path(output_path)
        final_output_dir.mkdir(parents=True, exist_ok=True)

        file_path_obj = Path(file_path)
        file_ext = file_path_obj.suffix.lower()

        # 1. ç¡®å®š Backend
        user_backend = options.get("parse_mode", "pipeline")
        if user_backend == "auto":
            user_backend = "pipeline"

        backend = user_backend
        server_url = options.get("server_url")

        # æ™ºèƒ½åˆ‡æ¢ VLLM åŠ é€Ÿ
        if not server_url and self.vlm_api_base:
            if user_backend == "vlm-auto-engine":
                backend = "vlm-http-client"
                server_url = self.vlm_api_base.replace("/v1", "")
                logger.info(f"ðŸ”„ [Accelerate] Switching to {backend} using local vLLM")
            elif user_backend == "hybrid-auto-engine":
                backend = "hybrid-http-client"
                server_url = self.vlm_api_base.replace("/v1", "")
                logger.info(f"ðŸ”„ [Accelerate] Switching to {backend} using local vLLM")

        # 2. å‡†å¤‡å‚æ•°
        parse_method = options.get("method", "auto")
        if options.get("force_ocr"):
            parse_method = "ocr"

        formula_enable = options.get("formula_enable", True)
        table_enable = options.get("table_enable", True)
        
        # è¾“å‡ºæŽ§åˆ¶
        f_draw_layout_bbox = options.get("draw_layout_bbox", True)      
        f_draw_span_bbox = options.get("draw_span_bbox", True)          
        f_dump_md = options.get("dump_markdown", True)                  
        f_dump_middle_json = options.get("dump_middle_json", True)      
        f_dump_model_output = options.get("dump_model_output", True)    
        f_dump_content_list = options.get("dump_content_list", True)    
        f_dump_orig_pdf = options.get("dump_orig_pdf", True)            

        # é¡µé¢èŒƒå›´
        start_page_id = options.get("start_page_id", 0)
        end_page_id = options.get("end_page_id", None)
        
        try: start_page_id = int(start_page_id)
        except: start_page_id = 0
        
        try: 
            if end_page_id is not None and str(end_page_id).strip() != "": 
                end_page_id = int(end_page_id)
                if end_page_id == -1: end_page_id = None
            else: end_page_id = None
        except: end_page_id = None

        # åŠ è½½å¼•æ“Ž
        do_parse_func = self._load_pipeline()

        try:
            # è¯»å–æºæ–‡ä»¶
            with open(file_path, "rb") as f:
                file_bytes = f.read()

            if file_ext in [".png", ".jpg", ".jpeg"]:
                logger.info("ðŸ–¼ï¸  Converting image to PDF...")
                try:
                    pdf_bytes = img2pdf.convert(file_bytes)
                except Exception as e:
                    raise ValueError(f"Image conversion failed: {e}")
            else:
                pdf_bytes = file_bytes

            lang = options.get("lang", "auto")
            if lang == "auto": lang = "ch"

            # =================================================================
            # ã€æ ¸å¿ƒä¿®å¤ã€‘ä½¿ç”¨ä¸´æ—¶çº¯è‹±æ–‡ç›®å½•å¤„ç†
            # =================================================================
            with tempfile.TemporaryDirectory(prefix="mineru_proc_") as temp_dir:
                temp_work_dir = Path(temp_dir)
                logger.info(f"ðŸ› ï¸  Working in temp directory: {temp_work_dir}")
                
                # å¼ºåˆ¶ä½¿ç”¨å®‰å…¨æ–‡ä»¶å result.pdf
                safe_file_name = "result.pdf"
                
                # è°ƒç”¨ MinerU å¤„ç†
                do_parse_func(
                    output_dir=str(temp_work_dir), # è¾“å‡ºåˆ°ä¸´æ—¶ç›®å½•
                    pdf_file_names=[safe_file_name],
                    pdf_bytes_list=[pdf_bytes],
                    p_lang_list=[lang],
                    
                    backend=backend,
                    parse_method=parse_method,
                    server_url=server_url,
                    
                    start_page_id=start_page_id,
                    end_page_id=end_page_id,
                    formula_enable=formula_enable,
                    table_enable=table_enable,
                    
                    f_draw_layout_bbox=f_draw_layout_bbox,
                    f_draw_span_bbox=f_draw_span_bbox,
                    f_dump_md=f_dump_md,
                    f_dump_middle_json=f_dump_middle_json,
                    f_dump_model_output=f_dump_model_output,
                    f_dump_orig_pdf=f_dump_orig_pdf,
                    f_dump_content_list=f_dump_content_list
                )

                # =============================================================
                # ç»“æžœæå–ä¸Žæ¬è¿ (æ›´å®½å®¹çš„æŸ¥æ‰¾é€»è¾‘)
                # =============================================================
                # MinerU è¾“å‡ºç»“æž„é€šå¸¸æ˜¯: {temp_work_dir}/{safe_file_name}/auto/result.md
                # ä½†ä¸ºäº†ä¿é™©ï¼Œæˆ‘ä»¬åœ¨æ•´ä¸ªä¸´æ—¶ç›®å½•é‡Œæ‰¾
                
                # 1. åœ¨ä¸´æ—¶ç›®å½•ä¸­æŸ¥æ‰¾ Markdown
                temp_md_files = list(temp_work_dir.rglob("*.md"))
                
                if not temp_md_files:
                    logger.error("âŒ No Markdown files found in temp output")
                    # å°è¯•åˆ—å‡ºæ‰€æœ‰æ–‡ä»¶å¸®åŠ©è°ƒè¯•
                    for f in temp_work_dir.rglob("*"):
                        logger.debug(f"   Found file: {f}")
                    raise FileNotFoundError("Processing failed internally - No markdown generated")

                md_file = temp_md_files[0]
                content = md_file.read_text(encoding="utf-8")
                logger.info(f"âœ… Read MD content: {len(content)} chars")
                
                # ç¡®å®šç”Ÿæˆç»“æžœçš„æ ¹ç›®å½• (é€šå¸¸æ˜¯ md æ–‡ä»¶æ‰€åœ¨çš„çˆ¶ç›®å½•ï¼Œå¦‚ auto/)
                # æˆ‘ä»¬è¦æ¬è¿çš„æ˜¯ result.pdf æ–‡ä»¶å¤¹ä¸‹çš„å†…å®¹ï¼Œè€Œä¸æ˜¯ temp_work_dir çš„å…¨éƒ¨
                # å‡è®¾ safe_file_name æ˜¯ result.pdfï¼ŒMinerU ä¼šåˆ›å»ºä¸€ä¸ª result.pdf æ–‡ä»¶å¤¹
                generated_root = temp_work_dir / safe_file_name
                if not generated_root.exists():
                    # å¦‚æžœæ‰¾ä¸åˆ°æ ‡å‡†ç›®å½•ï¼Œå°±ä»¥ md æ–‡ä»¶çš„ä¸Šçº§ç›®å½•ä½œä¸ºæº
                    generated_root = md_file.parent
                    logger.warning(f"âš ï¸  Standard output dir not found, using: {generated_root}")

                # 2. æŸ¥æ‰¾ JSON (ç”¨äºŽæ¢å¤å†…å®¹)
                json_content = None
                temp_json_files = list(temp_work_dir.rglob("*_content_list.json"))
                if temp_json_files:
                    try:
                        with open(temp_json_files[0], "r", encoding="utf-8") as f:
                            json_content = json.load(f)
                    except: pass

                # 3. å¦‚æžœ MD ä¸ºç©ºï¼Œå°è¯•ä»Ž JSON æ¢å¤
                if not content.strip() and json_content:
                    logger.warning("âš ï¸  Markdown file is empty, attempting to recover text from JSON...")
                    recovered_text = []
                    if isinstance(json_content, list):
                        for block in json_content:
                            if "text" in block:
                                recovered_text.append(block["text"])
                    content = "\n\n".join(recovered_text)
                    logger.info(f"â„¹ï¸  Recovered {len(content)} chars from JSON")

                # 4. å°†ç»“æžœæ–‡ä»¶æ¬è¿åˆ°ç”¨æˆ·æŒ‡å®šçš„ final_output_dir
                # æˆ‘ä»¬æŠŠ generated_root ä¸‹çš„æ‰€æœ‰å†…å®¹å¤åˆ¶è¿‡åŽ»
                logger.info(f"ðŸ“¦ Moving results from {generated_root} to {final_output_dir}")
                
                if generated_root.exists():
                    # éåŽ†å¹¶å¤åˆ¶æ‰€æœ‰æ–‡ä»¶
                    for src_path in generated_root.rglob("*"):
                        if src_path.is_file():
                            # è®¡ç®—ç›¸å¯¹è·¯å¾„
                            rel_path = src_path.relative_to(generated_root)
                            dest_path = final_output_dir / rel_path
                            
                            # ç¡®ä¿ç›®æ ‡æ–‡ä»¶å¤¹å­˜åœ¨
                            dest_path.parent.mkdir(parents=True, exist_ok=True)
                            
                            shutil.copy2(src_path, dest_path)
                else:
                    # é™çº§ï¼šç›´æŽ¥æŠŠæ‰¾åˆ°çš„é‚£ä¸ª md æ–‡ä»¶å’ŒåŒçº§æ–‡ä»¶å¤åˆ¶è¿‡åŽ»
                    shutil.copy2(md_file, final_output_dir / "result.md")

                # =============================================================
                # è¿”å›žæœ€ç»ˆç»“æžœè·¯å¾„
                # =============================================================
                final_md_path = None
                final_json_path = None
                
                final_mds = list(final_output_dir.rglob("*.md"))
                if final_mds:
                    final_md_path = str(final_mds[0])
                
                final_jsons = list(final_output_dir.rglob("*_content_list.json"))
                if final_jsons:
                    final_json_path = str(final_jsons[0])

                if not content.strip():
                    layout_pdfs = list(final_output_dir.rglob("*_layout.pdf"))
                    if layout_pdfs:
                        content = "> âš ï¸ Text extraction returned empty content. Please check layout PDF."
                    else:
                        raise FileNotFoundError("No valid content generated.")

                return {
                    "markdown": content,
                    "result_path": str(final_output_dir),
                    "markdown_file": final_md_path,
                    "json_path": final_json_path,
                    "json_content": json_content
                }

        except Exception as e:
            logger.error(f"âŒ Pipeline processing failed: {e}")
            import traceback
            logger.debug(traceback.format_exc())
            raise

        finally:
            self.cleanup()


# å…¨å±€å•ä¾‹
_engine = None

def get_engine(vlm_api_base: str = None) -> MinerUPipelineEngine:
    global _engine
    if _engine is None:
        _engine = MinerUPipelineEngine(vlm_api_base=vlm_api_base)
    return _engine
