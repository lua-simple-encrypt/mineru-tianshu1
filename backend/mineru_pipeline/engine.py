"""
MinerU Pipeline Engine
å•ä¾‹æ¨¡å¼ï¼Œæ¯ä¸ªè¿›ç¨‹åªåŠ è½½ä¸€æ¬¡æ¨¡å‹
ä½¿ç”¨ MinerU å¤„ç† PDF å’Œå›¾ç‰‡

ä¿®å¤è¯´æ˜ï¼š
- [æ ¸å¿ƒä¿®å¤] å¢åŠ æ·±åº¦æ–‡æœ¬æ¸…æ´— (_clean_markdown)ï¼Œè§£å†³ HTML è½¬ä¹‰ã€LaTeX è¿‡åº¦åŒ…è£…å’Œæ¨¡å‹å¹»è§‰æ ‡ç­¾
- [æ ¸å¿ƒä¿®å¤] ä½¿ç”¨ä¸´æ—¶çº¯è‹±æ–‡ç›®å½•å¤„ç†ï¼Œè§„é¿ä¸­æ–‡è·¯å¾„é—®é¢˜
- [å¢å¼º] å¢åŠ  VLLM æœåŠ¡å¥åº·æ£€æŸ¥ä¸è‡ªåŠ¨ç­‰å¾…æœºåˆ¶
- [å¢å¼º] ä¿®å¤ Markdown å†…å®¹ä¸ºç©ºæ—¶çš„è‡ªåŠ¨æ¢å¤é€»è¾‘
"""

import json
import os
import shutil
import tempfile
import time
import urllib.request
import urllib.error
import re        # <--- [æ–°å¢] æ­£åˆ™è¡¨è¾¾å¼åº“
import html      # <--- [æ–°å¢] HTMLè½¬ä¹‰åº“
from pathlib import Path
from typing import Optional, Dict, Any
from threading import Lock
from loguru import logger
import img2pdf


class MinerUPipelineEngine:
    """
    MinerU Pipeline å¼•æ“
    """

    _instance: Optional["MinerUPipelineEngine"] = None
    _lock = Lock()
    _pipeline = None  # è¿™é‡Œçš„ pipeline å®é™…ä¸Šæ˜¯ do_parse å‡½æ•°
    _initialized = False

    def __new__(cls, *args, **kwargs):
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
        return cls._instance

    def __init__(self, device: str = "cuda:0", vlm_api_base: str = None):
        if self._initialized:
            return

        with self._lock:
            if self._initialized:
                return

            self.device = device
            self.vlm_api_base = vlm_api_base

            if "cuda:" in device:
                self.gpu_id = device.split(":")[-1]
            else:
                self.gpu_id = "0"

            self._initialized = True
            logger.info(f"ğŸ”§ MinerU Pipeline Engine initialized on {device}")
            if self.vlm_api_base:
                logger.info(f"   VLLM API Base: {self.vlm_api_base}")

    def _load_pipeline(self):
        """å»¶è¿ŸåŠ è½½ MinerU ç®¡é“ (do_parse)"""
        if self._pipeline is not None:
            return self._pipeline

        with self._lock:
            if self._pipeline is not None:
                return self._pipeline

            logger.info("=" * 60)
            logger.info("ğŸ“¥ Loading MinerU Pipeline (do_parse)...")
            logger.info("=" * 60)

            try:
                from mineru.cli.common import do_parse
                self._pipeline = do_parse
                logger.info("âœ… MinerU Pipeline loaded successfully!")
                return self._pipeline
            except Exception as e:
                logger.error(f"âŒ Error loading MinerU pipeline: {e}")
                raise

    def _wait_for_server(self, server_url: str, timeout: int = 60) -> bool:
        """ç­‰å¾… VLLM æœåŠ¡å°±ç»ª"""
        base_url = server_url.rstrip("/")
        if base_url.endswith("/v1"):
            base_url = base_url[:-3]
            
        health_url = f"{base_url}/v1/models"
        
        logger.info(f"â³ Waiting for VLLM server at {base_url} (Timeout: {timeout}s)...")
        start_time = time.time()
        
        while time.time() - start_time < timeout:
            try:
                with urllib.request.urlopen(health_url, timeout=2) as response:
                    if response.status == 200:
                        logger.info(f"âœ… VLLM server is ready: {base_url}")
                        return True
            except (urllib.error.URLError, ConnectionRefusedError):
                pass
            except Exception as e:
                logger.debug(f"Health check warning: {e}")
            
            time.sleep(1)
            
        logger.warning(f"âš ï¸  VLLM server wait timed out after {timeout}s. Process may fail.")
        return False

    def _clean_markdown(self, text: str) -> str:
        """
        [å…³é”®åŠŸèƒ½] æ·±åº¦æ¸…æ´— Markdown æ–‡æœ¬
        è§£å†³ HTML è½¬ä¹‰ã€LaTeX è¿‡åº¦åŒ…è£…å’Œæ¨¡å‹å¹»è§‰é—®é¢˜
        """
        if not text:
            return ""

        # 1. HTML åè½¬ä¹‰ (è§£å†³ &gt; -> >)
        # å¿…é¡»å…ˆæ‰§è¡Œï¼Œå› ä¸ºæœ‰æ—¶å€™ &gt; å¯èƒ½è¢«åŒ…è£¹åœ¨ \mathrm{} ä¸­
        text = html.unescape(text)

        # 2. å»é™¤ LaTeX çš„ \mathrm{} åŒ…è£… (è§£å†³ \mathrm{LVEDd} -> LVEDd)
        # ä¿®æ”¹è¯´æ˜ï¼š
        # - ä½¿ç”¨ (.*?) éè´ªå©ªåŒ¹é…ï¼Œé¿å… [^\}]+ æ— æ³•åŒ¹é…ç©ºå†…å®¹æˆ–è·¨åº¦è¿‡å¤§çš„é—®é¢˜
        # - æ·»åŠ  re.DOTALL æ ‡å¿—ï¼Œç¡®ä¿ . å¯ä»¥åŒ¹é…æ¢è¡Œç¬¦ï¼Œå¤„ç†è·¨è¡Œçš„ \mathrm{...}
        text = re.sub(r'\\mathrm\{(.*?)\}', r'\1', text, flags=re.DOTALL)

        # 3. å»é™¤æ¨¡å‹å¹»è§‰äº§ç”Ÿçš„ <del> æ ‡ç­¾ (è§£å†³ <del>cm)
        text = text.replace('<del>', '').replace('</del>', '')

        return text

    def cleanup(self):
        """æ¸…ç†æ˜¾å­˜"""
        try:
            from mineru.utils.model_utils import clean_memory
            clean_memory()
            logger.debug("ğŸ§¹ MinerU: Memory cleanup completed")
        except Exception:
            pass

    def parse(self, file_path: str, output_path: str, options: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        å¤„ç†æ–‡ä»¶ (å¢å¼ºç‰ˆï¼šä¸´æ—¶ç›®å½• + æœåŠ¡ç­‰å¾… + æ·±åº¦æ¸…æ´—)
        """
        options = options or {}
        
        final_output_dir = Path(output_path)
        final_output_dir.mkdir(parents=True, exist_ok=True)

        file_path_obj = Path(file_path)
        file_ext = file_path_obj.suffix.lower()

        # 1. ç¡®å®š Backend
        user_backend = options.get("parse_mode", "pipeline")
        if user_backend == "auto":
            user_backend = "pipeline"

        backend = user_backend
        server_url = options.get("server_url")

        # æ™ºèƒ½åˆ‡æ¢ VLLM
        if not server_url and self.vlm_api_base:
            if user_backend == "vlm-auto-engine":
                backend = "vlm-http-client"
                server_url = self.vlm_api_base.replace("/v1", "")
                logger.info(f"ğŸ”„ [Accelerate] Switching to {backend} using local vLLM")
            elif user_backend == "hybrid-auto-engine":
                backend = "hybrid-http-client"
                server_url = self.vlm_api_base.replace("/v1", "")
                logger.info(f"ğŸ”„ [Accelerate] Switching to {backend} using local vLLM")

        # æœåŠ¡å¥åº·æ£€æŸ¥
        if "http-client" in backend and server_url:
            self._wait_for_server(server_url)

        # 2. å‡†å¤‡å‚æ•°
        parse_method = options.get("method", "auto")
        if options.get("force_ocr"):
            parse_method = "ocr"

        formula_enable = options.get("formula_enable", True)
        table_enable = options.get("table_enable", True)
        
        f_draw_layout_bbox = options.get("draw_layout_bbox", True)      
        f_draw_span_bbox = options.get("draw_span_bbox", True)          
        f_dump_md = options.get("dump_markdown", True)                  
        f_dump_middle_json = options.get("dump_middle_json", True)      
        f_dump_model_output = options.get("dump_model_output", True)    
        f_dump_content_list = options.get("dump_content_list", True)    
        f_dump_orig_pdf = options.get("dump_orig_pdf", True)            

        start_page_id = options.get("start_page_id", 0)
        end_page_id = options.get("end_page_id", None)
        
        try: start_page_id = int(start_page_id)
        except: start_page_id = 0
        
        try: 
            if end_page_id is not None and str(end_page_id).strip() != "": 
                end_page_id = int(end_page_id)
                if end_page_id == -1: end_page_id = None
            else: end_page_id = None
        except: end_page_id = None

        do_parse_func = self._load_pipeline()

        try:
            with open(file_path, "rb") as f:
                file_bytes = f.read()

            if file_ext in [".png", ".jpg", ".jpeg"]:
                logger.info("ğŸ–¼ï¸  Converting image to PDF...")
                try:
                    pdf_bytes = img2pdf.convert(file_bytes)
                except Exception as e:
                    raise ValueError(f"Image conversion failed: {e}")
            else:
                pdf_bytes = file_bytes

            lang = options.get("lang", "auto")
            if lang == "auto": lang = "ch"

            # ä½¿ç”¨ä¸´æ—¶çº¯è‹±æ–‡ç›®å½•å¤„ç†
            with tempfile.TemporaryDirectory(prefix="mineru_proc_") as temp_dir:
                temp_work_dir = Path(temp_dir)
                logger.info(f"ğŸ› ï¸  Working in temp directory: {temp_work_dir}")
                
                safe_file_name = "result.pdf"
                
                do_parse_func(
                    output_dir=str(temp_work_dir),
                    pdf_file_names=[safe_file_name],
                    pdf_bytes_list=[pdf_bytes],
                    p_lang_list=[lang],
                    
                    backend=backend,
                    parse_method=parse_method,
                    server_url=server_url,
                    
                    start_page_id=start_page_id,
                    end_page_id=end_page_id,
                    formula_enable=formula_enable,
                    table_enable=table_enable,
                    
                    f_draw_layout_bbox=f_draw_layout_bbox,
                    f_draw_span_bbox=f_draw_span_bbox,
                    f_dump_md=f_dump_md,
                    f_dump_middle_json=f_dump_middle_json,
                    f_dump_model_output=f_dump_model_output,
                    f_dump_orig_pdf=f_dump_orig_pdf,
                    f_dump_content_list=f_dump_content_list
                )

                # ç»“æœæå–ä¸æ¬è¿
                generated_result_dir = temp_work_dir / "result"
                
                if not generated_result_dir.exists():
                    temp_md_files = list(temp_work_dir.rglob("*.md"))
                    if temp_md_files:
                        generated_result_dir = temp_md_files[0].parent.parent
                    else:
                        temp_json_files = list(temp_work_dir.rglob("*_content_list.json"))
                        if temp_json_files:
                             generated_result_dir = temp_json_files[0].parent.parent
                        else:
                             raise FileNotFoundError("Processing failed internally - No output generated")

                # 1. è¯»å–å†…å®¹å¹¶è¿›è¡Œæ·±åº¦æ¸…æ´—
                content = ""
                json_content = None
                
                temp_md_files = list(generated_result_dir.rglob("*.md"))
                if temp_md_files:
                    md_file = temp_md_files[0]
                    raw_content = md_file.read_text(encoding="utf-8")
                    
                    # =========================================================
                    # ã€æ ¸å¿ƒä¿®å¤ã€‘è°ƒç”¨ _clean_markdown è¿›è¡Œæ·±åº¦æ¸…æ´—
                    # è§£å†³ &gt;, \mathrm{}, <del> ç­‰é—®é¢˜
                    # =========================================================
                    content = self._clean_markdown(raw_content)
                    
                    # è¦†ç›–å†™å…¥æ¸…æ´—åçš„å†…å®¹
                    md_file.write_text(content, encoding="utf-8")
                    
                    logger.info(f"âœ… Read and cleaned MD content: {len(content)} chars")
                
                temp_json_files = list(generated_result_dir.rglob("*_content_list.json"))
                if temp_json_files:
                    try:
                        with open(temp_json_files[0], "r", encoding="utf-8") as f:
                            json_content = json.load(f)
                    except: pass

                # 2. å¦‚æœ MD ä¸ºç©ºï¼Œå°è¯•ä» JSON æ¢å¤
                if not content.strip() and json_content:
                    logger.warning("âš ï¸  Markdown file is empty, attempting to recover text from JSON...")
                    recovered_text = []
                    if isinstance(json_content, list):
                        for block in json_content:
                            text = block.get("text", "")
                            # æ¢å¤æ—¶ä¹Ÿåšæ¸…æ´—
                            text = self._clean_markdown(text)
                            recovered_text.append(text)
                    content = "\n\n".join(recovered_text)
                    
                    # å¦‚æœæœ‰ MD æ–‡ä»¶ï¼Œæ›´æ–°å®ƒ
                    if temp_md_files:
                        temp_md_files[0].write_text(content, encoding="utf-8")
                        
                    logger.info(f"â„¹ï¸  Recovered {len(content)} chars from JSON")

                # 3. æ¬è¿æ–‡ä»¶
                logger.info(f"ğŸ“¦ Moving results from {generated_result_dir} to {final_output_dir}")
                if generated_result_dir.exists():
                    for src_path in generated_result_dir.rglob("*"):
                        if src_path.is_file():
                            rel_path = src_path.relative_to(generated_result_dir)
                            dest_path = final_output_dir / rel_path
                            dest_path.parent.mkdir(parents=True, exist_ok=True)
                            shutil.copy2(src_path, dest_path)

                # 4. è¿”å›è·¯å¾„
                final_md_path = None
                final_json_path = None
                
                final_mds = list(final_output_dir.rglob("*.md"))
                if final_mds:
                    final_md_path = str(final_mds[0])
                    # è¦†ç›–å†™å…¥æ¸…æ´—åçš„å†…å®¹ (åŒé‡ä¿é™©)
                    Path(final_md_path).write_text(content, encoding="utf-8")
                
                final_jsons = list(final_output_dir.rglob("*_content_list.json"))
                if final_jsons: final_json_path = str(final_jsons[0])

                if not content.strip():
                    layout_pdfs = list(final_output_dir.rglob("*_layout.pdf"))
                    if layout_pdfs:
                        content = "> âš ï¸ Text extraction returned empty content. Please check layout PDF."
                    else:
                        raise FileNotFoundError("No valid content generated.")

                return {
                    "markdown": content,
                    "result_path": str(final_output_dir),
                    "markdown_file": final_md_path,
                    "json_path": final_json_path,
                    "json_content": json_content
                }

        except Exception as e:
            logger.error(f"âŒ Pipeline processing failed: {e}")
            import traceback
            logger.debug(traceback.format_exc())
            raise

        finally:
            self.cleanup()


# å…¨å±€å•ä¾‹
_engine = None

def get_engine(vlm_api_base: str = None) -> MinerUPipelineEngine:
    global _engine
    if _engine is None:
        _engine = MinerUPipelineEngine(vlm_api_base=vlm_api_base)
    return _engine
