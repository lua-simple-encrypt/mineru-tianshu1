"""
MinerU Pipeline Engine
å•ä¾‹æ¨¡å¼ï¼Œæ¯ä¸ªè¿›ç¨‹åªåŠ è½½ä¸€æ¬¡æ¨¡åž‹
ä½¿ç”¨ MinerU å¤„ç† PDF å’Œå›¾ç‰‡

ä¿®å¤è¯´æ˜Žï¼š
- [å…³é”®] ä½¿ç”¨ä¸´æ—¶çº¯è‹±æ–‡ç›®å½•è¿›è¡Œå¤„ç†ï¼Œå½»åº•è§„é¿ä¸­æ–‡è·¯å¾„å¯¼è‡´çš„å†™å…¥å¤±è´¥/å†…å®¹ä¸ºç©ºé—®é¢˜
- [å…³é”®] ä¿®å¤ Markdown å†…å®¹ä¸ºç©ºæ—¶çš„è‡ªåŠ¨æ¢å¤é€»è¾‘ (ä»Ž JSON é‡å»º)
- [ä¿®å¤] å¼ºåˆ¶ä½¿ç”¨å®‰å…¨æ–‡ä»¶å 'result.pdf' è¿›è¡Œå†…éƒ¨å¤„ç†
- [ä¿®å¤] æ­£ç¡®é€ä¼  backend/server_url å‚æ•°ä»¥å¯ç”¨ VLLM åŠ é€Ÿ
"""

import json
import os
import shutil
import tempfile
from pathlib import Path
from typing import Optional, Dict, Any
from threading import Lock
from loguru import logger
import img2pdf


class MinerUPipelineEngine:
    """
    MinerU Pipeline å¼•æ“Ž
    """

    _instance: Optional["MinerUPipelineEngine"] = None
    _lock = Lock()
    _pipeline = None  # è¿™é‡Œçš„ pipeline å®žé™…ä¸Šæ˜¯ do_parse å‡½æ•°
    _initialized = False

    def __new__(cls, *args, **kwargs):
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
        return cls._instance

    def __init__(self, device: str = "cuda:0", vlm_api_base: str = None):
        if self._initialized:
            return

        with self._lock:
            if self._initialized:
                return

            self.device = device
            self.vlm_api_base = vlm_api_base

            if "cuda:" in device:
                self.gpu_id = device.split(":")[-1]
            else:
                self.gpu_id = "0"

            self._initialized = True
            logger.info(f"ðŸ”§ MinerU Pipeline Engine initialized on {device}")
            if self.vlm_api_base:
                logger.info(f"   VLLM API Base: {self.vlm_api_base}")

    def _load_pipeline(self):
        """å»¶è¿ŸåŠ è½½ MinerU ç®¡é“ (do_parse)"""
        if self._pipeline is not None:
            return self._pipeline

        with self._lock:
            if self._pipeline is not None:
                return self._pipeline

            logger.info("=" * 60)
            logger.info("ðŸ“¥ Loading MinerU Pipeline (do_parse)...")
            logger.info("=" * 60)

            try:
                from mineru.cli.common import do_parse
                self._pipeline = do_parse
                logger.info("âœ… MinerU Pipeline loaded successfully!")
                return self._pipeline
            except Exception as e:
                logger.error(f"âŒ Error loading MinerU pipeline: {e}")
                raise

    def cleanup(self):
        """æ¸…ç†æ˜¾å­˜"""
        try:
            from mineru.utils.model_utils import clean_memory
            clean_memory()
            logger.debug("ðŸ§¹ MinerU: Memory cleanup completed")
        except Exception:
            pass

    def parse(self, file_path: str, output_path: str, options: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        å¤„ç†æ–‡ä»¶ (å¢žå¼ºç‰ˆï¼šä½¿ç”¨ä¸´æ—¶ç›®å½•è§„é¿è·¯å¾„é—®é¢˜)
        """
        options = options or {}
        
        # ç”¨æˆ·æŒ‡å®šçš„æœ€ç»ˆè¾“å‡ºç›®å½• (å¯èƒ½åŒ…å«ä¸­æ–‡)
        final_output_dir = Path(output_path)
        final_output_dir.mkdir(parents=True, exist_ok=True)

        file_path_obj = Path(file_path)
        file_ext = file_path_obj.suffix.lower()

        # =========================================================================
        # 1. ç¡®å®š Backend (å¤„ç†æ¨¡å¼)
        # =========================================================================
        user_backend = options.get("parse_mode", "pipeline")
        if user_backend == "auto":
            user_backend = "pipeline"

        backend = user_backend
        server_url = options.get("server_url")

        # æ™ºèƒ½åˆ‡æ¢ VLLM åŠ é€Ÿ
        if not server_url and self.vlm_api_base:
            if user_backend == "vlm-auto-engine":
                backend = "vlm-http-client"
                server_url = self.vlm_api_base.replace("/v1", "")
                logger.info(f"ðŸ”„ [Accelerate] Switching to {backend} using local vLLM")
            elif user_backend == "hybrid-auto-engine":
                backend = "hybrid-http-client"
                server_url = self.vlm_api_base.replace("/v1", "")
                logger.info(f"ðŸ”„ [Accelerate] Switching to {backend} using local vLLM")

        # =========================================================================
        # 2. å‡†å¤‡å‚æ•°
        # =========================================================================
        parse_method = options.get("method", "auto")
        if options.get("force_ocr"):
            parse_method = "ocr"

        # åŠŸèƒ½å¼€å…³
        formula_enable = options.get("formula_enable", True)
        table_enable = options.get("table_enable", True)
        
        # è¾“å‡ºæŽ§åˆ¶ (é»˜è®¤å¼€å¯ä»¥ç¡®ä¿è°ƒè¯•æ–‡ä»¶ç”Ÿæˆ)
        f_draw_layout_bbox = options.get("draw_layout_bbox", True)      
        f_draw_span_bbox = options.get("draw_span_bbox", True)          
        f_dump_md = options.get("dump_markdown", True)                  
        f_dump_middle_json = options.get("dump_middle_json", True)      
        f_dump_model_output = options.get("dump_model_output", True)    
        f_dump_content_list = options.get("dump_content_list", True)    
        f_dump_orig_pdf = options.get("dump_orig_pdf", True)            

        # é¡µé¢èŒƒå›´
        start_page_id = options.get("start_page_id", 0)
        end_page_id = options.get("end_page_id", None)
        
        try: start_page_id = int(start_page_id)
        except: start_page_id = 0
        
        try: 
            if end_page_id is not None and str(end_page_id).strip() != "": 
                end_page_id = int(end_page_id)
                if end_page_id == -1: end_page_id = None
            else: end_page_id = None
        except: end_page_id = None

        # åŠ è½½å¼•æ“Ž
        do_parse_func = self._load_pipeline()

        try:
            # è¯»å–æºæ–‡ä»¶
            with open(file_path, "rb") as f:
                file_bytes = f.read()

            # æ ¼å¼è½¬æ¢
            if file_ext in [".png", ".jpg", ".jpeg"]:
                logger.info("ðŸ–¼ï¸  Converting image to PDF...")
                try:
                    pdf_bytes = img2pdf.convert(file_bytes)
                except Exception as e:
                    raise ValueError(f"Image conversion failed: {e}")
            else:
                pdf_bytes = file_bytes

            lang = options.get("lang", "auto")
            if lang == "auto": lang = "ch"

            # =================================================================
            # ã€æ ¸å¿ƒä¿®å¤ã€‘ä½¿ç”¨ä¸´æ—¶çº¯è‹±æ–‡ç›®å½•å¤„ç†
            # =================================================================
            # åˆ›å»ºä¸´æ—¶ç›®å½•ï¼Œç¡®ä¿è·¯å¾„ä¸å«ä»»ä½•ä¸­æ–‡æˆ–ç‰¹æ®Šå­—ç¬¦
            # è¿™èƒ½å½»åº•è§£å†³ MinerU åº•å±‚åº“å› ä¸ºè·¯å¾„ç¼–ç é—®é¢˜å¯¼è‡´çš„å†™å…¥å¤±è´¥æˆ–ç©ºæ–‡ä»¶
            with tempfile.TemporaryDirectory(prefix="mineru_proc_") as temp_dir:
                temp_work_dir = Path(temp_dir)
                logger.info(f"ðŸ› ï¸  Working in temp directory: {temp_work_dir}")
                
                # å¼ºåˆ¶ä½¿ç”¨å®‰å…¨æ–‡ä»¶å
                safe_file_name = "result.pdf"
                
                # è°ƒç”¨ MinerU å¤„ç†
                do_parse_func(
                    output_dir=str(temp_work_dir), # è¾“å‡ºåˆ°ä¸´æ—¶ç›®å½•
                    pdf_file_names=[safe_file_name],
                    pdf_bytes_list=[pdf_bytes],
                    p_lang_list=[lang],
                    
                    # å…³é”®å‚æ•°é€ä¼ 
                    backend=backend,
                    parse_method=parse_method,
                    server_url=server_url,
                    
                    start_page_id=start_page_id,
                    end_page_id=end_page_id,
                    formula_enable=formula_enable,
                    table_enable=table_enable,
                    
                    f_draw_layout_bbox=f_draw_layout_bbox,
                    f_draw_span_bbox=f_draw_span_bbox,
                    f_dump_md=f_dump_md,
                    f_dump_middle_json=f_dump_middle_json,
                    f_dump_model_output=f_dump_model_output,
                    f_dump_orig_pdf=f_dump_orig_pdf,
                    f_dump_content_list=f_dump_content_list
                )

                # =============================================================
                # ç»“æžœæå–ä¸Žæ¬è¿
                # =============================================================
                # MinerU è¾“å‡ºç»“æž„: {temp_work_dir}/result/auto/result.md
                # æ³¨æ„ï¼šresult æ¥è‡ª safe_file_name çš„ stem
                generated_result_dir = temp_work_dir / "result"
                
                if not generated_result_dir.exists():
                    logger.error("âŒ MinerU failed to generate output directory in temp workspace")
                    raise FileNotFoundError("Processing failed internally")

                # 1. åœ¨ä¸´æ—¶ç›®å½•ä¸­è¯»å–å†…å®¹ (æ­¤æ—¶è·¯å¾„ç»å¯¹å®‰å…¨)
                content = ""
                json_content = None
                
                # æŸ¥æ‰¾ Markdown
                temp_md_files = list(generated_result_dir.rglob("*.md"))
                if temp_md_files:
                    md_file = temp_md_files[0]
                    content = md_file.read_text(encoding="utf-8")
                    logger.info(f"âœ… Read MD content: {len(content)} chars")
                
                # æŸ¥æ‰¾ JSON
                temp_json_files = list(generated_result_dir.rglob("*_content_list.json"))
                if temp_json_files:
                    try:
                        with open(temp_json_files[0], "r", encoding="utf-8") as f:
                            json_content = json.load(f)
                    except: pass

                # ã€ä¿®å¤å†…å®¹ä¸ºç©ºã€‘å¦‚æžœ MD ä¸ºç©ºï¼Œå°è¯•ä»Ž JSON æ¢å¤
                if not content.strip() and json_content:
                    logger.warning("âš ï¸  Markdown file is empty, attempting to recover text from JSON...")
                    recovered_text = []
                    if isinstance(json_content, list):
                        for block in json_content:
                            if "text" in block:
                                recovered_text.append(block["text"])
                    content = "\n\n".join(recovered_text)
                    logger.info(f"â„¹ï¸  Recovered {len(content)} chars from JSON")

                # 2. å°†ç»“æžœæ–‡ä»¶æ¬è¿åˆ°ç”¨æˆ·æŒ‡å®šçš„ final_output_dir
                # å°† result/auto ä¸‹çš„æ‰€æœ‰æ–‡ä»¶å¤åˆ¶è¿‡åŽ»
                # æˆ–è€…ç›´æŽ¥æŠŠ result æ–‡ä»¶å¤¹é‡Œçš„å†…å®¹å¤åˆ¶åˆ° final_output_dir
                logger.info(f"ðŸ“¦ Moving results to: {final_output_dir}")
                
                for src_path in generated_result_dir.rglob("*"):
                    if src_path.is_file():
                        # è®¡ç®—ç›¸å¯¹è·¯å¾„ï¼Œä¿æŒç›®å½•ç»“æž„ (ä¾‹å¦‚ auto/images/1.jpg)
                        rel_path = src_path.relative_to(generated_result_dir)
                        dest_path = final_output_dir / rel_path
                        
                        # ç¡®ä¿ç›®æ ‡çˆ¶ç›®å½•å­˜åœ¨
                        dest_path.parent.mkdir(parents=True, exist_ok=True)
                        
                        # å¤åˆ¶æ–‡ä»¶
                        shutil.copy2(src_path, dest_path)

                # =============================================================
                # è¿”å›žæœ€ç»ˆç»“æžœè·¯å¾„
                # =============================================================
                # é‡æ–°å®šä½æœ€ç»ˆç›®å½•ä¸‹çš„å…³é”®æ–‡ä»¶
                final_md_path = None
                final_json_path = None
                
                # æŸ¥æ‰¾æœ€ç»ˆç›®å½•ä¸‹çš„ MD
                final_mds = list(final_output_dir.rglob("*.md"))
                if final_mds:
                    final_md_path = str(final_mds[0])
                
                # æŸ¥æ‰¾æœ€ç»ˆç›®å½•ä¸‹çš„ JSON
                final_jsons = list(final_output_dir.rglob("*_content_list.json"))
                if final_jsons:
                    final_json_path = str(final_jsons[0])

                if not content.strip():
                    # æœ€åŽä¸€é“é˜²çº¿ï¼šæ£€æŸ¥æ˜¯å¦æœ‰å¸ƒå±€ PDF
                    layout_pdfs = list(final_output_dir.rglob("*_layout.pdf"))
                    if layout_pdfs:
                        content = "> âš ï¸ Text extraction returned empty content. Please check layout PDF."
                        logger.warning("âš ï¸  Returning empty content warning.")
                    else:
                        raise FileNotFoundError("No valid content generated.")

                return {
                    "markdown": content,
                    "result_path": str(final_output_dir),
                    "markdown_file": final_md_path,
                    "json_path": final_json_path,
                    "json_content": json_content
                }

        except Exception as e:
            logger.error(f"âŒ Pipeline processing failed: {e}")
            # å°è¯•æ‰“å°é”™è¯¯å †æ ˆ
            import traceback
            logger.debug(traceback.format_exc())
            raise

        finally:
            self.cleanup()


# å…¨å±€å•ä¾‹
_engine = None

def get_engine(vlm_api_base: str = None) -> MinerUPipelineEngine:
    global _engine
    if _engine is None:
        _engine = MinerUPipelineEngine(vlm_api_base=vlm_api_base)
    return _engine
