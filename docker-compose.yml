# Tianshu (天枢) - Production Docker Compose
# 模式：相对路径挂载 + Paddle自动下载持久化

name: tianshu

services:
  # ============================================================================
  # Redis
  # ============================================================================
  redis:
    image: redis:7-alpine
    container_name: tianshu-redis
    restart: unless-stopped
    profiles:
      - redis
    ports:
      - "${REDIS_PORT:-6379}:6379"
    volumes:
      - redis-data:/data
      - /etc/localtime:/etc/localtime:ro
      - /etc/timezone:/etc/timezone:ro
    environment:
      - TZ=Asia/Shanghai
    command: redis-server --appendonly yes --maxmemory 256mb --maxmemory-policy allkeys-lru
    networks:
      - tianshu-network

  # ============================================================================
  # RustFS
  # ============================================================================
  rustfs:
    image: rustfs/rustfs:latest
    container_name: tianshu-rustfs
    restart: unless-stopped
    ports:
      - "${RUSTFS_PORT:-9000}:9000"
      - "${RUSTFS_CONSOLE_PORT:-9001}:9001"
    volumes:
      - rustfs-data:/data
      - rustfs-logs:/logs
      - /etc/localtime:/etc/localtime:ro
      - /etc/timezone:/etc/timezone:ro
    environment:
      - TZ=Asia/Shanghai
      - RUSTFS_ROOT_USER=${RUSTFS_ACCESS_KEY:-rustfsadmin}
      - RUSTFS_ROOT_PASSWORD=${RUSTFS_SECRET_KEY:-rustfsadmin}
    networks:
      - tianshu-network

  # ============================================================================
  # Model Initializer (用于预先下载必要模型)
  # ============================================================================
  init-models:
    image: tianshu-backend:latest
    container_name: tianshu-init-models
    entrypoint: ["python", "download_models.py", "--output", "/app/models"]
    volumes:
      # 挂载主模型目录
      - ./models:/app/models:rw
      # 确保初始化脚本也能看到并写入缓存目录
      - ./models/paddlex_cache:/root/.paddlex:rw
      - ./models/paddleocr_cache:/root/.paddleocr:rw
      - ./magic-pdf.json:/app/magic-pdf.json:rw
      - /etc/localtime:/etc/localtime:ro
    environment:
      - TZ=Asia/Shanghai
      - MODEL_DOWNLOAD_SOURCE=${MODEL_DOWNLOAD_SOURCE:-auto}
      - HF_ENDPOINT=${HF_ENDPOINT:-https://hf-mirror.com}
    networks:
      - tianshu-network

  # ============================================================================
  # Backend API
  # ============================================================================
  backend:
    build:
      context: .
      dockerfile: backend/Dockerfile
      cache_from:
        - tianshu-backend:latest
    image: tianshu-backend:latest
    container_name: tianshu-backend
    restart: unless-stopped
    ports:
      - "${API_PORT:-8000}:8000"
    volumes:
      - ./models:/app/models:rw
      - ./models/paddlex_cache:/root/.paddlex:rw
      - ./models/paddleocr_cache:/root/.paddleocr:rw
      - ./magic-pdf.json:/root/magic-pdf.json:ro
      - ./input:/app/data/uploads:rw
      - ./output:/app/data/output:rw
      - ./logs/backend:/app/logs:rw
      - ./data/db:/app/data/db:rw
      - /etc/localtime:/etc/localtime:ro
      - /etc/timezone:/etc/timezone:ro
    environment:
      - TZ=Asia/Shanghai
      - HOST=0.0.0.0
      - API_PORT=8000
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - JWT_SECRET_KEY=${JWT_SECRET_KEY}
      - CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES:-0}
      - WORKER_URL=${WORKER_URL:-http://worker:8001}
      - MODEL_PATH=/app/models
      - OUTPUT_PATH=/app/data/output
      - UPLOAD_PATH=/app/data/uploads
      - DATABASE_PATH=${DATABASE_PATH:-/app/data/db/mineru_tianshu.db}
      - RUSTFS_ENABLED=${RUSTFS_ENABLED:-true}
      - RUSTFS_ENDPOINT=${RUSTFS_ENDPOINT:-rustfs:9000}
      - RUSTFS_ACCESS_KEY=${RUSTFS_ACCESS_KEY:-rustfsadmin}
      - RUSTFS_SECRET_KEY=${RUSTFS_SECRET_KEY:-rustfsadmin}
      - RUSTFS_BUCKET=${RUSTFS_BUCKET:-ts-img}
      - RUSTFS_PUBLIC_URL=${RUSTFS_PUBLIC_URL}
      - MODEL_DOWNLOAD_SOURCE=${MODEL_DOWNLOAD_SOURCE:-auto}
      - HF_ENDPOINT=${HF_ENDPOINT:-https://hf-mirror.com}
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: ${GPU_COUNT:-1}
              capabilities: [gpu]
    networks:
      - tianshu-network
    depends_on:
      # ✅ [核心修改] 将列表语法改为字典语法，强制等待 init-models 执行完毕
      rustfs:
        condition: service_started
      init-models:
        condition: service_completed_successfully

  # ============================================================================
  # vLLM Service - PaddleOCR
  # ============================================================================
  vllm-paddleocr:
    image: vllm/vllm-openai:nightly
    container_name: tianshu-vllm-paddleocr
    restart: unless-stopped
    ports:
      - "30023:30023"
    volumes:
      - ./models:/models:ro
      # 映射下载脚本预先缓存好的 VLLM 权重目录
      - ./models/paddlex_cache/official_models/PaddleOCR-VL-1.5-0.9B:/models/paddlex/PaddleOCR-VL-1.5-0.9B:ro
      - ./models/paddlex_cache:/root/.paddlex:ro
      - /etc/localtime:/etc/localtime:ro
    environment:
      - TZ=Asia/Shanghai
      - CUDA_VISIBLE_DEVICES=${VLLM_PADDLE_DEVICE:-0}
      - TOKENIZERS_PARALLELISM=false
    command: >
      --model /models/paddlex/PaddleOCR-VL-1.5-0.9B
      --served-model-name PaddleOCR-VL-1.5-0.9B
      --trust-remote-code
      --host 0.0.0.0
      --port 30023
      --gpu-memory-utilization 0.7
      --max-model-len 16384
      --enforce-eager
    shm_size: 32gb
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    networks:
      - tianshu-network
    depends_on:
      # ✅ [核心修改] 强制要求等待预下载脚本执行完毕，防止 vLLM 找不到模型一直崩溃重启
      init-models:
        condition: service_completed_successfully

  # ============================================================================
  # vLLM Service - MinerU
  # ============================================================================
  vllm-mineru:
    image: vllm/vllm-openai:nightly
    container_name: tianshu-vllm-mineru
    restart: no
    profiles: ["manual"]
    ports:
      - "30024:30024"
    volumes:
      - ./models:/models:ro
      - /etc/localtime:/etc/localtime:ro
    environment:
      - TZ=Asia/Shanghai
      - CUDA_VISIBLE_DEVICES=${VLLM_MINERU_DEVICE:-0}
    command: >
      --model /models/MinerU2.5-2509-1.2B
      --served-model-name MinerU-1.2B
      --trust-remote-code
      --host 0.0.0.0
      --port 30024
      --gpu-memory-utilization 0.7
      --max-model-len 8192
      --enforce-eager
    shm_size: 32gb
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    networks:
      - tianshu-network
    depends_on:
      init-models:
        condition: service_completed_successfully

  # ============================================================================
  # Worker
  # ============================================================================
  worker:
    image: tianshu-backend:latest
    container_name: tianshu-worker
    user: root
    restart: unless-stopped
    command: [
      "worker",
      "python",
      "litserve_worker.py",
      "--paddleocr-vl-vllm-engine-enabled",
      "--paddleocr-vl-vllm-api-list", "['http://vllm-paddleocr:30023/v1']",
      "--mineru-vllm-api-list", "['http://vllm-mineru:30024/v1']"
    ]
    ports:
      - "${WORKER_PORT:-8001}:8001"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./models:/app/models:rw
      - ./models/paddlex_cache:/root/.paddlex:rw
      - ./models/paddleocr_cache:/root/.paddleocr:rw
      - ./magic-pdf.json:/root/magic-pdf.json:ro
      - ./input:/app/data/uploads:rw
      - ./output:/app/data/output:rw
      - ./logs/worker:/app/logs:rw
      - ./data/db:/app/data/db:rw
      - /etc/localtime:/etc/localtime:ro
      - /etc/timezone:/etc/timezone:ro
    environment:
      - TZ=Asia/Shanghai
      - HOST=0.0.0.0
      - WORKER_PORT=8001
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - WORKER_GPUS=${WORKER_GPUS:-2}
      - MODEL_PATH=/app/models
      - OUTPUT_PATH=/app/data/output
      - UPLOAD_PATH=/app/data/uploads
      - DATABASE_PATH=${DATABASE_PATH:-/app/data/db/mineru_tianshu.db}
      - MAX_BATCH_SIZE=${MAX_BATCH_SIZE:-4}
      - TIMEOUT=${WORKER_TIMEOUT:-300}
      - MODEL_DOWNLOAD_SOURCE=${MODEL_DOWNLOAD_SOURCE:-auto}
      - HF_ENDPOINT=${HF_ENDPOINT:-https://hf-mirror.com}
      - HF_TOKEN=${HF_TOKEN:-}
      - PDF_SPLIT_ENABLED=${PDF_SPLIT_ENABLED:-true}
      - PDF_SPLIT_THRESHOLD_PAGES=${PDF_SPLIT_THRESHOLD_PAGES:-500}
      - PDF_SPLIT_CHUNK_SIZE=${PDF_SPLIT_CHUNK_SIZE:-500}
      - RUSTFS_ENABLED=${RUSTFS_ENABLED:-true}
      - RUSTFS_ENDPOINT=${RUSTFS_ENDPOINT:-rustfs:9000}
      - RUSTFS_ACCESS_KEY=${RUSTFS_ACCESS_KEY:-rustfsadmin}
      - RUSTFS_SECRET_KEY=${RUSTFS_SECRET_KEY:-rustfsadmin}
      - RUSTFS_BUCKET=${RUSTFS_BUCKET:-ts-img}
      - RUSTFS_PUBLIC_URL=${RUSTFS_PUBLIC_URL}
      - REDIS_QUEUE_ENABLED=${REDIS_QUEUE_ENABLED:-false}
      - REDIS_HOST=${REDIS_HOST:-redis}
      - REDIS_PORT=${REDIS_PORT:-6379}
      - PADDLE_HOME=/root/.paddleocr
      - PADDLEX_HOME=/root/.paddlex
    mem_limit: ${WORKER_MEMORY_LIMIT:-16G}
    memswap_limit: ${WORKER_MEMORY_LIMIT:-16G}
    mem_reservation: ${WORKER_MEMORY_RESERVATION:-8G}
    deploy:
      resources:
        limits:
          memory: ${WORKER_MEMORY_LIMIT:-16G}
        reservations:
          memory: ${WORKER_MEMORY_RESERVATION:-8G}
          devices:
            - driver: nvidia
              count: ${GPU_COUNT:-1}
              capabilities: [gpu]
    networks:
      - tianshu-network
    depends_on:
      # ✅ [核心修改] 将列表语法改为字典语法，强制等待 backend 启动且 init-models 执行完毕
      rustfs:
        condition: service_started
      backend:
        condition: service_started
      init-models:
        condition: service_completed_successfully

  # ============================================================================
  # MCP Server
  # ============================================================================
  mcp-server:
    image: tianshu-backend:latest
    container_name: tianshu-mcp
    restart: unless-stopped
    command: ["mcp", "python", "mcp_server.py"]
    ports:
      - "${MCP_PORT:-8002}:8002"
    volumes:
      - ./mcp_config.example.json:/app/backend/mcp_config.json:ro
      - ./logs/mcp:/app/logs:rw
      - /etc/localtime:/etc/localtime:ro
      - /etc/timezone:/etc/timezone:ro
    environment:
      - TZ=Asia/Shanghai
      - HOST=0.0.0.0
      - MCP_PORT=8002
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - API_URL=${API_URL:-http://backend:8000}
    networks:
      - tianshu-network
    depends_on:
      - backend

  # ============================================================================
  # Frontend
  # ============================================================================
  frontend:
    build:
      context: .
      dockerfile: frontend/Dockerfile
      cache_from:
        - tianshu-frontend:latest
    image: tianshu-frontend:latest
    container_name: tianshu-frontend
    restart: unless-stopped
    ports:
      - "${FRONTEND_PORT:-80}:80"
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - /etc/timezone:/etc/timezone:ro
    environment:
      - TZ=Asia/Shanghai
      - VITE_API_BASE_URL=${VITE_API_BASE_URL:-http://localhost:8000}
    networks:
      - tianshu-network
    depends_on:
      - backend

networks:
  tianshu-network:
    driver: bridge
    ipam:
      driver: default
      config:
        - subnet: 172.28.0.0/16
          gateway: 172.28.0.1

volumes:
  models:
    driver: local
  uploads:
    driver: local
  output:
    driver: local
  logs:
    driver: local
  redis-data:
    driver: local
  rustfs-data:
    driver: local
  rustfs-logs:
    driver: local
